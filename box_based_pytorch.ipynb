{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract boxes with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T15:26:51.802617Z",
     "start_time": "2017-11-03T15:26:50.458295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, glob, json, tqdm, pandas, pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "from imgaug import imgaug as ia\n",
    "from PIL import Image\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from prepare_images_utils import *\n",
    "from latex_dataset import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T15:26:51.839874Z",
     "start_time": "2017-11-03T15:26:51.806831Z"
    }
   },
   "outputs": [],
   "source": [
    "SRC_DIR = './generated/src/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T15:26:51.974752Z",
     "start_time": "2017-11-03T15:26:51.843749Z"
    }
   },
   "outputs": [],
   "source": [
    "all_image_ids = [os.path.basename(fname)[:-9]\n",
    "                 for fname in glob.glob(os.path.join(SRC_DIR, '*_out.json'))]\n",
    "random.shuffle(all_image_ids)\n",
    "\n",
    "TOTAL_SAMPLES = len(all_image_ids)\n",
    "TRAIN_SAMPLES = int(TOTAL_SAMPLES * 0.8)\n",
    "VAL_SAMPLES = TOTAL_SAMPLES - TRAIN_SAMPLES\n",
    "train_image_ids = all_image_ids[:TRAIN_SAMPLES]\n",
    "val_image_ids = all_image_ids[TRAIN_SAMPLES:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T15:26:52.420538Z",
     "start_time": "2017-11-03T15:26:51.976313Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_image_with_boxes(img_id):\n",
    "    img = load_image_opaque(os.path.join(SRC_DIR, img_id + '_in.png'))\n",
    "    with open(os.path.join(SRC_DIR, img_id + '_out.json'), 'r') as f:\n",
    "        boxes = json.load(f)\n",
    "    return img, boxes\n",
    "\n",
    "\n",
    "def prepare_img_boxes_for_nn(img, boxes, shape=(600, 600)):\n",
    "    cats, just_boxes = zip(*boxes)\n",
    "    cats = numpy.array(cats)\n",
    "    just_boxes = numpy.array(just_boxes) * POINTS_TO_PIXELS_FACTOR\n",
    "    just_boxes = just_boxes[:, [1, 0, 3, 2]] # x1, y1, x2, y2\n",
    "    cropbox = numpy.array((just_boxes[:, 0].min(),\n",
    "                           just_boxes[:, 1].min(),\n",
    "                           just_boxes[:, 2].max(),\n",
    "                           just_boxes[:, 3].max())).astype('int')\n",
    "\n",
    "    res_in_img = Image.new('L', shape, 255)\n",
    "    res_in_img.paste(img.crop(cropbox))\n",
    "\n",
    "    just_boxes -= cropbox[[0, 1, 0, 1]]\n",
    "    just_boxes = numpy.clip(just_boxes,\n",
    "                            (0, 0, 0, 0),\n",
    "                            (shape[0], shape[1], shape[0], shape[1]))\n",
    "    boxes_area = (just_boxes[:, 2] - just_boxes[:, 0]) * (just_boxes[:, 3] - just_boxes[:, 1])\n",
    "    good_boxes = numpy.where(boxes_area > 0)[0]\n",
    "    return (numpy.array(res_in_img).astype('float32') / 255,\n",
    "            cats[good_boxes],\n",
    "            just_boxes[good_boxes])\n",
    "\n",
    "\n",
    "TOTAL_CLASSES = 5\n",
    "def make_mask_for_nn(size, box_cats, boxes_on_image):\n",
    "    result = numpy.zeros((TOTAL_CLASSES, ) + size, dtype='float32')\n",
    "    for cat, bbox in zip(box_cats, boxes_on_image.bounding_boxes):\n",
    "        result[cat, int(bbox.y1):int(bbox.y2+1), int(bbox.x1):int(bbox.x2+1)] = 1\n",
    "    return result\n",
    "\n",
    "\n",
    "def calc_loss_weights(mask, edge_add_weight=0.2, laplacian_ksize=9, edge_th=1.1):\n",
    "    result = numpy.ones_like(mask)\n",
    "    for sample_i in range(mask.shape[0]):\n",
    "        for channel_i in range(mask.shape[1]):\n",
    "            edges = numpy.absolute(cv2.Laplacian(mask[sample_i, channel_i],\n",
    "                                                 cv2.CV_32F,\n",
    "                                                 ksize=laplacian_ksize))\n",
    "            edges = numpy.where(edges > edge_th, 1, 0)\n",
    "            if edges.max() > 0:\n",
    "                result[sample_i, channel_i] += edge_add_weight * edges\n",
    "    return result\n",
    "\n",
    "\n",
    "def prepare_batch(batch_image_ids, augmenter):\n",
    "    images, box_cats, boxes = zip(*[prepare_img_boxes_for_nn(*load_image_with_boxes(img_id))\n",
    "                                    for img_id in batch_image_ids])\n",
    "\n",
    "    det = augmenter.to_deterministic() if not augmenter.deterministic else augseq\n",
    "\n",
    "    images_aug = det.augment_images(images)\n",
    "\n",
    "    boxes = [ia.BoundingBoxesOnImage([ia.BoundingBox(*box)\n",
    "                                      for box in img_boxes],\n",
    "                                     img.shape)\n",
    "             for img, img_boxes in zip(images, boxes)]\n",
    "    boxes_aug = det.augment_bounding_boxes(boxes)\n",
    "\n",
    "    mask = numpy.array([make_mask_for_nn(img.shape, img_box_cats, img_boxes)\n",
    "                        for img, img_box_cats, img_boxes\n",
    "                        in zip(images_aug, box_cats, boxes_aug)])\n",
    "\n",
    "    boxes_aug_lists_with_cats = []\n",
    "    for img_boxes, img_box_cats in zip(boxes_aug, box_cats):\n",
    "        img_boxes_with_cats = collections.defaultdict(list)\n",
    "        for b, c in zip(img_boxes.bounding_boxes, img_box_cats):\n",
    "            img_boxes_with_cats[c].append((b.x1, b.y1, b.x2, b.y2))\n",
    "        boxes_aug_lists_with_cats.append(img_boxes_with_cats)\n",
    "\n",
    "    return (batch_image_ids,\n",
    "            numpy.expand_dims(numpy.array(images_aug), 1),\n",
    "            mask,\n",
    "            calc_loss_weights(mask),\n",
    "            boxes_aug_lists_with_cats)\n",
    "\n",
    "\n",
    "def data_gen(image_ids, augmenter, batch_size=32):\n",
    "    while True:\n",
    "        yield prepare_batch(numpy.random.choice(image_ids, size=batch_size),\n",
    "                            augmenter)\n",
    "\n",
    "\n",
    "class SegmDataset(Dataset):\n",
    "    def __init__(self, all_image_ids, augmenter):\n",
    "        self.all_image_ids = all_image_ids\n",
    "        self.augmenter = augmenter\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_image_ids)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        (batch_image_ids,\n",
    "         in_img,\n",
    "         mask,\n",
    "         loss_weights,\n",
    "         boxes_aug) = prepare_batch([self.all_image_ids[i]],\n",
    "                                    self.augmenter)\n",
    "        boxes_aug_str = pickle.dumps(boxes_aug[0])\n",
    "        return (batch_image_ids,\n",
    "                in_img[0],\n",
    "                mask[0],\n",
    "                loss_weights[0],\n",
    "                boxes_aug_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T15:26:52.513982Z",
     "start_time": "2017-11-03T15:26:52.422390Z"
    }
   },
   "outputs": [],
   "source": [
    "imgaug_pipeline = iaa.Sequential([\n",
    "#     iaa.Fliplr(0.5), # horizontally flip 50% of the images\n",
    "#     iaa.GaussianBlur(sigma=(0, 3.0)) # blur images with a sigma of 0 to 3.0\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T15:26:52.586013Z",
     "start_time": "2017-11-03T15:26:52.515924Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_gen_mt = DataLoader(SegmDataset(train_image_ids, imgaug_pipeline),\n",
    "#                           batch_size=8,\n",
    "#                           shuffle=True,\n",
    "#                           num_workers=4)\n",
    "# train_gen_mt_iter = iter(train_gen_mt)\n",
    "# _ = next(train_gen_mt_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T15:26:52.680841Z",
     "start_time": "2017-11-03T15:26:52.587767Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%prun\n",
    "# for _ in range(10):\n",
    "#     next(train_gen_mt_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T15:26:52.748350Z",
     "start_time": "2017-11-03T15:26:52.682423Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_gen_st = data_gen(train_image_ids, imgaug_pipeline, batch_size=8)\n",
    "# train_gen_st_iter = iter(train_gen_st)\n",
    "# _ = next(train_gen_st_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T15:26:52.810798Z",
     "start_time": "2017-11-03T15:26:52.750085Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%prun\n",
    "# for _ in range(10):\n",
    "#     next(train_gen_st_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T15:26:53.022230Z",
     "start_time": "2017-11-03T15:26:52.812375Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilations=[1], bn=True):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.bn = nn.BatchNorm2d(in_channels)\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(in_channels,\n",
    "                                              out_channels,\n",
    "                                              kernel_size,\n",
    "                                              padding=dil,\n",
    "                                              dilation=dil)\n",
    "                                    for dil in dilations])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn(x)\n",
    "        return F.relu(torch.cat([conv(x) for conv in self.convs], dim=1))\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, out_channels=TOTAL_CLASSES, first_conv_channels=4, depth=2, out_layers=1, conv_kernel=(3, 3),\n",
    "                 enc_dilations=[1], dec_dilations=[1]):\n",
    "        super(UNet, self).__init__()\n",
    "        enc_channels = [1] + [first_conv_channels * (2**step) for step in range(depth)]\n",
    "        enc_in_channels = [1] + [n * len(enc_dilations) for n in enc_channels[1:]]\n",
    "        self.encoder = nn.ModuleList([ConvBlock(enc_in_channels[i],\n",
    "                                                enc_channels[i+1],\n",
    "                                                conv_kernel,\n",
    "                                                dilations=enc_dilations)\n",
    "                                      for i in range(depth)])\n",
    "        bottleneck_channels = enc_channels[-1] * 2\n",
    "        self.bottleneck = ConvBlock(enc_channels[-1],\n",
    "                                    bottleneck_channels,\n",
    "                                    conv_kernel,\n",
    "                                    dilations=enc_dilations)\n",
    "        dec_channels = [bottleneck_channels] + enc_channels[:0:-1]\n",
    "        self.dec_conv = nn.ModuleList([ConvBlock(dec_channels[i],\n",
    "                                                 dec_channels[i+1],\n",
    "                                                 conv_kernel,\n",
    "                                                 dilations=dec_dilations)\n",
    "                                      for i in range(depth)])\n",
    "        self.dec_deconv = nn.ModuleList([nn.ConvTranspose2d(dec_channels[i],\n",
    "                                                            dec_channels[i+1],\n",
    "                                                            (2, 2),\n",
    "                                                            stride=2)\n",
    "                                         for i in range(depth)])\n",
    "        self.out_layers = nn.ModuleList([ConvBlock(dec_channels[-1],\n",
    "                                                   dec_channels[-1],\n",
    "                                                   conv_kernel,\n",
    "                                                   dilations=dec_dilations)])\n",
    "        self.out_conv = nn.Conv2d(dec_channels[-1],\n",
    "                                  out_channels,\n",
    "                                  (1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc_conv_outs = []\n",
    "        enc_pool_outs = [x]\n",
    "        for enc_conv in self.encoder:\n",
    "            cur_conv_out = enc_conv(enc_pool_outs[-1])\n",
    "            enc_conv_outs.append(cur_conv_out)\n",
    "            cur_pool_out = F.max_pool2d(cur_conv_out, (2, 2))\n",
    "            enc_pool_outs.append(cur_pool_out)\n",
    "\n",
    "        cur_out = self.bottleneck(enc_pool_outs[-1])\n",
    "\n",
    "        for dec_step, (dec_conv, dec_deconv) in enumerate(zip(self.dec_conv, self.dec_deconv)):\n",
    "            up = dec_deconv(cur_out)\n",
    "            cur_out = torch.cat([up, enc_conv_outs[-dec_step-1]], dim=1)\n",
    "            cur_out = dec_conv(cur_out)\n",
    "\n",
    "        for out_layer in self.out_layers:\n",
    "            cur_out = F.relu(out_layer(cur_out))\n",
    "\n",
    "        return F.sigmoid(self.out_conv(cur_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define losses and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T15:26:53.439688Z",
     "start_time": "2017-11-03T15:26:53.024523Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_all_boxes(mask, min_area=100, min_size=(10, 10), threshold=0.5):\n",
    "# def get_all_boxes(mask, min_area=0, min_size=(0, 0), threshold=0.5):\n",
    "    result = []\n",
    "    contours = cv2.findContours((mask > threshold).astype('uint8'),\n",
    "                                cv2.RETR_LIST,\n",
    "                                cv2.CHAIN_APPROX_SIMPLE)[1]\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) < min_area:\n",
    "            continue\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if h < min_size[0] or w < min_size[1]:\n",
    "            continue\n",
    "        result.append((y, x, y+h, x+w))\n",
    "    result.sort()\n",
    "    return result\n",
    "\n",
    "\n",
    "def filter_by_intersection(big_box, boxes_to_filter, threshold=0.8):\n",
    "    return [b for b in boxes_to_filter\n",
    "            if box_inter_area(big_box, b) / box_area(b) >= threshold]\n",
    "\n",
    "\n",
    "def get_biggest_box(boxes):\n",
    "    return boxes[numpy.argmax(list(map(box_area, boxes)))]\n",
    "\n",
    "\n",
    "def get_boxes_by_channel(pred):\n",
    "    pred_boxes = [[]]\n",
    "    pred_boxes.append(get_all_boxes(pred[1]))\n",
    "    pred_body = get_biggest_box(pred_boxes[1])\n",
    "    for ch in range(2, TOTAL_CLASSES):\n",
    "        pred_boxes.append(filter_by_intersection(pred_body, get_all_boxes(pred[ch])))\n",
    "    return pred_boxes\n",
    "\n",
    "\n",
    "def find_closest_box(box, others, min_dice=0.8):\n",
    "    ba = box_area(box)\n",
    "    best_dice = 0\n",
    "    best_idx = None\n",
    "    for i, other in enumerate(others):\n",
    "        dice = 2 * box_inter_area(box, other) / (ba + box_area(other))\n",
    "        if dice > best_dice:\n",
    "            best_idx = i\n",
    "            best_dice = dice\n",
    "    return best_idx\n",
    "\n",
    "\n",
    "def classify_boxes(pred_boxes, gold_boxes, strictness=0.8):\n",
    "    true_positive = []\n",
    "    false_positive = []\n",
    "\n",
    "    found_gold = set()\n",
    "    for i, box in enumerate(pred_boxes):\n",
    "        closest_gold_i = find_closest_box(box, gold_boxes, min_dice=strictness)\n",
    "        if not closest_gold_i is None:\n",
    "            true_positive.append(i)\n",
    "            found_gold.add(closest_gold_i)\n",
    "        else:\n",
    "            false_positive.append(i)\n",
    "\n",
    "    false_negative = set(range(len(gold_boxes))) - found_gold\n",
    "    return (true_positive, false_positive, false_negative)\n",
    "\n",
    "\n",
    "def calc_precision(tp, fp, fn):\n",
    "    denom = float(tp + fp)\n",
    "    return (tp / denom) if denom > 1e-4 else 0\n",
    "\n",
    "\n",
    "def calc_recall(tp, fp, fn):\n",
    "    denom = float(tp + fn)\n",
    "    return (tp / denom) if denom > 1e-4 else 0\n",
    "\n",
    "\n",
    "def box_match_single_image(pred, gold_boxes, metric, strictness=0.8):\n",
    "    pred_boxes = get_boxes_by_channel(pred)\n",
    "    result = []\n",
    "    for ch in range(pred.shape[0]):\n",
    "        tp, fp, fn = classify_boxes(pred_boxes[ch],\n",
    "                                    gold_boxes.get(ch, []),\n",
    "                                    strictness=strictness)\n",
    "        tp, fp, fn = len(tp), len(fp), len(fn)\n",
    "        result.append(metric(tp, fp, fn))\n",
    "    return result\n",
    "\n",
    "def box_match_batch(pred, gold_boxes, metric, strictness=0.8):\n",
    "    if not isinstance(pred, numpy.ndarray):\n",
    "        pred = pred.data.cpu().numpy()\n",
    "    image_metrics = [box_match_single_image(pred[i],\n",
    "                                            gold_boxes[i],\n",
    "                                            metric,\n",
    "                                            strictness=strictness)\n",
    "                     for i in range(pred.shape[0])]\n",
    "    return numpy.array(image_metrics).mean(0)\n",
    "\n",
    "\n",
    "def box_match_precision(pred, target, gold_boxes, strictness=0.8):\n",
    "    return box_match_batch(pred, gold_boxes, calc_precision, strictness=strictness)\n",
    "\n",
    "\n",
    "def box_match_recall(pred, target, gold_boxes, strictness=0.8):\n",
    "    return box_match_batch(pred, gold_boxes, calc_recall, strictness=strictness)\n",
    "\n",
    "# box_match_precision(numpy.tile(numpy.array([[[[1, 1, 1, 1], [1, 1, 1, 1]]]]), (1, 5, 1, 1)),\n",
    "#                     None,\n",
    "#                     [{2 : [[0, 0, 2, 4]]}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy\n",
    "\n",
    "$Dice(p, t, w) = 1 - \\frac{ p \\cdot t + 1 }{ p + t + 1 }$\n",
    "\n",
    "$WDice(p, t, w) = 1 - \\frac{ p \\cdot t \\cdot w^{-1} + 1 }{ p + t + p \\cdot (1 - t) \\cdot w + 1 }$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T15:26:53.564109Z",
     "start_time": "2017-11-03T15:26:53.441683Z"
    }
   },
   "outputs": [],
   "source": [
    "DICE_SMOOTH = 1.0\n",
    "def dice_coef(pred, target, gold_boxes):\n",
    "    intersection = pred * target\n",
    "    union = pred + target\n",
    "    return ((2. * intersection.sum(3).sum(2).sum(0) + DICE_SMOOTH) /\n",
    "            (union.sum(3).sum(2).sum(0) + DICE_SMOOTH))\n",
    "\n",
    "\n",
    "def px_precision(pred, target, threshold=0.5):\n",
    "    pred = pred >= threshold\n",
    "    target = target >= threshold\n",
    "    tp = (pred * target).float().sum(3).sum(2).sum(0)\n",
    "    fp = ((target - pred) < 0).float().sum(3).sum(2).sum(0)\n",
    "    denum = tp + fp\n",
    "    return tp / (denum + (denum == 0).float())\n",
    "\n",
    "\n",
    "def px_recall(pred, target, threshold=0.5):\n",
    "    pred = pred >= threshold\n",
    "    target = target >= threshold\n",
    "    tp = (pred * target).float().sum(3).sum(2).sum(0)\n",
    "    fn = ((pred - target) < 0).float().sum(3).sum(2).sum(0)\n",
    "    denum = tp + fn\n",
    "    return tp / (denum + (denum == 0).float())\n",
    "\n",
    "\n",
    "def make_single_channel(f, channel):\n",
    "    def _impl(pred, target):\n",
    "        return f(pred[:, channel:channel+1], target[:, channel:channel+1])\n",
    "    return _impl\n",
    "\n",
    "\n",
    "def make_cpu(f):\n",
    "    def _impl(pred, target):\n",
    "        return f(pred.cpu(), target.cpu())\n",
    "    return _impl\n",
    "\n",
    "\n",
    "METRICS_DIMENSIONS_MEANING = (None, 'area', 'cell', 'rows', 'cols')\n",
    "METRICS = {'d' : (dice_coef, METRICS_DIMENSIONS_MEANING),\n",
    "#            'bp' : (box_match_precision, METRICS_DIMENSIONS_MEANING),\n",
    "#            'br' : (box_match_recall, METRICS_DIMENSIONS_MEANING),\n",
    "#            'p' : px_precision,\n",
    "#            'r' : px_recall\n",
    "           }\n",
    "# for channel in range(1, TOTAL_CLASSES):\n",
    "#     METRICS['d{}'.format(channel)] = make_single_channel(make_cpu(dice_coef), channel)\n",
    "#     METRICS['pp{}'.format(channel)] = make_single_channel(px_precision, channel)\n",
    "#     METRICS['pr{}'.format(channel)] = make_single_channel(px_recall, channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T15:26:53.659375Z",
     "start_time": "2017-11-03T15:26:53.565820Z"
    }
   },
   "outputs": [],
   "source": [
    "def dice_loss(pred, target, weights):\n",
    "    intersection = pred * target\n",
    "    union = pred + target\n",
    "    return 1 - ((2. * intersection.sum() + DICE_SMOOTH) /\n",
    "                (union.sum() + DICE_SMOOTH))\n",
    "\n",
    "\n",
    "def weighted_dice_loss(pred, target, weights):\n",
    "    # the idea is to lower actual intersection in important areas\n",
    "    inv_weights = 1 / weights\n",
    "    intersection = pred * inv_weights * target\n",
    "    \n",
    "    # the idea is to increase actual predicted values\n",
    "    # where they have to be zero\n",
    "    inv_target = 1 - target\n",
    "    inv_intersection = pred * inv_target * weights\n",
    "    union = pred + target + inv_intersection\n",
    "\n",
    "    return 1 - ((2. * intersection.sum() + DICE_SMOOTH) /\n",
    "                (union.sum() + DICE_SMOOTH))\n",
    "\n",
    "\n",
    "def dice_bce_loss(pred, target, weights):\n",
    "    return dice_loss(pred, target, weights) + F.binary_cross_entropy(pred, target, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T15:26:53.757642Z",
     "start_time": "2017-11-03T15:26:53.660990Z"
    }
   },
   "outputs": [],
   "source": [
    "def mcuda(x, cuda):\n",
    "    return x.cuda() if cuda else x\n",
    "\n",
    "\n",
    "def npten(arr, cuda):\n",
    "    return mcuda(torch.from_numpy(arr), cuda)\n",
    "\n",
    "\n",
    "def npvar(arr, cuda):\n",
    "    if not torch.is_tensor(arr):\n",
    "        arr = torch.from_numpy(arr)\n",
    "    return mcuda(Variable(arr), cuda)\n",
    "\n",
    "\n",
    "def run_network(network, generator, num_batches, criterion=dice_bce_loss, optimizer=None, cuda=True):\n",
    "    metrics = []\n",
    "    gen_iter = iter(generator)\n",
    "    for _ in tqdm.tqdm(range(num_batches)):\n",
    "        image_ids, images, mask, loss_weights, boxes = next(gen_iter)\n",
    "        images_var = npvar(images, cuda)\n",
    "        mask_var = npvar(mask, cuda)\n",
    "        loss_weights_var = npvar(loss_weights, cuda)\n",
    "        boxes = [pickle.loads(b) for b in boxes]\n",
    "\n",
    "        cur_out = network(images_var)\n",
    "\n",
    "        loss = criterion(cur_out, mask_var, loss_weights_var)\n",
    "\n",
    "        if optimizer:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm(network.parameters(), 10)\n",
    "            optimizer.step()\n",
    "\n",
    "        cur_metrics = { 'loss' : loss.data[0] }\n",
    "        for name, (func, elem_names) in METRICS.items():\n",
    "            metric_value = func(cur_out, mask_var, boxes)\n",
    "            if not isinstance(metric_value, (list, numpy.ndarray)):\n",
    "                metric_value = metric_value.cpu().data.numpy()\n",
    "            cur_metrics.update(('\\n'.join((name, n)), v) for n, v in zip(elem_names, metric_value) if n)\n",
    "        metrics.append(cur_metrics)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T15:31:18.258710Z",
     "start_time": "2017-11-03T15:26:53.759549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total parameters 60423\n",
      "epoch 0\n",
      "lr 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:42<00:00,  1.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d\n",
       "area</th>\n",
       "      <th>d\n",
       "cell</th>\n",
       "      <th>d\n",
       "cols</th>\n",
       "      <th>d\n",
       "rows</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.377635</td>\n",
       "      <td>0.151276</td>\n",
       "      <td>0.367543</td>\n",
       "      <td>0.146761</td>\n",
       "      <td>0.865857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.081692</td>\n",
       "      <td>0.028460</td>\n",
       "      <td>0.095364</td>\n",
       "      <td>0.052462</td>\n",
       "      <td>0.038225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       d\\narea   d\\ncell   d\\ncols   d\\nrows      loss\n",
       "mean  0.377635  0.151276  0.367543  0.146761  0.865857\n",
       "std   0.081692  0.028460  0.095364  0.052462  0.038225"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:12<00:00,  1.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d\n",
       "area</th>\n",
       "      <th>d\n",
       "cell</th>\n",
       "      <th>d\n",
       "cols</th>\n",
       "      <th>d\n",
       "rows</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.506821</td>\n",
       "      <td>0.200598</td>\n",
       "      <td>0.538252</td>\n",
       "      <td>0.261781</td>\n",
       "      <td>0.793365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.031868</td>\n",
       "      <td>0.012992</td>\n",
       "      <td>0.030592</td>\n",
       "      <td>0.019088</td>\n",
       "      <td>0.016962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       d\\narea   d\\ncell   d\\ncols   d\\nrows      loss\n",
       "mean  0.506821  0.200598  0.538252  0.261781  0.793365\n",
       "std   0.031868  0.012992  0.030592  0.019088  0.016962"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "lr 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:44<00:00,  1.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d\n",
       "area</th>\n",
       "      <th>d\n",
       "cell</th>\n",
       "      <th>d\n",
       "cols</th>\n",
       "      <th>d\n",
       "rows</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.702750</td>\n",
       "      <td>0.307249</td>\n",
       "      <td>0.749642</td>\n",
       "      <td>0.378293</td>\n",
       "      <td>0.648785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.127376</td>\n",
       "      <td>0.079954</td>\n",
       "      <td>0.114463</td>\n",
       "      <td>0.084669</td>\n",
       "      <td>0.102993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       d\\narea   d\\ncell   d\\ncols   d\\nrows      loss\n",
       "mean  0.702750  0.307249  0.749642  0.378293  0.648785\n",
       "std   0.127376  0.079954  0.114463  0.084669  0.102993"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:13<00:00,  1.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d\n",
       "area</th>\n",
       "      <th>d\n",
       "cell</th>\n",
       "      <th>d\n",
       "cols</th>\n",
       "      <th>d\n",
       "rows</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.902227</td>\n",
       "      <td>0.437700</td>\n",
       "      <td>0.889189</td>\n",
       "      <td>0.536584</td>\n",
       "      <td>0.464065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.010868</td>\n",
       "      <td>0.018483</td>\n",
       "      <td>0.011694</td>\n",
       "      <td>0.018910</td>\n",
       "      <td>0.013472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       d\\narea   d\\ncell   d\\ncols   d\\nrows      loss\n",
       "mean  0.902227  0.437700  0.889189  0.536584  0.464065\n",
       "std   0.010868  0.018483  0.011694  0.018910  0.013472"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2\n",
      "lr 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:46<00:00,  1.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d\n",
       "area</th>\n",
       "      <th>d\n",
       "cell</th>\n",
       "      <th>d\n",
       "cols</th>\n",
       "      <th>d\n",
       "rows</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.944422</td>\n",
       "      <td>0.500854</td>\n",
       "      <td>0.900044</td>\n",
       "      <td>0.646998</td>\n",
       "      <td>0.357422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.017636</td>\n",
       "      <td>0.030582</td>\n",
       "      <td>0.010999</td>\n",
       "      <td>0.048276</td>\n",
       "      <td>0.053050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       d\\narea   d\\ncell   d\\ncols   d\\nrows      loss\n",
       "mean  0.944422  0.500854  0.900044  0.646998  0.357422\n",
       "std   0.017636  0.030582  0.010999  0.048276  0.053050"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:13<00:00,  1.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d\n",
       "area</th>\n",
       "      <th>d\n",
       "cell</th>\n",
       "      <th>d\n",
       "cols</th>\n",
       "      <th>d\n",
       "rows</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.944087</td>\n",
       "      <td>0.537337</td>\n",
       "      <td>0.890840</td>\n",
       "      <td>0.673273</td>\n",
       "      <td>0.293871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.010262</td>\n",
       "      <td>0.011046</td>\n",
       "      <td>0.009835</td>\n",
       "      <td>0.011767</td>\n",
       "      <td>0.007480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       d\\narea   d\\ncell   d\\ncols   d\\nrows      loss\n",
       "mean  0.944087  0.537337  0.890840  0.673273  0.293871\n",
       "std   0.010262  0.011046  0.009835  0.011767  0.007480"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3\n",
      "lr 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:48<00:00,  1.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d\n",
       "area</th>\n",
       "      <th>d\n",
       "cell</th>\n",
       "      <th>d\n",
       "cols</th>\n",
       "      <th>d\n",
       "rows</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.966722</td>\n",
       "      <td>0.697317</td>\n",
       "      <td>0.909088</td>\n",
       "      <td>0.668369</td>\n",
       "      <td>0.230084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.008996</td>\n",
       "      <td>0.090282</td>\n",
       "      <td>0.010636</td>\n",
       "      <td>0.017997</td>\n",
       "      <td>0.032759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       d\\narea   d\\ncell   d\\ncols   d\\nrows      loss\n",
       "mean  0.966722  0.697317  0.909088  0.668369  0.230084\n",
       "std   0.008996  0.090282  0.010636  0.017997  0.032759"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:12<00:00,  1.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d\n",
       "area</th>\n",
       "      <th>d\n",
       "cell</th>\n",
       "      <th>d\n",
       "cols</th>\n",
       "      <th>d\n",
       "rows</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.295192</td>\n",
       "      <td>0.576386</td>\n",
       "      <td>0.265540</td>\n",
       "      <td>0.384663</td>\n",
       "      <td>0.822027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.036010</td>\n",
       "      <td>0.024905</td>\n",
       "      <td>0.034669</td>\n",
       "      <td>0.023222</td>\n",
       "      <td>0.024292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       d\\narea   d\\ncell   d\\ncols   d\\nrows      loss\n",
       "mean  0.295192  0.576386  0.265540  0.384663  0.822027\n",
       "std   0.036010  0.024905  0.034669  0.023222  0.024292"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4\n",
      "lr 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 5/75 [00:04<01:05,  1.06it/s]Process Process-20:\n",
      "Process Process-17:\n",
      "Process Process-6:\n",
      "Process Process-22:\n",
      "Process Process-2:\n",
      "Process Process-18:\n",
      "Process Process-21:\n",
      "Process Process-4:\n",
      "Process Process-1:\n",
      "Process Process-16:\n",
      "Process Process-23:\n",
      "Process Process-5:\n",
      "Process Process-7:\n",
      "Process Process-11:\n",
      "Process Process-8:\n",
      "Process Process-14:\n",
      "Process Process-10:\n",
      "Process Process-15:\n",
      "Process Process-12:\n",
      "Process Process-9:\n",
      "Process Process-13:\n",
      "Process Process-3:\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 44, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 44, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 44, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 44, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 44, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 44, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/queues.py\", line 354, in put\n",
      "    with self._wlock:\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 44, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 44, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/queues.py\", line 354, in put\n",
      "    with self._wlock:\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 44, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/queues.py\", line 354, in put\n",
      "    with self._wlock:\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 44, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 44, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/queues.py\", line 354, in put\n",
      "    with self._wlock:\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 44, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 44, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/queues.py\", line 354, in put\n",
      "    with self._wlock:\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 44, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/queues.py\", line 354, in put\n",
      "    with self._wlock:\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 44, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/queues.py\", line 354, in put\n",
      "    with self._wlock:\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 44, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/queues.py\", line 354, in put\n",
      "    with self._wlock:\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 44, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/queues.py\", line 355, in put\n",
      "    self._writer.send_bytes(obj)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 44, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/queues.py\", line 354, in put\n",
      "    with self._wlock:\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 44, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/queues.py\", line 354, in put\n",
      "    with self._wlock:\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/queues.py\", line 354, in put\n",
      "    with self._wlock:\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 44, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/queues.py\", line 354, in put\n",
      "    with self._wlock:\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 44, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/queues.py\", line 355, in put\n",
      "    self._writer.send_bytes(obj)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/queues.py\", line 355, in put\n",
      "    self._writer.send_bytes(obj)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/queues.py\", line 355, in put\n",
      "    self._writer.send_bytes(obj)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/queues.py\", line 354, in put\n",
      "    with self._wlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "KeyboardInterrupt\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 44, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/queues.py\", line 355, in put\n",
      "    self._writer.send_bytes(obj)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/queues.py\", line 355, in put\n",
      "    self._writer.send_bytes(obj)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/queues.py\", line 355, in put\n",
      "    self._writer.send_bytes(obj)\n",
      "KeyboardInterrupt\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/connection.py\", line 397, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/queues.py\", line 354, in put\n",
      "    with self._wlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/connection.py\", line 398, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/connection.py\", line 397, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/queues.py\", line 355, in put\n",
      "    self._writer.send_bytes(obj)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/connection.py\", line 398, in _send_bytes\n",
      "    self._send(buf)\n",
      "KeyboardInterrupt\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/connection.py\", line 398, in _send_bytes\n",
      "    self._send(buf)\n",
      "KeyboardInterrupt\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/connection.py\", line 397, in _send_bytes\n",
      "    self._send(header)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/connection.py\", line 398, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/connection.py\", line 398, in _send_bytes\n",
      "    self._send(buf)\n",
      "KeyboardInterrupt\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "KeyboardInterrupt\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-15-04393183b9d4>\", line 44, in <module>\n",
      "    optimizer=optimizer)\n",
      "  File \"<ipython-input-14-a11e8ef91bf5>\", line 19, in run_network\n",
      "    image_ids, images, mask, loss_weights, boxes = next(gen_iter)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 195, in __next__\n",
      "    idx, batch = self.data_queue.get()\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1828, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1090, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/inspect.py\", line 1454, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/inspect.py\", line 1411, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/inspect.py\", line 666, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/inspect.py\", line 709, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/inspect.py\", line 678, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/inspect.py\", line 663, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/root/.pyenv/versions/3.6.0/lib/python3.6/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "train_gen = None\n",
    "val_gen = None\n",
    "\n",
    "EPOCHS_NUM = 60\n",
    "BATCH_SIZE = 16\n",
    "PART_PER_EPOCH = 0.5\n",
    "BATCHES_PER_EPOCH_TRAIN = int(len(train_image_ids) * PART_PER_EPOCH / BATCH_SIZE)\n",
    "BATCHES_PER_EPOCH_VAL = int(len(val_image_ids) * PART_PER_EPOCH // BATCH_SIZE)\n",
    "\n",
    "# train_gen = data_gen(train_image_ids, imgaug_pipeline, batch_size=BATCH_SIZE)\n",
    "# val_gen = data_gen(val_image_ids, imgaug_pipeline, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "net = UNet(first_conv_channels=8,\n",
    "           depth=3,\n",
    "           enc_dilations=[1]).cuda()\n",
    "# LOSS = dice_bce_loss\n",
    "# LOSS = dice_loss\n",
    "LOSS = weighted_dice_loss\n",
    "print('total parameters', sum(numpy.product(p.size()) for p in net.parameters()))\n",
    "\n",
    "train_metrics = []\n",
    "val_metrics = []\n",
    "for epoch in range(EPOCHS_NUM):\n",
    "    try:\n",
    "        train_gen = DataLoader(SegmDataset(train_image_ids, imgaug_pipeline),\n",
    "                               batch_size=BATCH_SIZE,\n",
    "                               shuffle=True,\n",
    "                               num_workers=4)\n",
    "        val_gen = DataLoader(SegmDataset(val_image_ids, imgaug_pipeline),\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=True,\n",
    "                             num_workers=2)\n",
    "        print('epoch', epoch)\n",
    "\n",
    "        lr_factor = 0.5 ** (epoch // 20)\n",
    "        lr = 1e-3 * lr_factor\n",
    "        print('lr', lr)\n",
    "        optimizer = Adam(net.parameters(), lr=lr)\n",
    "\n",
    "        net.train()\n",
    "        cur_train_metrics = run_network(net, train_gen, BATCHES_PER_EPOCH_TRAIN,\n",
    "                                        criterion=LOSS,\n",
    "                                        optimizer=optimizer)\n",
    "        train_metrics.extend(cur_train_metrics)\n",
    "        display(pandas.DataFrame(cur_train_metrics).describe().loc[['mean', 'std']])\n",
    "\n",
    "        net.eval()\n",
    "        cur_val_metrics = run_network(net, val_gen, BATCHES_PER_EPOCH_VAL,\n",
    "                                      criterion=LOSS)\n",
    "        val_metrics.extend(cur_val_metrics)\n",
    "        display(pandas.DataFrame(cur_val_metrics).describe().loc[['mean', 'std']])\n",
    "    finally:\n",
    "        if train_gen:\n",
    "            del train_gen\n",
    "        if val_gen:\n",
    "            del val_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T15:31:18.259723Z",
     "start_time": "2017-11-03T15:26:50.528Z"
    }
   },
   "outputs": [],
   "source": [
    "train_metrics = pandas.DataFrame(train_metrics)\n",
    "val_metrics = pandas.DataFrame(val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T15:31:18.260922Z",
     "start_time": "2017-11-03T15:26:50.533Z"
    }
   },
   "outputs": [],
   "source": [
    "pandas.rolling_mean(train_metrics, 100).plot(figsize=(13, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T15:31:18.261897Z",
     "start_time": "2017-11-03T15:26:50.539Z"
    }
   },
   "outputs": [],
   "source": [
    "pandas.rolling_mean(val_metrics, 100).plot(figsize=(13, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T15:31:18.262923Z",
     "start_time": "2017-11-03T15:26:50.545Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.save(net, 'models/torch1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T15:31:18.264071Z",
     "start_time": "2017-11-03T15:26:50.550Z"
    }
   },
   "outputs": [],
   "source": [
    "test_net = torch.load('models/torch1').cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T15:31:18.265234Z",
     "start_time": "2017-11-03T15:26:50.557Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_net = net.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T15:31:18.266439Z",
     "start_time": "2017-11-03T15:26:50.564Z"
    }
   },
   "outputs": [],
   "source": [
    "test_batch = prepare_batch(val_image_ids[:10], imgaug_pipeline)\n",
    "test_pred = test_net(npvar(test_batch[1], False))\n",
    "test_pred_np = test_pred.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T15:31:18.267696Z",
     "start_time": "2017-11-03T15:26:50.570Z"
    }
   },
   "outputs": [],
   "source": [
    "arr_to_img((test_batch[3][3][2] / test_batch[3][3][2].max()) + test_batch[2][3][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T15:31:18.268883Z",
     "start_time": "2017-11-03T15:26:50.578Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "arr_to_img(test_batch[1][6][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T15:31:18.269962Z",
     "start_time": "2017-11-03T15:26:50.586Z"
    }
   },
   "outputs": [],
   "source": [
    "arr_to_img(test_pred_np[6][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T15:31:18.271003Z",
     "start_time": "2017-11-03T15:26:50.598Z"
    }
   },
   "outputs": [],
   "source": [
    "arr_to_img((test_pred_np[6][1] > 0.5).astype('uint8'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "138px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "793px",
    "left": "0px",
    "right": "1708px",
    "top": "111px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
