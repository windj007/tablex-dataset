{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract boxes with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:53:48.161861Z",
     "start_time": "2018-01-16T09:53:48.155604Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -U toposort\n",
    "# !pip uninstall -y torch\n",
    "# !pip install -U http://download.pytorch.org/whl/cu80/torch-0.2.0.post3-cp36-cp36m-manylinux1_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:03.966613Z",
     "start_time": "2018-01-16T09:53:48.164694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    multiprocessing.set_start_method('spawn', force=True)\n",
    "\n",
    "import os, glob, json, tqdm, pandas, pickle, rtree, gc, toposort, joblib, tabulate, lxml.etree\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "from imgaug import imgaug as ia\n",
    "from PIL import Image\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from intracell_utils.data_source import *\n",
    "\n",
    "from prepare_images_utils import *\n",
    "from latex_dataset import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:04.422958Z",
     "start_time": "2018-01-16T09:54:03.970124Z"
    }
   },
   "outputs": [],
   "source": [
    "DET_SRC_DIR = './data/arxiv/inout_pairs/'\n",
    "all_det_image_ids = [fname[:-9]\n",
    "                     for fname in glob.glob(os.path.join(DET_SRC_DIR, '*_out.json'))]\n",
    "random.shuffle(all_det_image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:04.449101Z",
     "start_time": "2018-01-16T09:54:04.424376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_det_image_ids 17669 strange_det_images 0\n",
      "train 14135 val 3534\n"
     ]
    }
   ],
   "source": [
    "# all_det_image_ids, strange_det_images = leave_only_valid_samples(all_det_image_ids, prepare_det_batch, fake_imgaug_pipeline)\n",
    "all_det_image_ids, strange_det_images = all_det_image_ids, []\n",
    "print('all_det_image_ids', len(all_det_image_ids), 'strange_det_images', len(strange_det_images))\n",
    "TOTAL_DET_SAMPLES = len(all_det_image_ids)\n",
    "TRAIN_DET_SAMPLES = int(TOTAL_DET_SAMPLES * 0.8)\n",
    "VAL_DET_SAMPLES = TOTAL_DET_SAMPLES - TRAIN_DET_SAMPLES\n",
    "train_det_image_ids = all_det_image_ids[:TRAIN_DET_SAMPLES]\n",
    "val_det_image_ids = all_det_image_ids[TRAIN_DET_SAMPLES:]\n",
    "print('train', len(train_det_image_ids), 'val', len(val_det_image_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internal table structure segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:04.494180Z",
     "start_time": "2018-01-16T09:54:04.453096Z"
    }
   },
   "outputs": [],
   "source": [
    "# INT_SRC_DIR = './data/generated/complex_clean/src/'\n",
    "# all_int_image_ids = [fname[:-9]\n",
    "#                      for fname in glob.glob(os.path.join(INT_SRC_DIR, '*_out.json'))]\n",
    "# random.shuffle(all_int_image_ids)\n",
    "# len(all_int_image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:04.518990Z",
     "start_time": "2018-01-16T09:54:04.495991Z"
    }
   },
   "outputs": [],
   "source": [
    "# all_int_image_ids, strange_int_images = leave_only_valid_samples(all_int_image_ids, prepare_int_batch, fake_imgaug_pipeline)\n",
    "# print(len(all_int_image_ids), len(strange_int_images))\n",
    "# TOTAL_INT_SAMPLES = len(all_int_image_ids)\n",
    "# TRAIN_INT_SAMPLES = int(TOTAL_INT_SAMPLES * 0.8)\n",
    "# VAL_INT_SAMPLES = TOTAL_INT_SAMPLES - TRAIN_INT_SAMPLES\n",
    "# train_int_image_ids = all_int_image_ids[:TRAIN_INT_SAMPLES]\n",
    "# val_int_image_ids = all_int_image_ids[TRAIN_INT_SAMPLES:]\n",
    "# print('train', len(train_int_image_ids), 'val', len(val_int_image_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generators playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:04.569636Z",
     "start_time": "2018-01-16T09:54:04.520823Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# qq = prepare_int_batch(all_int_image_ids[:10], imgaug_pipeline)\n",
    "# qq = prepare_det_batch(all_det_image_ids[:10], imgaug_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:04.602288Z",
     "start_time": "2018-01-16T09:54:04.571481Z"
    }
   },
   "outputs": [],
   "source": [
    "# arr_to_img(qq[1][5][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:04.633732Z",
     "start_time": "2018-01-16T09:54:04.603941Z"
    }
   },
   "outputs": [],
   "source": [
    "# arr_to_img(mask_to_img(qq[2][5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:04.659659Z",
     "start_time": "2018-01-16T09:54:04.636132Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_gen_mt = DataLoader(SegmDataset(train_image_ids, imgaug_pipeline),\n",
    "#                           batch_size=8,\n",
    "#                           shuffle=True,\n",
    "#                           num_workers=4)\n",
    "# train_gen_mt_iter = iter(train_gen_mt)\n",
    "# _ = next(train_gen_mt_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:04.710355Z",
     "start_time": "2018-01-16T09:54:04.661074Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%prun\n",
    "# for _ in range(10):\n",
    "#     next(train_gen_mt_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:04.757439Z",
     "start_time": "2018-01-16T09:54:04.711748Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_gen_st = data_gen(train_image_ids, imgaug_pipeline, batch_size=8)\n",
    "# train_gen_st_iter = iter(train_gen_st)\n",
    "# _ = next(train_gen_st_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:04.790688Z",
     "start_time": "2018-01-16T09:54:04.759380Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%prun\n",
    "# for _ in range(10):\n",
    "#     next(train_gen_st_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define losses and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:05.823765Z",
     "start_time": "2018-01-16T09:54:04.792166Z"
    }
   },
   "outputs": [],
   "source": [
    "def unsharp_mask(image, kernel=(9, 9), sigma=10, power=0.7):\n",
    "    blurred = cv2.GaussianBlur(image, kernel, sigma)\n",
    "    return cv2.addWeighted(image, 1.0, blurred, -power, 0, blurred)\n",
    "\n",
    "\n",
    "# def get_all_boxes(mask, min_area=100, min_size=(5, 5), threshold=0.5):\n",
    "def get_all_boxes(mask, min_area=10, min_size=(5, 5)):\n",
    "    result = []\n",
    "#     binarized_mask = cv2.adaptiveThreshold((mask*255).astype('uint8'),\n",
    "#                                            255,\n",
    "#                                            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "#                                            cv2.THRESH_BINARY,\n",
    "#                                            11,\n",
    "#                                            50)\n",
    "    mask_img = (mask*255).astype('uint8')\n",
    "#     display('src mask')\n",
    "#     display(arr_to_img((mask_img / 255).astype('float32')))\n",
    "    \n",
    "    mask_img = unsharp_mask(mask_img)\n",
    "    \n",
    "#     display('unsharp mask')\n",
    "#     display(arr_to_img((mask_img / 255).astype('float32')))\n",
    "    \n",
    "    _, binarized_mask = cv2.threshold(mask_img,\n",
    "                                      0,\n",
    "                                      255,\n",
    "                                      cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "#     display(arr_to_img((binarized_mask / 255).astype('float32')))\n",
    "    contours = cv2.findContours(binarized_mask,\n",
    "                                cv2.RETR_LIST,\n",
    "                                cv2.CHAIN_APPROX_SIMPLE)[1]\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) < min_area:\n",
    "            continue\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if h < min_size[0] or w < min_size[1]:\n",
    "            continue\n",
    "        result.append((y, x, y+h, x+w))\n",
    "    result.sort()\n",
    "    return result\n",
    "\n",
    "\n",
    "def filter_boxes_by_overlap(boxes, min_overlap=0.9):\n",
    "    boxes = list(boxes)\n",
    "    boxes.sort(key=box_area)\n",
    "    while True:\n",
    "        boxes_to_remove = set()\n",
    "        for i, cur in enumerate(boxes):\n",
    "            for j, bigger in enumerate(boxes[i+1:]):\n",
    "                overlap = box_inter_area(cur, bigger) / box_area(cur)\n",
    "                if overlap >= min_overlap:\n",
    "                    boxes_to_remove.add(i)\n",
    "                    break\n",
    "        if len(boxes_to_remove) == 0:\n",
    "            break\n",
    "        boxes = [b for i, b in enumerate(boxes) if i not in boxes_to_remove]\n",
    "    return boxes\n",
    "        \n",
    "\n",
    "\n",
    "def get_boxes_by_channel(pred, **kwargs):\n",
    "    pred_boxes = collections.defaultdict(list)\n",
    "    for channel in range(pred.shape[0]):\n",
    "        pred_boxes[channel] = filter_boxes_by_overlap(get_all_boxes(pred[channel], **kwargs))\n",
    "    return pred_boxes\n",
    "\n",
    "\n",
    "def get_boxes_by_channel_and_filter(pred, from_channel=2, to_channel=TOTAL_INT_CLASSES, body_channel=1):\n",
    "    pred_boxes = collections.defaultdict(list)\n",
    "    pred_boxes[body_channel] = get_all_boxes(pred[body_channel])\n",
    "    if len(pred_boxes[body_channel]) > 0:\n",
    "        pred_body = get_biggest_box(pred_boxes[body_channel])\n",
    "        for ch in range(from_channel, to_channel):\n",
    "            cand_boxes = get_all_boxes(pred[ch])\n",
    "            cand_idx = filter_by_intersection(pred_body, cand_boxes)\n",
    "            pred_boxes[ch] = [cand_boxes[i] for i in cand_idx]\n",
    "    return pred_boxes\n",
    "\n",
    "\n",
    "\n",
    "def calc_dice(box, other):\n",
    "    return 2 * box_inter_area(box, other) / (box_area(box) + box_area(other))\n",
    "\n",
    "\n",
    "def calc_inter_over_other_area(box, other):\n",
    "    return box_inter_area(box, other) / box_area(other)\n",
    "\n",
    "\n",
    "def find_closest_box(box, others, min_overlap=0.8, calc_overlap=calc_dice):\n",
    "    best_overlap = 0\n",
    "    best_idx = None\n",
    "    for i, other in enumerate(others):\n",
    "        overlap = calc_overlap(box, other)\n",
    "        if overlap > best_overlap:\n",
    "            best_idx = i\n",
    "            best_overlap = overlap\n",
    "    return best_idx\n",
    "\n",
    "\n",
    "def classify_boxes(pred_boxes, gold_boxes, strictness=0.8, calc_overlap=calc_dice):\n",
    "    true_positive = []\n",
    "    false_positive = []\n",
    "\n",
    "    found_gold = set()\n",
    "    pred_i_to_gold_i = {}\n",
    "    for i, box in enumerate(pred_boxes):\n",
    "        closest_gold_i = find_closest_box(box, gold_boxes, min_overlap=strictness, calc_overlap=calc_overlap)\n",
    "        if not closest_gold_i is None:\n",
    "            pred_i_to_gold_i[i] = closest_gold_i\n",
    "            true_positive.append(i)\n",
    "            found_gold.add(closest_gold_i)\n",
    "        else:\n",
    "            false_positive.append(i)\n",
    "\n",
    "    false_negative = set(range(len(gold_boxes))) - found_gold\n",
    "    return (true_positive, false_positive, false_negative, pred_i_to_gold_i)\n",
    "\n",
    "\n",
    "def calc_precision(tp, fp, fn):\n",
    "    denom = float(tp + fp)\n",
    "    return (tp / denom) if denom > 1e-4 else 0.0\n",
    "\n",
    "\n",
    "def calc_recall(tp, fp, fn):\n",
    "    denom = float(tp + fn)\n",
    "    return (tp / denom) if denom > 1e-4 else 0.0\n",
    "\n",
    "\n",
    "def calc_f1(tp, fp, fn):\n",
    "    p = calc_precision(tp, fp, fn)\n",
    "    r = calc_recall(tp, fp, fn)\n",
    "    denom = p + r\n",
    "    return (2 * p * r / denom) if denom > 1e-4 else 0.0\n",
    "\n",
    "\n",
    "def calc_metric_over_boxes(pred_boxes, gold_boxes, metric, strictness=0.8, calc_overlap=calc_dice):\n",
    "    result = []\n",
    "    for ch in range(len(gold_boxes)):\n",
    "        tp, fp, fn, _ = classify_boxes(pred_boxes.get(ch, []),\n",
    "                                       gold_boxes.get(ch, []),\n",
    "                                       strictness=strictness,\n",
    "                                       calc_overlap=calc_overlap)\n",
    "        tp, fp, fn = len(tp), len(fp), len(fn)\n",
    "        result.append(metric(tp, fp, fn))\n",
    "    return result\n",
    "\n",
    "\n",
    "def box_match_single_image(pred, gold_boxes, metric, strictness=0.8, calc_overlap=calc_dice):\n",
    "    pred_boxes = get_boxes_by_channel_and_filter(pred)\n",
    "    return calc_metric_over_boxes(pred_boxes,\n",
    "                                  gold_boxes,\n",
    "                                  metric,\n",
    "                                  strictness=strictness,\n",
    "                                  calc_overlap=calc_overlap)\n",
    "\n",
    "\n",
    "def box_match_batch(pred, gold_boxes, metric, strictness=0.8, calc_overlap=calc_dice):\n",
    "    if not isinstance(pred, numpy.ndarray):\n",
    "        pred = pred.data.cpu().numpy()\n",
    "    image_metrics = [box_match_single_image(pred[i],\n",
    "                                            gold_boxes[i],\n",
    "                                            metric,\n",
    "                                            strictness=strictness,\n",
    "                                            calc_overlap=calc_overlap)\n",
    "                     for i in range(pred.shape[0])]\n",
    "    return numpy.array(image_metrics).mean(0)\n",
    "\n",
    "\n",
    "def box_match_precision(pred, target, gold_boxes, strictness=0.95):\n",
    "    return box_match_batch(pred, gold_boxes, calc_precision,\n",
    "                           strictness=strictness,\n",
    "                           calc_overlap=calc_dice)\n",
    "\n",
    "\n",
    "def box_match_recall(pred, target, gold_boxes, strictness=0.95):\n",
    "    return box_match_batch(pred, gold_boxes, calc_recall,\n",
    "                           strictness=strictness,\n",
    "                           calc_overlap=calc_inter_over_other_area)\n",
    "\n",
    "\n",
    "def box_match_f1(pred, target, gold_boxes, strictness=0.95):\n",
    "    return box_match_batch(pred, gold_boxes, calc_f1,\n",
    "                           strictness=strictness,\n",
    "                           calc_overlap=calc_inter_over_other_area)\n",
    "\n",
    "\n",
    "def fill_boxes_on_mask_single_image(mask):\n",
    "    boxes_dict = get_boxes_by_channel(mask)\n",
    "    boxes_lst = [boxes_dict[i] for i in range(mask.shape[0])]\n",
    "    return make_mask_for_nn_base(mask.shape[1:], mask.shape[0], boxes_lst)\n",
    "\n",
    "\n",
    "def fill_boxes_on_mask_batch(mask_batch):\n",
    "    result = numpy.zeros_like(mask_batch)\n",
    "    for i in range(mask_batch.shape[0]):\n",
    "        result[i] = fill_boxes_on_mask_single_image(mask_batch[i])\n",
    "    return result\n",
    "\n",
    "# box_match_precision(numpy.tile(numpy.array([[[[1, 1, 1, 1], [1, 1, 1, 1]]]]), (1, 5, 1, 1)),\n",
    "#                     None,\n",
    "#                     [{2 : [[0, 0, 2, 4]]}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:06.402290Z",
     "start_time": "2018-01-16T09:54:05.827343Z"
    }
   },
   "outputs": [],
   "source": [
    "def flatten_cell_dependencies(grid):\n",
    "    full_deps = { i : set(itertools.chain.from_iterable(neighbors.values()))\n",
    "                 for i, neighbors in enumerate(grid) }\n",
    "    for cell_i, neigbors in full_deps.items():\n",
    "        neighs_to_remove = set()\n",
    "        for neigh in neigbors:\n",
    "            if cell_i in full_deps[neigh]:\n",
    "                neighs_to_remove.add(neigh)\n",
    "        neigbors -= neighs_to_remove\n",
    "    return full_deps\n",
    "\n",
    "\n",
    "def filter_boxes_by_real_pixels(boxes, image, max_mean=0.99, min_mean=0.01):\n",
    "    result = []\n",
    "    for box in boxes:\n",
    "        y1, x1, y2, x2 = box\n",
    "        mean = image[y1:y2+1, x1:x2+1].mean()\n",
    "        if mean >= min_mean and mean <= max_mean:\n",
    "            result.append(box)\n",
    "    return result\n",
    "\n",
    "\n",
    "NO_GRID = (None, (), (), (), {})\n",
    "def table_grid_from_intracell_mask(mask, input_image=None):\n",
    "    body_candidates = get_all_boxes(mask[0])\n",
    "    if len(body_candidates) == 0:\n",
    "        return NO_GRID\n",
    "    body = get_biggest_box(body_candidates)\n",
    "    cells = filter_boxes_by_overlap(get_all_boxes(mask[1]))\n",
    "    if len(cells) == 0:\n",
    "        return NO_GRID\n",
    "    if not input_image is None:\n",
    "        cells = filter_boxes_by_real_pixels(cells, input_image)\n",
    "    cells = [cells[i] for i in filter_by_intersection(body, cells)]\n",
    "    grid = make_grid(cells)\n",
    "    full_deps = flatten_cell_dependencies(grid)\n",
    "    cell_idx = list(full_deps.keys()) # toposort.toposort_flatten(full_deps)\n",
    "    intracell_relations = {}\n",
    "    for cur_cell_i in cell_idx:\n",
    "        cur_cell = cells[cur_cell_i]\n",
    "        for direction, dir_neighbors in grid[cur_cell_i].items():\n",
    "            for neigh_cell_i in dir_neighbors:\n",
    "                intracell_relations[(cur_cell_i, neigh_cell_i)] = direction\n",
    "    return (body, cells, grid, cell_idx, intracell_relations)\n",
    "\n",
    "\n",
    "def reconstruct_table_from_grid(body, cells, grid, cell_idx, intracell_space_classes):\n",
    "    cell2row = collections.defaultdict(set)\n",
    "    cell2col = collections.defaultdict(set)\n",
    "\n",
    "    for cur_cell_i in cell_idx:\n",
    "        cur_cell = cells[cur_cell_i]\n",
    "        lower_neighbors = grid[cur_cell_i]['lower']\n",
    "        if len(lower_neighbors) == 0:\n",
    "            cell2col[cur_cell_i] = { len(cell2col) }\n",
    "        right_neighbors = grid[cur_cell_i]['right']\n",
    "        if len(right_neighbors) == 0:\n",
    "            cell2row[cur_cell_i] = { len(cell2row) }\n",
    "\n",
    "        for neigh_cell_i in lower_neighbors + right_neighbors:\n",
    "            intracell_cls_proba = intracell_space_classes[(cur_cell_i, neigh_cell_i)]\n",
    "            if intracell_cls_proba[0] > 0.5:\n",
    "                cell2row[cur_cell_i].update(cell2row[neigh_cell_i])\n",
    "            elif intracell_cls_proba[1] > 0.5:\n",
    "                cell2col[cur_cell_i].update(cell2col[neigh_cell_i])\n",
    "            else:\n",
    "                pass # they are not linked\n",
    "\n",
    "    rows = collections.defaultdict(set)\n",
    "    for cell_i, cell_rows_idx in cell2row.items():\n",
    "        for row_i in cell_rows_idx:\n",
    "            rows[row_i].add(cell_i)\n",
    "\n",
    "    cols = collections.defaultdict(set)\n",
    "    for cell_i, cell_cols_idx in cell2col.items():\n",
    "        for col_i in cell_cols_idx:\n",
    "            cols[col_i].add(cell_i)\n",
    "\n",
    "    row_boxes = [just_box_union([cells[i] for i in row_idx])\n",
    "                 for row_idx in rows.values()]\n",
    "    row_boxes.sort(key=lambda b: (b[0], b[1]))\n",
    "\n",
    "    col_boxes = [just_box_union([cells[i] for i in col_idx])\n",
    "                 for col_idx in cols.values()]\n",
    "    col_boxes.sort(key=lambda b: (b[1], b[0]))\n",
    "    return (body,\n",
    "            cells,\n",
    "            row_boxes,\n",
    "            col_boxes)\n",
    "\n",
    "\n",
    "def reconstruct_table_from_intracell_mask(mask, interbox_classifier):\n",
    "    body, cells, grid, cell_idx, intracell_relations = table_grid_from_intracell_mask(mask)\n",
    "    intracell_space_classes = { k : interbox_classifier([mask], [pair])\n",
    "                               for pair in intracell_relations }\n",
    "    return reconstruct_table_from_grid(body, cells, grid, cell_idx, intracell_space_classes)\n",
    "\n",
    "\n",
    "def boxes_by_channel_from_reconstructed_table(mask):\n",
    "    table_info = reconstruct_table_from_intracell_mask(mask)\n",
    "    if table_info is None:\n",
    "        return {}\n",
    "    body, cells, rows, cols = table_info\n",
    "    result = { 1 : [body] }\n",
    "    result[2] = cells\n",
    "    result[3] = rows\n",
    "    result[4] = cols\n",
    "    return result\n",
    "\n",
    "\n",
    "def table_level_metric_single_image(pred, gold_boxes, metric, strictness=0.5):\n",
    "    pred_boxes = boxes_by_channel_from_reconstructed_table(pred)\n",
    "    return calc_metric_over_boxes(pred_boxes, gold_boxes, calc_precision, strictness=strictness)\n",
    "\n",
    "\n",
    "def table_level_metric_by_batch(pred, gold_boxes, metric, strictness=0.5):\n",
    "    if not isinstance(pred, numpy.ndarray):\n",
    "        pred = pred.data.cpu().numpy()\n",
    "    image_metrics = [table_level_metric_single_image(pred[i],\n",
    "                                                     gold_boxes[i],\n",
    "                                                     metric,\n",
    "                                                     strictness=strictness)\n",
    "                     for i in range(pred.shape[0])]\n",
    "    return numpy.array(image_metrics).mean(0)\n",
    "\n",
    "def table_level_precision(pred, target, gold_boxes, strictness=0.5):\n",
    "    return table_level_metric_by_batch(pred, gold_boxes, calc_precision, strictness=strictness)\n",
    "\n",
    "\n",
    "def table_level_recall(pred, target, gold_boxes, strictness=0.5):\n",
    "    return table_level_metric_by_batch(pred, gold_boxes, calc_recall, strictness=strictness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy\n",
    "\n",
    "$Dice(p, t, w) = 1 - \\frac{ p \\cdot t + 1 }{ p + t + 1 }$\n",
    "\n",
    "$WDice(p, t, w) = 1 - \\frac{ p \\cdot t \\cdot w^{-1} + 1 }{ p + t + p \\cdot (1 - t) \\cdot w + 1 }$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:06.642907Z",
     "start_time": "2018-01-16T09:54:06.403824Z"
    }
   },
   "outputs": [],
   "source": [
    "DICE_SMOOTH = 1.0\n",
    "def dice_coef(pred, target, gold_boxes):\n",
    "    intersection = pred * target\n",
    "    union = pred + target\n",
    "    return ((2. * intersection.sum(3).sum(2).sum(0) + DICE_SMOOTH) /\n",
    "            (union.sum(3).sum(2).sum(0) + DICE_SMOOTH))\n",
    "\n",
    "\n",
    "def px_precision(pred, target, gold_boxes, threshold=0.5):\n",
    "    pred = (pred >= threshold).float()\n",
    "    target = (target >= threshold).float()\n",
    "    tp = (pred * target).float().sum(3).sum(2).sum(0)\n",
    "    fp = ((target - pred) < 0).float().sum(3).sum(2).sum(0)\n",
    "    denum = tp + fp\n",
    "    return tp / (denum + (denum == 0).float())\n",
    "\n",
    "\n",
    "def px_recall(pred, target, gold_boxes, threshold=0.5):\n",
    "    pred = (pred >= threshold).float()\n",
    "    target = (target >= threshold).float()\n",
    "    tp = (pred * target).float().sum(3).sum(2).sum(0)\n",
    "    fn = ((pred - target) < 0).float().sum(3).sum(2).sum(0)\n",
    "    denum = tp + fn\n",
    "    return tp / (denum + (denum == 0).float())\n",
    "\n",
    "\n",
    "def dice_on_boxes(pred, target, gold_boxes):\n",
    "    return dice_coef(fill_boxes_on_mask_batch(pred.data.cpu().numpy()), target.data.cpu().numpy(), gold_boxes)\n",
    "\n",
    "\n",
    "def make_single_channel(f, channel):\n",
    "    def _impl(pred, target):\n",
    "        return f(pred[:, channel:channel+1], target[:, channel:channel+1])\n",
    "    return _impl\n",
    "\n",
    "\n",
    "def make_cpu(f):\n",
    "    def _impl(pred, target):\n",
    "        return f(pred.cpu(), target.cpu())\n",
    "    return _impl\n",
    "\n",
    "\n",
    "def _make_key_from_metric_title(txt):\n",
    "    levels = txt.split('\\n', 1)\n",
    "    if len(levels) < 2:\n",
    "        levels.append(levels[0])\n",
    "    return tuple(levels)\n",
    "\n",
    "def compactify_metrics_table(metrics_df):\n",
    "    data = { _make_key_from_metric_title(c) : '{:.2f}Â±{:.2f}'.format(metrics_df[c]['mean'], metrics_df[c]['std'])\n",
    "            for c in metrics_df.columns }\n",
    "    idx = pandas.MultiIndex.from_tuples(data.keys())\n",
    "    return pandas.Series(data, index=idx).unstack(level=0)\n",
    "\n",
    "\n",
    "def format_metrics_table_md(df):\n",
    "    df = compactify_metrics_table(df.describe())\n",
    "    print(tabulate.tabulate(df, df.columns, tablefmt='pipe'))\n",
    "\n",
    "\n",
    "TRAIN_DET_METRICS = {'d' : (dice_coef, DET_MASK_CHANNELS),\n",
    "                     }\n",
    "VAL_DET_METRICS = {'d' : (dice_coef, DET_MASK_CHANNELS),\n",
    "                   'bd' : (dice_on_boxes, DET_MASK_CHANNELS),\n",
    "                   'px_p' : (px_precision, DET_MASK_CHANNELS),\n",
    "                   'px_r' : (px_recall, DET_MASK_CHANNELS)\n",
    "                   }\n",
    "\n",
    "\n",
    "TRAIN_INT_METRICS = {'d' : (dice_coef, INT_MASK_CHANNELS),\n",
    "#                  'tp' : (table_level_precision, INT_MASK_CHANNELS),\n",
    "#                  'tr' : (table_level_recall, INT_MASK_CHANNELS)\n",
    "                     }\n",
    "VAL_INT_METRICS = {'d' : (dice_coef, INT_MASK_CHANNELS),\n",
    "#                'bp' : (box_match_precision, INT_MASK_CHANNELS),\n",
    "#                'br' : (box_match_recall, INT_MASK_CHANNELS)\n",
    "#                'tp' : (table_level_precision, INT_MASK_CHANNELS),\n",
    "#                'tr' : (table_level_recall, INT_MASK_CHANNELS),\n",
    "                   }\n",
    "TEST_INT_METRICS = {'d' : (dice_coef, INT_MASK_CHANNELS),\n",
    "                    'bp' : (box_match_precision, INT_MASK_CHANNELS),\n",
    "                    'br' : (box_match_recall, INT_MASK_CHANNELS),\n",
    "                    'bf' : (box_match_f1, INT_MASK_CHANNELS),\n",
    "                    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IID Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:06.740884Z",
     "start_time": "2018-01-16T09:54:06.645486Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_metric_data_by_columns(pred, target):\n",
    "    pred = (pred.data.cpu().numpy() > 0.5).astype('int')\n",
    "    target = (target.data.cpu().numpy() > 0.5).astype('int')\n",
    "    tp = numpy.array([(pred[:, col] == target[:, col]).sum()\n",
    "                      for col in range(pred.shape[1])]).astype('float32')\n",
    "    fp = numpy.array([((pred[:, col] - target[:, col]) > 0).sum()\n",
    "                      for col in range(pred.shape[1])]).astype('float32')\n",
    "    fn = numpy.array([((target[:, col] - pred[:, col]) > 0).sum()\n",
    "                      for col in range(pred.shape[1])]).astype('float32')\n",
    "    return tp, fp, fn\n",
    "\n",
    "\n",
    "def precision_by_col(pred, target):\n",
    "    tp, fp, fn = prepare_metric_data_by_columns(pred, target)\n",
    "    return numpy.nan_to_num(tp / (tp + fp))\n",
    "\n",
    "\n",
    "def recall_by_col(pred, target):\n",
    "    tp, fp, fn = prepare_metric_data_by_columns(pred, target)\n",
    "    return numpy.nan_to_num(tp / (tp + fn))\n",
    "\n",
    "\n",
    "def f1_by_col(pred, target):\n",
    "    tp, fp, fn = prepare_metric_data_by_columns(pred, target)\n",
    "    p = tp / (tp + fp)\n",
    "    r = tp / (tp + fn)\n",
    "    return numpy.nan_to_num(2 * p * r / (p + r))\n",
    "\n",
    "\n",
    "CELL_CLASSES = ('same_row', 'same_col')\n",
    "CELL_TRAIN_METRICS = {'f1' : (f1_by_col, CELL_CLASSES),\n",
    "                      'p' : (precision_by_col, CELL_CLASSES),\n",
    "                      'r' : (recall_by_col, CELL_CLASSES) }\n",
    "CELL_VAL_METRICS = {'f1' : (f1_by_col, CELL_CLASSES),\n",
    "                    'p' : (precision_by_col, CELL_CLASSES),\n",
    "                    'r' : (recall_by_col, CELL_CLASSES) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:06.791441Z",
     "start_time": "2018-01-16T09:54:06.742297Z"
    }
   },
   "outputs": [],
   "source": [
    "def dice_score(pred, target):\n",
    "    intersection = pred * target\n",
    "    union = pred + target\n",
    "    return ((2. * intersection.sum() + DICE_SMOOTH) /\n",
    "                (union.sum() + DICE_SMOOTH))\n",
    "\n",
    "def dice_loss(pred, target, weights):\n",
    "    return 1 - dice_score(pred, target)\n",
    "\n",
    "\n",
    "def weighted_dice_loss(pred, target, weights):\n",
    "    # the idea is to lower actual intersection in important areas\n",
    "    inv_weights = 1 / weights\n",
    "    intersection = pred * inv_weights * target\n",
    "    \n",
    "    # the idea is to increase actual predicted values\n",
    "    # where they have to be zero\n",
    "    inv_target = 1 - target\n",
    "    inv_intersection = pred * inv_target * weights\n",
    "    union = pred + target + inv_intersection\n",
    "\n",
    "    return 1 - ((2. * intersection.sum() + DICE_SMOOTH) /\n",
    "                (union.sum() + DICE_SMOOTH))\n",
    "\n",
    "\n",
    "def dice_bce_loss(pred, target, weights):\n",
    "#     return dice_loss(pred, target, weights) + F.binary_cross_entropy(pred, target, weights)\n",
    "    return F.binary_cross_entropy(pred, target, weights) - torch.log(dice_score(pred, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:08.963752Z",
     "start_time": "2018-01-16T09:54:06.793114Z"
    }
   },
   "outputs": [],
   "source": [
    "def mcuda(x, cuda):\n",
    "    return x.cuda() if cuda else x\n",
    "\n",
    "\n",
    "def npten(arr, cuda):\n",
    "    return mcuda(torch.from_numpy(arr), cuda)\n",
    "\n",
    "\n",
    "def npvar(arr, cuda):\n",
    "    if not torch.is_tensor(arr):\n",
    "        arr = torch.from_numpy(arr)\n",
    "    return mcuda(Variable(arr), cuda)\n",
    "\n",
    "\n",
    "def is_module_on_cuda(m):\n",
    "    return next(m.parameters()).is_cuda\n",
    "\n",
    "\n",
    "class LocalAttention(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(LocalAttention, self).__init__()\n",
    "        self.att = nn.Conv2d(in_channels, 1, (1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        unnorm = self.att(x)\n",
    "        norm = F.softmax(unnorm.view(unnorm.size()[0], -1)).view(*unnorm.size())\n",
    "        return x * norm\n",
    "\n",
    "\n",
    "def masked_average(x, masks):\n",
    "    return (x * masks).mean(3).mean(2)\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilations=[1], bn=True, out_act=F.relu):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.bn = nn.BatchNorm2d(in_channels)\n",
    "        assert out_channels % len(dilations) == 0\n",
    "        channels_per_dilation = out_channels // len(dilations)\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(in_channels,\n",
    "                                              channels_per_dilation,\n",
    "                                              kernel_size,\n",
    "                                              padding=dil,\n",
    "                                              dilation=dil)\n",
    "                                    for dil in dilations])\n",
    "        self.out_act = out_act\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn(x)\n",
    "        return self.out_act(torch.cat([conv(x) for conv in self.convs], dim=1))\n",
    "\n",
    "    @property\n",
    "    def receptive_field(self):\n",
    "        dils = numpy.array([c.dilation for c in self.convs])\n",
    "        kernels = numpy.array([c.kernel_size for c in self.convs])\n",
    "        kernels_odd = kernels % 2\n",
    "        return (dils * (kernels - 1) + kernels_odd).max(axis=0)\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, out_channels=TOTAL_INT_CLASSES, first_conv_channels=4, depth=2, out_layers=1, conv_kernel=(3, 3),\n",
    "                 enc_dilations=[1], dec_dilations=[1]):\n",
    "        super(UNet, self).__init__()\n",
    "        self.out_channels = out_channels\n",
    "        enc_channels = [1] + [first_conv_channels * (2**step) for step in range(depth)]\n",
    "        self.encoder = nn.ModuleList([ConvBlock(enc_channels[i],\n",
    "                                                enc_channels[i+1],\n",
    "                                                conv_kernel,\n",
    "                                                dilations=enc_dilations)\n",
    "                                      for i in range(depth)])\n",
    "        bottleneck_channels = enc_channels[-1] * 2\n",
    "        self.bottleneck = ConvBlock(enc_channels[-1],\n",
    "                                    bottleneck_channels,\n",
    "                                    conv_kernel,\n",
    "                                    dilations=enc_dilations)\n",
    "        dec_channels = [bottleneck_channels] + enc_channels[:0:-1]\n",
    "\n",
    "        self.dec_conv = nn.ModuleList([ConvBlock(dec_channels[i],\n",
    "                                                 dec_channels[i+1],\n",
    "                                                 conv_kernel,\n",
    "                                                 dilations=dec_dilations)\n",
    "                                      for i in range(depth)])\n",
    "        self.dec_deconv = nn.ModuleList([nn.ConvTranspose2d(dec_channels[i],\n",
    "                                                            dec_channels[i+1],\n",
    "                                                            (2, 2),\n",
    "                                                            stride=2)\n",
    "                                         for i in range(depth)])\n",
    "        self.out_layers = nn.ModuleList([ConvBlock(dec_channels[-1],\n",
    "                                                   dec_channels[-1],\n",
    "                                                   conv_kernel,\n",
    "                                                   dilations=dec_dilations)])\n",
    "        self.out_conv = nn.Conv2d(dec_channels[-1],\n",
    "                                  out_channels,\n",
    "                                  (1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc_conv_outs = []\n",
    "        enc_pool_outs = [x]\n",
    "        for enc_conv in self.encoder:\n",
    "            cur_conv_out = enc_conv(enc_pool_outs[-1])\n",
    "            enc_conv_outs.append(cur_conv_out)\n",
    "            cur_pool_out = F.max_pool2d(cur_conv_out, (2, 2))\n",
    "            enc_pool_outs.append(cur_pool_out)\n",
    "\n",
    "        cur_out = self.bottleneck(enc_pool_outs[-1])\n",
    "\n",
    "        for dec_step, (dec_conv, dec_deconv) in enumerate(zip(self.dec_conv, self.dec_deconv)):\n",
    "            up = dec_deconv(cur_out)\n",
    "            cur_out = torch.cat([up, enc_conv_outs[-dec_step-1]], dim=1)\n",
    "            cur_out = dec_conv(cur_out)\n",
    "\n",
    "        for out_layer in self.out_layers:\n",
    "            cur_out = F.relu(out_layer(cur_out))\n",
    "\n",
    "        return F.sigmoid(self.out_conv(cur_out))\n",
    "\n",
    "\n",
    "class SimpleConvFCN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, conv_layers=1, conv_kernel=(3, 3), dilations=[1, 2, 4], conv_block_class=ConvBlock):\n",
    "        super(SimpleConvFCN, self).__init__()\n",
    "        conv_channels = [in_channels] + [len(dilations) * (2 ** (i + 1)) for i in range(conv_layers)]\n",
    "        print('conv channels', conv_channels)\n",
    "        self.convs = nn.ModuleList([conv_block_class(conv_channels[i],\n",
    "                                                     conv_channels[i+1],\n",
    "                                                     conv_kernel,\n",
    "                                                     dilations=dilations)\n",
    "                                    for i in range(conv_layers)])\n",
    "        self.output = nn.Linear(conv_channels[-1], out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for conv in self.convs:\n",
    "            x = conv(x)\n",
    "        x = self.output(x.transpose(1, -1)).transpose(1, -1)\n",
    "        return F.sigmoid(x)\n",
    "\n",
    "    @property\n",
    "    def receptive_field(self):\n",
    "        conv_fields = [c.receptive_field for c in self.convs]\n",
    "        result = conv_fields[0]\n",
    "        for i in range(1, len(conv_fields)):\n",
    "            result += numpy.clip(conv_fields[i] // 2, 1, None)\n",
    "        return result\n",
    "\n",
    "\n",
    "class DenseNetWrapper(nn.Module):\n",
    "    def __init__(self, *blocks):\n",
    "        super(DenseNetWrapper, self).__init__()\n",
    "        self.blocks = nn.ModuleList(list(blocks))\n",
    "\n",
    "    def forward(self, x):\n",
    "        last_out = x\n",
    "        for block in self.blocks:\n",
    "            last_out = block(x)\n",
    "            x = torch.cat([x, last_out], 1)\n",
    "        return last_out\n",
    "\n",
    "\n",
    "class Linear1dMixture(nn.Module):\n",
    "    def __init__(self, n_sources, n_channels):\n",
    "        super(Linear1dMixture, self).__init__()\n",
    "        self.weights = nn.ModuleList([nn.Linear(n_sources, 1, bias=False)\n",
    "                                      for _ in range(n_channels)])\n",
    "        self.n_sources = n_sources\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Expects tensor of shape (n_sources, B, n_channels, *)\n",
    "        \"\"\"\n",
    "        src_size = tuple(x.size())\n",
    "        # transpose to (n_channels, B, *, n_sources)\n",
    "        forward_axis_order = (2, 1) + tuple(range(3, len(src_size))) + (0,)\n",
    "        x = x.permute(*forward_axis_order)\n",
    "        weighted_sums = [channel_weights(x[i])\n",
    "                         for i, channel_weights\n",
    "                         in enumerate(self.weights)]\n",
    "        print('weighted_sums', weighted_sums[0].size())\n",
    "        1 / 0\n",
    "        return torch.cat(weighted_sums) / n_sources\n",
    "        \n",
    "\n",
    "\n",
    "class DenseStack(nn.Module):\n",
    "    def __init__(self, *blocks):\n",
    "        super(DenseStack, self).__init__()\n",
    "        self.blocks = nn.ModuleList(list(blocks))\n",
    "\n",
    "    def forward(self, x):\n",
    "        outs = []\n",
    "        for block in self.blocks:\n",
    "            last_out = block(x)\n",
    "            outs.append(last_out)\n",
    "            x = torch.cat([x, last_out], 1)\n",
    "        return torch.cat([t.unsqueeze(2) for t in outs]).mean(0)\n",
    "\n",
    "\n",
    "class DenseMixture(nn.Module):\n",
    "    def __init__(self, out_channels, *blocks):\n",
    "        super(DenseMixture, self).__init__()\n",
    "        self.blocks = nn.ModuleList(list(blocks))\n",
    "        self.mix = Linear1dMixture(len(self.blocks), out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outs = []\n",
    "        for block in self.blocks:\n",
    "            last_out = block(x)\n",
    "            outs.append(last_out)\n",
    "            x = torch.cat([x, last_out], 1)\n",
    "        return self.mix(torch.cat([t.unsqueeze(0) for t in outs]))\n",
    "\n",
    "\n",
    "class StackedUNet1(DenseStack):\n",
    "    def __init__(self, out_channels=TOTAL_INT_CLASSES):\n",
    "        super(StackedUNet1, self).__init__(\n",
    "            UNet(out_channels=out_channels,\n",
    "                 first_conv_channels=6,\n",
    "                 depth=4,\n",
    "                 enc_dilations=[1, 2, 4, 8, 16, 32]),\n",
    "            SimpleConvFCN(out_channels+1,\n",
    "                          out_channels)\n",
    "        )\n",
    "\n",
    "\n",
    "class DenseNet1(DenseNetWrapper):\n",
    "    def __init__(self, out_channels=TOTAL_INT_CLASSES):\n",
    "        super(DenseNet1, self).__init__(\n",
    "            UNet(out_channels=out_channels,\n",
    "                 first_conv_channels=6,\n",
    "                 depth=4,\n",
    "                 enc_dilations=[1, 2, 4, 8, 16, 32]),\n",
    "            SimpleConvFCN(out_channels+1,\n",
    "                          out_channels,\n",
    "                          dilations=[1, 2, 4, 8, 16, 32]),\n",
    "            SimpleConvFCN(out_channels*2+1,\n",
    "                          out_channels,\n",
    "                          conv_layers=0)\n",
    "        )\n",
    "\n",
    "\n",
    "def run_network(network, generator, num_batches, criterion=dice_bce_loss, optimizer=None, metrics=TRAIN_INT_METRICS, cuda=True):\n",
    "    metric_values = []\n",
    "    gen_iter = iter(generator)\n",
    "    for _ in tqdm.tqdm(range(num_batches)):\n",
    "        image_ids, images, mask, loss_weights, boxes = next(gen_iter)\n",
    "        images_var = npvar(images, cuda)\n",
    "        mask_var = npvar(mask, cuda)\n",
    "        loss_weights_var = npvar(loss_weights, cuda)\n",
    "        boxes = [pickle.loads(b) for b in boxes]\n",
    "\n",
    "        cur_out = network(images_var)\n",
    "\n",
    "        loss = criterion(cur_out, mask_var, loss_weights_var)\n",
    "\n",
    "        if optimizer:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm(network.parameters(), 10)\n",
    "            optimizer.step()\n",
    "\n",
    "        cur_metrics = { 'loss' : loss.data[0] }\n",
    "        for name, (func, elem_names) in metrics.items():\n",
    "            metric_value = func(cur_out, mask_var, boxes)\n",
    "            if not isinstance(metric_value, (list, numpy.ndarray)):\n",
    "                metric_value = metric_value.cpu().data.numpy()\n",
    "            cur_metrics.update(('\\n'.join((name, n)), v) for n, v in zip(elem_names, metric_value) if n)\n",
    "        metric_values.append(cur_metrics)\n",
    "    return metric_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured End-to-End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:10.308076Z",
     "start_time": "2018-01-16T09:54:08.966805Z"
    }
   },
   "outputs": [],
   "source": [
    "def bbox_shift(box, y, x):\n",
    "    y1, x1, y2, x2 = box\n",
    "    return (y1 + y, x1 + x, y2 + y, x2 + x)\n",
    "\n",
    "\n",
    "class ConvFCNClassifier(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, conv_layers=1, conv_kernel=(3, 3), dilations=[1, 2, 4], conv_block_class=ConvBlock):\n",
    "        super(ConvFCNClassifier, self).__init__()\n",
    "        conv_channels = [in_channels] + [len(dilations) * (2 ** (i + 1)) for i in range(conv_layers)]\n",
    "        self.convs = nn.ModuleList([conv_block_class(conv_channels[i],\n",
    "                                                     conv_channels[i+1],\n",
    "                                                     conv_kernel,\n",
    "                                                     dilations=dilations)\n",
    "                                    for i in range(conv_layers)])\n",
    "        self.attention = LocalAttention(conv_channels[-1])\n",
    "        self.output = nn.Linear(conv_channels[-1], out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for conv in self.convs:\n",
    "            x = conv(x)\n",
    "        x = self.attention(x).mean(-1).mean(-1)\n",
    "        return F.sigmoid(self.output(x))\n",
    "\n",
    "    @property\n",
    "    def receptive_field(self):\n",
    "        conv_fields = [c.receptive_field for c in self.convs]\n",
    "        result = conv_fields[0]\n",
    "        for i in range(1, len(conv_fields)):\n",
    "            result += numpy.clip(conv_fields[i] // 2, 1, None)\n",
    "        return result\n",
    "\n",
    "\n",
    "class CellRelConvFCNClassifier(nn.Module):\n",
    "    def __init__(self, base_classifier):\n",
    "        super(CellRelConvAttention, self).__init__()\n",
    "        self.base_classifier = base_classifier\n",
    "\n",
    "    def forward(self, table_masks, relations_by_image):\n",
    "        out = self.make_batch(table_masks, relations_by_image)\n",
    "        if out is None:\n",
    "            return mcuda(Variable(torch.DoubleTensor()), table_masks.data.is_cuda)\n",
    "        return self.base_classifier(out)\n",
    "\n",
    "    @staticmethod\n",
    "    def make_batch(table_masks, relations_by_image):\n",
    "        assert table_masks.size()[0] == len(relations_by_image)\n",
    "        samples_num = sum(len(img_rels) for img_rels in relations_by_image)\n",
    "        if samples_num == 0:\n",
    "            return None\n",
    "\n",
    "        rel_boxes = [get_intercell_line_bbox(cell1, cell2, direction)\n",
    "                     for img_rels in relations_by_image\n",
    "                     for (cell1, cell2, direction) in img_rels]\n",
    "        max_rel_width = max(x2 - x1 for _, x1, _, x2 in rel_boxes) + 1\n",
    "        max_rel_height = max(y2 - y1 for y1, _, y2, _ in rel_boxes) + 1\n",
    "\n",
    "        table_masks_for_samples = npvar(numpy.zeros((len(rel_boxes),\n",
    "                                                     table_masks.size()[1],\n",
    "                                                     max_rel_height,\n",
    "                                                     max_rel_width),\n",
    "                                                    dtype='float32'),\n",
    "                                        table_masks.data.is_cuda)\n",
    "        relation_masks_for_samples = numpy.zeros((table_masks_for_samples.size()[0],\n",
    "                                                  max_rel_height,\n",
    "                                                  max_rel_width),\n",
    "                                                 dtype='float32')\n",
    "        sample_i = 0\n",
    "        for img_i, img_rels in enumerate(relations_by_image):\n",
    "            for cell1, cell2, direction in img_rels:\n",
    "                by1, bx1, by2, bx2 = rel_boxes[sample_i]\n",
    "                cur_table_mask = table_masks[img_i, :, by1:by2+1, bx1:bx2+1]\n",
    "                mask_size = cur_table_mask.size()\n",
    "                table_masks_for_samples[sample_i, :, :mask_size[1], :mask_size[2]] = cur_table_mask\n",
    "\n",
    "                draw_intercell_mask(relation_masks_for_samples[sample_i],\n",
    "                                    bbox_shift(cell1, -by1, -bx1),\n",
    "                                    bbox_shift(cell2, -by1, -bx1),\n",
    "                                    direction)\n",
    "                sample_i += 1\n",
    "\n",
    "        out = torch.cat([table_masks_for_samples,\n",
    "                         npvar(relation_masks_for_samples, table_masks.data.is_cuda).unsqueeze(1)],\n",
    "                        dim=1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class CellRelationsClassifier(nn.Module):\n",
    "    def __init__(self, base_classifier, return_grids=False):\n",
    "        super(CellRelationsClassifier, self).__init__()\n",
    "        self.base_classifier = base_classifier\n",
    "        self.return_grids = return_grids\n",
    "\n",
    "    def forward(self, simple_mask):\n",
    "        simple_mask_np = simple_mask.data.cpu().numpy()\n",
    "        grids = list(map(table_grid_from_intracell_mask, simple_mask_np))\n",
    "        intracell_relation_by_image = [[(cells[i1], cells[i2], direction)\n",
    "                                        for (i1, i2), direction in rels.items()]\n",
    "                                       for body, cells, grid, cell_idx, rels in grids]\n",
    "        intracell_classes_flat = self.base_classifier(simple_mask, intracell_relation_by_image)\n",
    "        if self.return_grids:\n",
    "            return intracell_classes_flat, grids\n",
    "        else:\n",
    "            return intracell_classes_flat\n",
    "\n",
    "\n",
    "class TableSegmenter(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TableSegmenter, self).__init__()\n",
    "        self.unet = UNet(first_conv_channels=12,\n",
    "                         depth=2,\n",
    "                         enc_dilations=[1, 2, 4, 8])\n",
    "        self.intra_cls = CellRelationsClassifier(CellRelConvAttention(self.unet.out_channels, 2, conv_layers=1),\n",
    "                                                 return_grids=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        simple_mask = self.unet(x)\n",
    "        intracell_classes_flat, grids = self.intra_cls(simple_mask, intracell_relation_by_image)\n",
    "        return simple_mask, grids, intracell_classes_flat\n",
    "\n",
    "\n",
    "STRUCT_SAME_ROWS_I = 0\n",
    "STRUCT_SAME_COLS_I = 1\n",
    "def make_structured_gold_single_image(gold_boxes, grid_info, cell_strictness=0.5):\n",
    "    body, pred_cells, grid, cell_idx, rels = grid_info\n",
    "    gold_cells = gold_boxes[1]\n",
    "    gold_rows = gold_boxes[2]\n",
    "    gold_cols = gold_boxes[3]\n",
    "    gold_cell2rows = group_by_intersection(gold_rows, gold_cells)\n",
    "    gold_cell2cols = group_by_intersection(gold_cols, gold_cells)\n",
    "    \n",
    "    cell_tp, cell_fp, cell_fn, pred_cell_to_gold = classify_boxes(pred_cells,\n",
    "                                                                  gold_cells,\n",
    "                                                                  strictness=cell_strictness)\n",
    "    gold_intracell_classes = numpy.zeros((len(rels), 2),\n",
    "                                         dtype='float32')\n",
    "    for row_i, (pred_i1, pred_i2) in enumerate(rels.keys()):\n",
    "        gold_i1 = pred_cell_to_gold.get(pred_i1, None)\n",
    "        gold_i2 = pred_cell_to_gold.get(pred_i2, None)\n",
    "        if gold_i1 is None or gold_i2 is None:\n",
    "            continue\n",
    "        same_rows = gold_cell2rows[gold_i1] <= gold_cell2rows[gold_i2]\n",
    "        if same_rows:\n",
    "            gold_intracell_classes[row_i, STRUCT_SAME_ROWS_I] = 1\n",
    "        same_cols = gold_cell2cols[gold_i1] <= gold_cell2cols[gold_i2]\n",
    "        if same_cols:\n",
    "            gold_intracell_classes[row_i, STRUCT_SAME_COLS_I] = 1\n",
    "    return gold_intracell_classes\n",
    "\n",
    "\n",
    "def make_structured_gold_batch(gold_boxes_by_image, grid_info_by_image, cell_strictness=0.5):\n",
    "    result = [make_structured_gold_single_image(gold_boxes, grid_info)\n",
    "              for gold_boxes, grid_info in zip(gold_boxes_by_image, grid_info_by_image)]\n",
    "    return numpy.concatenate(result)\n",
    "\n",
    "\n",
    "def run_network_structured(network, generator, num_batches,\n",
    "                           raw_criterion=dice_loss, structured_criterion=F.binary_cross_entropy,\n",
    "                           optimizer=None, metrics=TRAIN_INT_METRICS, cuda=True):\n",
    "    metric_values = []\n",
    "    gen_iter = iter(generator)\n",
    "    for _ in tqdm.tqdm(range(num_batches)):\n",
    "        image_ids, images, mask, loss_weights, boxes = next(gen_iter)\n",
    "        images_var = npvar(images, cuda)\n",
    "        mask_var = npvar(mask, cuda)\n",
    "        loss_weights_var = npvar(loss_weights, cuda)\n",
    "        boxes = [pickle.loads(b) for b in boxes]\n",
    "\n",
    "        cur_out, pred_grids, pred_intracell_classes = network(images_var)\n",
    "\n",
    "        raw_loss = raw_criterion(cur_out, mask_var, loss_weights_var)\n",
    "        gold_intracell_classes = make_structured_gold_batch(boxes, pred_grids)\n",
    "        if gold_intracell_classes.shape[0] > 0:\n",
    "            gold_intracell_classes = npvar(gold_intracell_classes,\n",
    "                                           pred_intracell_classes.data.is_cuda)\n",
    "            structured_loss = structured_criterion(pred_intracell_classes,\n",
    "                                                   gold_intracell_classes)\n",
    "        else:\n",
    "            structured_loss = npvar(numpy.zeros(1).astype('float32'), raw_loss.data.is_cuda)\n",
    "        full_loss = raw_loss.contiguous() + structured_loss.contiguous()\n",
    "\n",
    "        if optimizer:\n",
    "            optimizer.zero_grad()\n",
    "            full_loss.backward()\n",
    "            nn.utils.clip_grad_norm(network.parameters(), 10)\n",
    "            optimizer.step()\n",
    "\n",
    "        cur_metrics = {'raw_loss' : raw_loss.data[0],\n",
    "                       'structured_loss' : structured_loss.data[0],\n",
    "                       'full_loss' : full_loss.data[0] }\n",
    "        for name, (func, elem_names) in metrics.items():\n",
    "            metric_value = func(cur_out, mask_var, boxes)\n",
    "            if not isinstance(metric_value, (list, numpy.ndarray)):\n",
    "                metric_value = metric_value.cpu().data.numpy()\n",
    "            cur_metrics.update(('\\n'.join((name, n)), v) for n, v in zip(elem_names, metric_value) if n)\n",
    "        metric_values.append(cur_metrics)\n",
    "    return metric_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured Two-step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:10.528336Z",
     "start_time": "2018-01-16T09:54:10.309541Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad_and_concat(tensors):\n",
    "    max_height = max(t.size()[2] for t in tensors)\n",
    "    max_width = max(t.size()[3] for t in tensors)\n",
    "    return torch.cat([F.pad(t, (0, max_width-t.size()[3], 0, max_height-t.size()[2]))\n",
    "                      for t in tensors])\n",
    "\n",
    "\n",
    "def structured_two_step_datagen(orig_datagen, model=None, cuda=True, batch_size=32, tamper_channels=[]):\n",
    "    batch_input = []\n",
    "    batch_output = []\n",
    "    out_i = 0\n",
    "    for image_ids, in_img, mask, loss_weights, boxes_aug in orig_datagen:\n",
    "        if model:\n",
    "            mask = model(npvar(in_img, cuda)).data\n",
    "        mask = mask.cpu().numpy()\n",
    "        for table_mask, gold_boxes in zip(mask, boxes_aug):\n",
    "            gold_boxes = pickle.loads(gold_boxes)\n",
    "\n",
    "            body, cells, grid, cell_idx, rels = table_grid_from_intracell_mask(table_mask)\n",
    "            intracell_relation_keys = list(rels.keys())\n",
    "\n",
    "            in_i = 0\n",
    "            while in_i < len(intracell_relation_keys):\n",
    "                step = min(batch_size - out_i, len(intracell_relation_keys) - in_i)\n",
    "\n",
    "                batch_relation_keys = intracell_relation_keys[in_i:in_i+step]\n",
    "                batch_relations = [(cells[i1], cells[i2], rels[(i1, i2)])\n",
    "                                   for (i1, i2) in batch_relation_keys]\n",
    "                batch_input.append(CellRelConvFCNClassifier.make_batch(npvar(table_mask, cuda).unsqueeze(0),\n",
    "                                                                       [batch_relations]))\n",
    "                gold_cls = make_structured_gold_single_image(gold_boxes,\n",
    "                                                             (body, cells, grid, cell_idx,\n",
    "                                                              { k : rels[k] for k in batch_relation_keys }))\n",
    "                batch_output.append(npvar(gold_cls, cuda))\n",
    "                in_i += step\n",
    "                out_i += step\n",
    "\n",
    "                if out_i >= batch_size:\n",
    "                    out_input = pad_and_concat(batch_input)\n",
    "                    if tamper_channels:\n",
    "                        out_input[:, tamper_channels] = 0\n",
    "                    yield out_input, torch.cat(batch_output)\n",
    "                    batch_input = []\n",
    "                    batch_output = []\n",
    "                    out_i = 0\n",
    "\n",
    "\n",
    "def run_cell_network(network, generator, num_batches, criterion=F.binary_cross_entropy, optimizer=None, metrics=CELL_TRAIN_METRICS):\n",
    "    metric_values = []\n",
    "    gen_iter = iter(generator)\n",
    "    for _ in tqdm.tqdm(range(num_batches)):\n",
    "        inp, gold = next(gen_iter)\n",
    "\n",
    "        pred = network(inp)\n",
    "\n",
    "        loss = criterion(pred, gold)\n",
    "\n",
    "        if optimizer:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm(network.parameters(), 10)\n",
    "            optimizer.step()\n",
    "\n",
    "        cur_metrics = { 'loss' : loss.data[0] }\n",
    "        for name, (func, elem_names) in metrics.items():\n",
    "            metric_value = func(pred, gold)\n",
    "            if not isinstance(metric_value, (list, numpy.ndarray)):\n",
    "                metric_value = metric_value.cpu().data.numpy()\n",
    "            cur_metrics.update(('\\n'.join((name, n)), v) for n, v in zip(elem_names, metric_value) if n)\n",
    "        metric_values.append(cur_metrics)\n",
    "    return metric_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:10.904818Z",
     "start_time": "2018-01-16T09:54:10.529727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3d4161c208>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3d41609240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clean_pytorch_dataloadergen(gen_iter):\n",
    "    try:\n",
    "        gen_iter._shutdown_workers()\n",
    "        for _ in range(100):\n",
    "            gen_iter.index_queue.put(None)\n",
    "#         while not gen_iter.data_queue.empty():\n",
    "#             b = gen_iter.data_queue.get()\n",
    "        for w in gen_iter.workers:\n",
    "            w.terminate()\n",
    "        del gen_iter\n",
    "    except ex:\n",
    "        print(ex)\n",
    "\n",
    "\n",
    "def const_lr(epoch, value=1e-3):\n",
    "    return value\n",
    "\n",
    "\n",
    "def step_annealed_lr(epoch, start=1e-3, step_epochs=15, decay_factor=0.5):\n",
    "    lr_factor = decay_factor ** (epoch // step_epochs)\n",
    "    return start * lr_factor\n",
    "\n",
    "\n",
    "def sin_annealed_lr(epoch, freq=0.6, start=1e-3, sin_amp=5e-4, amp_decay_factor=0.97, mean_decay_factor=0.94, min_lr=1e-5):\n",
    "    base = (numpy.sin(epoch * freq) + 1) * sin_amp * (amp_decay_factor ** epoch)\n",
    "    mean = start * (mean_decay_factor ** epoch)\n",
    "    return numpy.clip(base + mean, min_lr, None)\n",
    "\n",
    "\n",
    "lr_vis_x = numpy.arange(0, 60, 1)\n",
    "pandas.DataFrame(data=dict(const=const_lr(lr_vis_x),\n",
    "                           step=step_annealed_lr(lr_vis_x),\n",
    "                           sin=sin_annealed_lr(lr_vis_x))).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detect tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:10.948842Z",
     "start_time": "2018-01-16T09:54:10.907734Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_gen = None\n",
    "# val_gen = None\n",
    "\n",
    "# EPOCHS_NUM = 30\n",
    "# BATCH_SIZE = 10\n",
    "# PART_PER_EPOCH = 0.5\n",
    "# BATCHES_PER_EPOCH_TRAIN = int(len(train_det_image_ids) * PART_PER_EPOCH // BATCH_SIZE)\n",
    "# BATCHES_PER_EPOCH_VAL = int(len(val_det_image_ids) * PART_PER_EPOCH // BATCH_SIZE)\n",
    "\n",
    "\n",
    "# # det_net = StackedUNet1()\n",
    "\n",
    "# det_net = UNet(out_channels=TOTAL_DET_CLASSES,\n",
    "#                first_conv_channels=6,\n",
    "#                depth=4,\n",
    "#                enc_dilations=[1, 2, 4, 8, 16, 32]).cuda()\n",
    "# LOSS = dice_bce_loss\n",
    "# # LOSS = dice_loss\n",
    "# # LOSS = weighted_dice_loss\n",
    "\n",
    "# LR_SCHEDULE = step_annealed_lr\n",
    "# # LR_SCHEDULE = sin_annealed_lr\n",
    "\n",
    "# det_augmenter = imgaug_pipeline\n",
    "# # det_augmenter = fake_imgaug_pipeline\n",
    "\n",
    "# print('total parameters', sum(numpy.product(p.size()) for p in det_net.parameters()))\n",
    "\n",
    "# train_metrics = []\n",
    "# val_metrics = []\n",
    "# for epoch in range(EPOCHS_NUM):\n",
    "#     try:\n",
    "#         train_gen = iter(DataLoader(SegmDataset(train_det_image_ids,\n",
    "#                                                 det_augmenter,\n",
    "#                                                 prepare_det_batch),\n",
    "#                                     batch_size=BATCH_SIZE,\n",
    "#                                     shuffle=True,\n",
    "#                                     num_workers=4))\n",
    "#         val_gen = iter(DataLoader(SegmDataset(val_det_image_ids,\n",
    "#                                               det_augmenter,\n",
    "#                                               prepare_det_batch),\n",
    "#                                   batch_size=BATCH_SIZE,\n",
    "#                                   shuffle=True,\n",
    "#                                   num_workers=2))\n",
    "#         print('epoch', epoch)\n",
    "\n",
    "#         lr = LR_SCHEDULE(epoch)\n",
    "#         print('lr', lr)\n",
    "#         optimizer = Adam(det_net.parameters(), lr=lr)\n",
    "\n",
    "#         det_net.train()\n",
    "#         cur_train_metrics = run_network(det_net, train_gen, BATCHES_PER_EPOCH_TRAIN,\n",
    "#                                         criterion=LOSS,\n",
    "#                                         metrics=TRAIN_DET_METRICS,\n",
    "#                                         optimizer=optimizer)\n",
    "#         train_metrics.extend(cur_train_metrics)\n",
    "#         display(pandas.DataFrame(cur_train_metrics).describe().loc[['mean', 'std']])\n",
    "\n",
    "#         det_net.eval()\n",
    "#         cur_val_metrics = run_network(det_net, val_gen, BATCHES_PER_EPOCH_VAL,\n",
    "#                                       criterion=LOSS,\n",
    "#                                       metrics=VAL_DET_METRICS)\n",
    "#         val_metrics.extend(cur_val_metrics)\n",
    "#         display(pandas.DataFrame(cur_val_metrics).describe().loc[['mean', 'std']])\n",
    "#     finally:\n",
    "#         if train_gen:\n",
    "#             clean_pytorch_dataloadergen(train_gen)\n",
    "#         if val_gen:\n",
    "#             clean_pytorch_dataloadergen(val_gen)\n",
    "\n",
    "#         gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segment structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:11.250481Z",
     "start_time": "2018-01-16T09:54:10.950218Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_gen = None\n",
    "# val_gen = None\n",
    "\n",
    "# EPOCHS_NUM = 40\n",
    "# BATCH_SIZE = 16\n",
    "# PART_PER_EPOCH = 0.5\n",
    "# BATCHES_PER_EPOCH_TRAIN = int(len(train_int_image_ids) * PART_PER_EPOCH // BATCH_SIZE)\n",
    "# BATCHES_PER_EPOCH_VAL = int(len(val_int_image_ids) * PART_PER_EPOCH // BATCH_SIZE)\n",
    "\n",
    "\n",
    "# # net = StackedUNet1().cuda()\n",
    "# # net = DenseNet1().cuda()\n",
    "\n",
    "# net = UNet(first_conv_channels=6,\n",
    "#            depth=4,\n",
    "#            enc_dilations=[1, 2, 4, 8, 16, 32]).cuda()\n",
    "# LOSS = dice_bce_loss\n",
    "# # LOSS = dice_loss\n",
    "# # LOSS = weighted_dice_loss\n",
    "\n",
    "# LR_SCHEDULE = step_annealed_lr\n",
    "# # LR_SCHEDULE = sin_annealed_lr\n",
    "\n",
    "# int_augmenter = imgaug_pipeline\n",
    "# # int_augmenter = fake_imgaug_pipeline\n",
    "\n",
    "# print('total parameters', sum(numpy.product(p.size()) for p in net.parameters()))\n",
    "\n",
    "# train_metrics = []\n",
    "# val_metrics = []\n",
    "# for epoch in range(EPOCHS_NUM):\n",
    "#     try:\n",
    "#         train_gen = iter(DataLoader(SegmDataset(train_int_image_ids,\n",
    "#                                                 int_augmenter,\n",
    "#                                                 prepare_int_batch),\n",
    "#                                     batch_size=BATCH_SIZE,\n",
    "#                                     shuffle=True,\n",
    "#                                     num_workers=4))\n",
    "#         val_gen = iter(DataLoader(SegmDataset(val_int_image_ids,\n",
    "#                                               int_augmenter,\n",
    "#                                               prepare_int_batch),\n",
    "#                                   batch_size=BATCH_SIZE,\n",
    "#                                   shuffle=True,\n",
    "#                                   num_workers=2))\n",
    "#         print('epoch', epoch)\n",
    "\n",
    "#         lr = LR_SCHEDULE(epoch)\n",
    "#         print('lr', lr)\n",
    "#         optimizer = Adam(net.parameters(), lr=lr)\n",
    "\n",
    "#         net.train()\n",
    "#         cur_train_metrics = run_network(net, train_gen, BATCHES_PER_EPOCH_TRAIN,\n",
    "#                                         criterion=LOSS,\n",
    "#                                         metrics=TRAIN_INT_METRICS,\n",
    "#                                         optimizer=optimizer)\n",
    "#         train_metrics.extend(cur_train_metrics)\n",
    "#         display(pandas.DataFrame(cur_train_metrics).describe().loc[['mean', 'std']])\n",
    "\n",
    "#         net.eval()\n",
    "#         cur_val_metrics = run_network(net, val_gen, BATCHES_PER_EPOCH_VAL,\n",
    "#                                       criterion=LOSS,\n",
    "#                                       metrics=VAL_INT_METRICS)\n",
    "#         val_metrics.extend(cur_val_metrics)\n",
    "#         display(pandas.DataFrame(cur_val_metrics).describe().loc[['mean', 'std']])\n",
    "#     finally:\n",
    "#         if train_gen:\n",
    "#             clean_pytorch_dataloadergen(train_gen)\n",
    "#         if val_gen:\n",
    "#             clean_pytorch_dataloadergen(val_gen)\n",
    "\n",
    "#         gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structured End-to-End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:11.296660Z",
     "start_time": "2018-01-16T09:54:11.254261Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_gen = None\n",
    "# val_gen = None\n",
    "\n",
    "# EPOCHS_NUM = 30\n",
    "# BATCH_SIZE = 1\n",
    "# PART_PER_EPOCH = 0.5\n",
    "# BATCHES_PER_EPOCH_TRAIN = int(len(train_image_ids) * PART_PER_EPOCH // BATCH_SIZE)\n",
    "# BATCHES_PER_EPOCH_VAL = int(len(val_image_ids) * PART_PER_EPOCH // BATCH_SIZE)\n",
    "\n",
    "# net = TableSegmenter().cuda()\n",
    "# RAW_LOSS = dice_loss\n",
    "# print('total parameters', sum(numpy.product(p.size()) for p in net.parameters()))\n",
    "\n",
    "# train_metrics = []\n",
    "# val_metrics = []\n",
    "# for epoch in range(EPOCHS_NUM):\n",
    "#     try:\n",
    "#         train_gen = iter(DataLoader(SegmDataset(train_image_ids, imgaug_pipeline, prepare_int_batch),\n",
    "#                                     batch_size=BATCH_SIZE,\n",
    "#                                     shuffle=True,\n",
    "#                                     num_workers=4))\n",
    "#         val_gen = iter(DataLoader(SegmDataset(val_image_ids, imgaug_pipeline, prepare_int_batch),\n",
    "#                                   batch_size=BATCH_SIZE,\n",
    "#                                   shuffle=True,\n",
    "#                                   num_workers=2))\n",
    "#         print('epoch', epoch)\n",
    "\n",
    "#         lr_factor = 0.5 ** (epoch // 20)\n",
    "#         lr = 1e-3 * lr_factor\n",
    "#         print('lr', lr)\n",
    "#         optimizer = Adam(net.parameters(), lr=lr)\n",
    "\n",
    "#         net.train()\n",
    "#         cur_train_metrics = run_network_structured(net, train_gen,\n",
    "#                                                    BATCHES_PER_EPOCH_TRAIN,\n",
    "#                                                    raw_criterion=RAW_LOSS,\n",
    "#                                                    metrics=TRAIN_METRICS,\n",
    "#                                                    optimizer=optimizer)\n",
    "#         train_metrics.extend(cur_train_metrics)\n",
    "#         display(pandas.DataFrame(cur_train_metrics).describe().loc[['mean', 'std']])\n",
    "\n",
    "#         net.eval()\n",
    "#         cur_val_metrics = run_network_structured(net, val_gen,\n",
    "#                                                  BATCHES_PER_EPOCH_VAL,\n",
    "#                                                  raw_criterion=RAW_LOSS,\n",
    "#                                                  metrics=VAL_METRICS)\n",
    "#         val_metrics.extend(cur_val_metrics)\n",
    "#         display(pandas.DataFrame(cur_val_metrics).describe().loc[['mean', 'std']])\n",
    "#     finally:\n",
    "#         if train_gen:\n",
    "#             clean_pytorch_dataloadergen(train_gen)\n",
    "#         if val_gen:\n",
    "#             clean_pytorch_dataloadergen(val_gen)\n",
    "\n",
    "#         gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structured Two-step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:11.366633Z",
     "start_time": "2018-01-16T09:54:11.299311Z"
    }
   },
   "outputs": [],
   "source": [
    "# base_segm_model = torch.load('./models/segm_unet1_step_aug').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:11.414751Z",
     "start_time": "2018-01-16T09:54:11.369805Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# base_train_gen = None\n",
    "# base_val_gen = None\n",
    "\n",
    "# EPOCHS_NUM = 60\n",
    "# BASE_BATCH_SIZE = 4\n",
    "# BATCH_SIZE = 10\n",
    "# PART_PER_EPOCH = 0.5\n",
    "# MEAN_RELS_PER_IMAGE = 2\n",
    "# BATCHES_PER_EPOCH_TRAIN = int(len(train_int_image_ids) * PART_PER_EPOCH // BASE_BATCH_SIZE) * MEAN_RELS_PER_IMAGE\n",
    "# BATCHES_PER_EPOCH_VAL = int(len(val_int_image_ids) * PART_PER_EPOCH // BASE_BATCH_SIZE) * MEAN_RELS_PER_IMAGE\n",
    "\n",
    "# cell_net = ConvFCNClassifier(5, 2,\n",
    "#                              conv_layers=3,\n",
    "#                              dilations=[1, 2, 4, 8, 16, 32]).cuda()\n",
    "# print('receptive field', cell_net.receptive_field)\n",
    "# CELL_REL_LOSS = F.binary_cross_entropy\n",
    "# print('total parameters', sum(numpy.product(p.size()) for p in cell_net.parameters()))\n",
    "\n",
    "# # cell_tamper_channels = [0, 2, 3]\n",
    "# cell_tamper_channels = []\n",
    "\n",
    "# # cell_augmenter = imgaug_pipeline\n",
    "# cell_augmenter = fake_imgaug_pipeline\n",
    "\n",
    "# CELL_LR_SCHEDULE = step_annealed_lr\n",
    "\n",
    "# train_metrics = []\n",
    "# val_metrics = []\n",
    "# for epoch in range(EPOCHS_NUM):\n",
    "#     try:\n",
    "#         base_train_gen = iter(DataLoader(SegmDataset(train_int_image_ids,\n",
    "#                                                      cell_augmenter,\n",
    "#                                                      prepare_int_batch),\n",
    "#                                          batch_size=BASE_BATCH_SIZE,\n",
    "#                                          shuffle=True,\n",
    "#                                          num_workers=4))\n",
    "#         train_gen = structured_two_step_datagen(base_train_gen,\n",
    "#                                                 model=base_segm_model,\n",
    "#                                                 cuda=True,\n",
    "#                                                 batch_size=BATCH_SIZE,\n",
    "#                                                 tamper_channels=cell_tamper_channels)\n",
    "# #         qq = next(iter(train_gen))[0].data.cpu().numpy()\n",
    "#         base_val_gen = iter(DataLoader(SegmDataset(val_int_image_ids,\n",
    "#                                                    cell_augmenter,\n",
    "#                                                    prepare_int_batch),\n",
    "#                                        batch_size=BASE_BATCH_SIZE,\n",
    "#                                        shuffle=True,\n",
    "#                                        num_workers=2))\n",
    "#         val_gen = structured_two_step_datagen(base_val_gen,\n",
    "#                                               model=base_segm_model,\n",
    "#                                               cuda=True,\n",
    "#                                               batch_size=BATCH_SIZE,\n",
    "#                                               tamper_channels=cell_tamper_channels)\n",
    "\n",
    "#         print('epoch', epoch)\n",
    "\n",
    "#         lr = CELL_LR_SCHEDULE(epoch)\n",
    "#         print('lr', lr)\n",
    "#         optimizer = Adam(cell_net.parameters(), lr=lr)\n",
    "\n",
    "#         cell_net.train()\n",
    "#         cur_train_metrics = run_cell_network(cell_net, train_gen, BATCHES_PER_EPOCH_TRAIN,\n",
    "#                                              criterion=CELL_REL_LOSS,\n",
    "#                                              metrics=CELL_TRAIN_METRICS,\n",
    "#                                              optimizer=optimizer)\n",
    "#         train_metrics.extend(cur_train_metrics)\n",
    "#         display(pandas.DataFrame(cur_train_metrics).describe().loc[['mean', 'std']])\n",
    "\n",
    "#         cell_net.eval()\n",
    "#         cur_val_metrics = run_cell_network(cell_net, val_gen, BATCHES_PER_EPOCH_VAL,\n",
    "#                                            criterion=CELL_REL_LOSS,\n",
    "#                                            metrics=CELL_VAL_METRICS)\n",
    "#         val_metrics.extend(cur_val_metrics)\n",
    "#         display(pandas.DataFrame(cur_val_metrics).describe().loc[['mean', 'std']])\n",
    "#     finally:\n",
    "#         if base_train_gen:\n",
    "#             clean_pytorch_dataloadergen(base_train_gen)\n",
    "#         if base_val_gen:\n",
    "#             clean_pytorch_dataloadergen(base_val_gen)\n",
    "\n",
    "#         gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:11.474076Z",
     "start_time": "2018-01-16T09:54:11.416482Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_metrics = pandas.DataFrame(train_metrics)\n",
    "# val_metrics = pandas.DataFrame(val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:11.505174Z",
     "start_time": "2018-01-16T09:54:11.475497Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pandas.rolling_mean(train_metrics, 100).plot(figsize=(13, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:11.538243Z",
     "start_time": "2018-01-16T09:54:11.507832Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pandas.rolling_mean(val_metrics[[c for c in val_metrics.columns if 'cell' in c]], 10).plot(figsize=(13, 8))\n",
    "# pandas.rolling_mean(val_metrics, 100).plot(figsize=(13, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:11.596064Z",
     "start_time": "2018-01-16T09:54:11.539683Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.save(det_net, 'models/det_unet2_aug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:16.763136Z",
     "start_time": "2018-01-16T09:54:11.598995Z"
    }
   },
   "outputs": [],
   "source": [
    "# det_test_net = det_net\n",
    "det_test_net = torch.load('models/det_unet1_aug').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:16.789531Z",
     "start_time": "2018-01-16T09:54:16.765583Z"
    }
   },
   "outputs": [],
   "source": [
    "# det_test_gen = DataLoader(SegmDataset(val_det_image_ids,\n",
    "# #                                       imgaug_pipeline,\n",
    "#                                       fake_imgaug_pipeline,\n",
    "#                                       prepare_det_batch),\n",
    "#                           batch_size=4,\n",
    "#                           shuffle=True,\n",
    "#                           num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:16.843490Z",
     "start_time": "2018-01-16T09:54:16.792571Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# det_test_metrics = pandas.DataFrame(run_network(det_test_net,\n",
    "#                                                 det_test_gen,\n",
    "#                                                 len(val_det_image_ids) // 4,\n",
    "#                                                 metrics=VAL_DET_METRICS))\n",
    "# format_metrics_table_md(det_test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:16.877096Z",
     "start_time": "2018-01-16T09:54:16.846454Z"
    }
   },
   "outputs": [],
   "source": [
    "# det_test_batch = next(iter(det_test_gen))\n",
    "# det_test_img = det_test_batch[1].cpu().numpy()\n",
    "# det_test_mask = det_test_batch[2].cpu().numpy()\n",
    "# det_test_pred = det_test_net(npvar(det_test_batch[1], True))\n",
    "# det_test_pred_np = det_test_pred.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:16.926899Z",
     "start_time": "2018-01-16T09:54:16.878811Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# arr_to_img(det_test_img[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:16.954074Z",
     "start_time": "2018-01-16T09:54:16.928382Z"
    }
   },
   "outputs": [],
   "source": [
    "# arr_to_img(mask_to_img(det_test_mask[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:16.982187Z",
     "start_time": "2018-01-16T09:54:16.955922Z"
    }
   },
   "outputs": [],
   "source": [
    "# arr_to_img(mask_to_img(det_test_pred_np[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:17.018777Z",
     "start_time": "2018-01-16T09:54:16.984069Z"
    }
   },
   "outputs": [],
   "source": [
    "# arr_to_img(mask_to_img(fill_boxes_on_mask_single_image(det_test_pred_np[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "\n",
    "##### Trained Without Augmentation\n",
    "\n",
    "###### U-net1+step\n",
    "\n",
    "|         | bd        | d         | loss      | px_p      | px_r      |\n",
    "|:--------|:----------|:----------|:----------|:----------|:----------|\n",
    "| body    | 0.90Â±0.10 | 0.90Â±0.10 |           | 0.91Â±0.12 | 0.92Â±0.11 |\n",
    "| caption | 0.76Â±0.18 | 0.75Â±0.18 |           | 0.79Â±0.17 | 0.79Â±0.21 |\n",
    "| loss    |           |           | 0.21Â±0.24 |           |           |\n",
    "\n",
    "###### DenseNet1\n",
    "\n",
    "\n",
    "##### Trained With Augmentation\n",
    "\n",
    "###### U-net1+step\n",
    "\n",
    "|         | bd        | d         | loss      | px_p      | px_r      |\n",
    "|:--------|:----------|:----------|:----------|:----------|:----------|\n",
    "| body    | 0.90Â±0.10 | 0.89Â±0.10 |           | 0.93Â±0.11 | 0.88Â±0.12 |\n",
    "| caption | 0.72Â±0.20 | 0.66Â±0.20 |           | 0.81Â±0.19 | 0.62Â±0.24 |\n",
    "| loss    |           |           | 0.25Â±0.24 |           |           |\n",
    "\n",
    "###### DenseNet1\n",
    "\n",
    "\n",
    "#### Old Results\n",
    "\n",
    "##### torch4_net\n",
    "\td body\td caption\tloss\n",
    "    mean\t0.889029\t0.724086\t0.238287\n",
    "    std\t0.104200\t0.185334\t0.262712"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table structure segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:17.052798Z",
     "start_time": "2018-01-16T09:54:17.021890Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.save(net, 'models/segm_unet1_step_aug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:17.096061Z",
     "start_time": "2018-01-16T09:54:17.054296Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_net = net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:17.129107Z",
     "start_time": "2018-01-16T09:54:17.098898Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_net = torch.load('models/segm_unet1_step_aug').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:17.162632Z",
     "start_time": "2018-01-16T09:54:17.132279Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_gen = DataLoader(SegmDataset(val_int_image_ids,\n",
    "#                                   imgaug_pipeline,\n",
    "# #                                   fake_imgaug_pipeline,\n",
    "#                                   prepare_int_batch),\n",
    "#                       batch_size=4,\n",
    "#                       shuffle=True,\n",
    "#                       num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:17.196872Z",
     "start_time": "2018-01-16T09:54:17.164252Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_metrics = pandas.DataFrame(run_network(test_net,\n",
    "#                                             test_gen,\n",
    "#                                             100,\n",
    "#                                             metrics=TEST_INT_METRICS))\n",
    "# format_metrics_table_md(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:17.245704Z",
     "start_time": "2018-01-16T09:54:17.198337Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_batch = next(iter(test_gen))\n",
    "# test_pred = test_net(npvar(test_batch[1], True))\n",
    "# test_pred_np = test_pred.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:17.278836Z",
     "start_time": "2018-01-16T09:54:17.248745Z"
    }
   },
   "outputs": [],
   "source": [
    "# arr_to_img(test_batch[1][1][0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:17.312842Z",
     "start_time": "2018-01-16T09:54:17.280191Z"
    }
   },
   "outputs": [],
   "source": [
    "# arr_to_img(mask_to_img(test_batch[2][1].cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:17.356718Z",
     "start_time": "2018-01-16T09:54:17.315637Z"
    }
   },
   "outputs": [],
   "source": [
    "# arr_to_img(mask_to_img(test_pred_np[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "\n",
    "##### Trained Without Augmentation\n",
    "\n",
    "###### U-net1+step\n",
    "\n",
    "*Eval With Augmentation*\n",
    "\n",
    "|                    | bf        | bp        | br        | d         | loss      |\n",
    "|:-------------------|:----------|:----------|:----------|:----------|:----------|\n",
    "| body               | 0.00Â±0.00 | 0.00Â±0.00 | 0.00Â±0.00 | 0.86Â±0.05 |           |\n",
    "| cell               | 0.43Â±0.20 | 0.60Â±0.25 | 0.38Â±0.19 | 0.47Â±0.19 |           |\n",
    "| loss               |           |           |           |           | 1.33Â±0.45 |\n",
    "| same_col_other_row | 0.01Â±0.03 | 0.06Â±0.10 | 0.01Â±0.02 | 0.37Â±0.18 |           |\n",
    "| same_row_other_col | 0.01Â±0.02 | 0.03Â±0.09 | 0.00Â±0.02 | 0.50Â±0.17 |           |\n",
    "\n",
    "*Eval Without Augmentation*\n",
    "\n",
    "|                    | bf        | bp        | br        | d         | loss      |\n",
    "|:-------------------|:----------|:----------|:----------|:----------|:----------|\n",
    "| body               | 0.00Â±0.00 | 0.00Â±0.00 | 0.00Â±0.00 | 1.00Â±0.00 |           |\n",
    "| cell               | 0.97Â±0.02 | 1.00Â±0.01 | 0.95Â±0.03 | 0.96Â±0.00 |           |\n",
    "| loss               |           |           |           |           | 0.11Â±0.02 |\n",
    "| same_col_other_row | 0.01Â±0.02 | 0.02Â±0.07 | 0.00Â±0.01 | 0.87Â±0.02 |           |\n",
    "| same_row_other_col | 0.02Â±0.04 | 0.10Â±0.16 | 0.01Â±0.02 | 0.91Â±0.01 |           |\n",
    "\n",
    "###### U-net1+sin\n",
    "\n",
    "*Eval With Augmentation*\n",
    "\n",
    "|                    | bf        | bp        | br        | d         | loss      |\n",
    "|:-------------------|:----------|:----------|:----------|:----------|:----------|\n",
    "| body               | 0.00Â±0.00 | 0.00Â±0.00 | 0.00Â±0.00 | 0.86Â±0.07 |           |\n",
    "| cell               | 0.28Â±0.21 | 0.35Â±0.25 | 0.25Â±0.20 | 0.29Â±0.21 |           |\n",
    "| loss               |           |           |           |           | 2.13Â±0.60 |\n",
    "| same_col_other_row | 0.00Â±0.01 | 0.02Â±0.06 | 0.00Â±0.01 | 0.27Â±0.19 |           |\n",
    "| same_row_other_col | 0.01Â±0.01 | 0.04Â±0.09 | 0.00Â±0.01 | 0.33Â±0.19 |           |\n",
    "\n",
    "*Eval Without Augmentation*\n",
    "\n",
    "|                    | bf        | bp        | br        | d         | loss      |\n",
    "|:-------------------|:----------|:----------|:----------|:----------|:----------|\n",
    "| body               | 0.00Â±0.00 | 0.00Â±0.00 | 0.00Â±0.00 | 1.00Â±0.00 |           |\n",
    "| cell               | 0.97Â±0.02 | 1.00Â±0.00 | 0.95Â±0.03 | 0.96Â±0.00 |           |\n",
    "| loss               |           |           |           |           | 0.12Â±0.02 |\n",
    "| same_col_other_row | 0.01Â±0.02 | 0.02Â±0.08 | 0.00Â±0.01 | 0.87Â±0.02 |           |\n",
    "| same_row_other_col | 0.02Â±0.04 | 0.10Â±0.17 | 0.01Â±0.02 | 0.90Â±0.02 |           |\n",
    "\n",
    "###### DenseNet1+step\n",
    "\n",
    "*Eval With Augmentation*\n",
    "\n",
    "*Eval Without Augmentation*\n",
    "\n",
    "|                    | bf        | bp        | br        | d         | loss      |\n",
    "|:-------------------|:----------|:----------|:----------|:----------|:----------|\n",
    "| body               | 0.00Â±0.00 | 0.00Â±0.00 | 0.00Â±0.00 | 0.98Â±0.01 |           |\n",
    "| cell               | 0.97Â±0.02 | 1.00Â±0.01 | 0.95Â±0.03 | 0.93Â±0.01 |           |\n",
    "| loss               |           |           |           |           | 0.32Â±0.02 |\n",
    "| same_col_other_row | 0.00Â±0.00 | 0.00Â±0.00 | 0.00Â±0.00 | 0.27Â±0.01 |           |\n",
    "| same_row_other_col | 0.13Â±0.08 | 0.50Â±0.23 | 0.08Â±0.05 | 0.64Â±0.02 |           |\n",
    "\n",
    "###### DenseNet1+sin\n",
    "\n",
    "*Eval With Augmentation*\n",
    "\n",
    "*Eval Without Augmentation*\n",
    "\n",
    "\n",
    "##### Trained With Augmentation\n",
    "\n",
    "###### U-net1+step\n",
    "\n",
    "*Eval With Augmentation*\n",
    "\n",
    "|                    | bf        | bp        | br        | d         | loss      |\n",
    "|:-------------------|:----------|:----------|:----------|:----------|:----------|\n",
    "| body               | 0.00Â±0.00 | 0.00Â±0.00 | 0.00Â±0.00 | 0.99Â±0.00 |           |\n",
    "| cell               | 0.93Â±0.03 | 0.99Â±0.01 | 0.89Â±0.05 | 0.92Â±0.01 |           |\n",
    "| loss               |           |           |           |           | 0.16Â±0.03 |\n",
    "| same_col_other_row | 0.01Â±0.02 | 0.03Â±0.08 | 0.00Â±0.01 | 0.82Â±0.02 |           |\n",
    "| same_row_other_col | 0.04Â±0.04 | 0.16Â±0.17 | 0.02Â±0.03 | 0.86Â±0.03 |           |\n",
    "\n",
    "*Eval Without Augmentation*\n",
    "\n",
    "|                    | bf        | bp        | br        | d         | loss      |\n",
    "|:-------------------|:----------|:----------|:----------|:----------|:----------|\n",
    "| body               | 0.00Â±0.00 | 0.00Â±0.00 | 0.00Â±0.00 | 0.99Â±0.00 |           |\n",
    "| cell               | 0.96Â±0.02 | 0.98Â±0.01 | 0.94Â±0.03 | 0.91Â±0.01 |           |\n",
    "| loss               |           |           |           |           | 0.21Â±0.03 |\n",
    "| same_col_other_row | 0.01Â±0.02 | 0.03Â±0.09 | 0.00Â±0.01 | 0.83Â±0.02 |           |\n",
    "| same_row_other_col | 0.05Â±0.05 | 0.20Â±0.18 | 0.03Â±0.03 | 0.85Â±0.02 |           |\n",
    "\n",
    "###### U-net1+sin\n",
    "\n",
    "*Eval With Augmentation*\n",
    "\n",
    "*Eval Without Augmentation*\n",
    "\n",
    "###### DenseNet1+step\n",
    "\n",
    "*Eval With Augmentation*\n",
    "\n",
    "*Eval Without Augmentation*\n",
    "\n",
    "###### DenseNet1+sin\n",
    "\n",
    "*Eval With Augmentation*\n",
    "\n",
    "*Eval Without Augmentation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intracell classification (second step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:17.500879Z",
     "start_time": "2018-01-16T09:54:17.359735Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.save(cell_net, './models/cell_fcn1_no_aug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:17.662970Z",
     "start_time": "2018-01-16T09:54:17.503862Z"
    }
   },
   "outputs": [],
   "source": [
    "cell_test_net = torch.load('models/cell_fcn1_no_aug').cuda()\n",
    "cell_test_base_segm_model = torch.load('models/segm_unet1_step_aug').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:17.687089Z",
     "start_time": "2018-01-16T09:54:17.664564Z"
    }
   },
   "outputs": [],
   "source": [
    "# cell_test_gen = structured_two_step_datagen(DataLoader(SegmDataset(val_int_image_ids,\n",
    "#                                                                    imgaug_pipeline,\n",
    "# #                                                                    fake_imgaug_pipeline,\n",
    "#                                                                    prepare_int_batch),\n",
    "#                                                        batch_size=4,\n",
    "#                                                        shuffle=True,\n",
    "#                                                        num_workers=0),\n",
    "#                                             model=cell_test_base_segm_model,\n",
    "#                                             cuda=True,\n",
    "#                                             batch_size=10, \n",
    "#                                             tamper_channels=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:17.739087Z",
     "start_time": "2018-01-16T09:54:17.688581Z"
    }
   },
   "outputs": [],
   "source": [
    "# cell_test_metrics = pandas.DataFrame(run_cell_network(cell_test_net,\n",
    "#                                                       cell_test_gen,\n",
    "#                                                       1000,\n",
    "#                                                       metrics=CELL_TRAIN_METRICS))\n",
    "# format_metrics_table_md(cell_test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:17.779505Z",
     "start_time": "2018-01-16T09:54:17.741975Z"
    }
   },
   "outputs": [],
   "source": [
    "# cell_test_batch = next(iter(cell_test_gen))\n",
    "\n",
    "# cell_test_pred = cell_test_net(cell_test_batch[0])\n",
    "# cell_test_pred_np = cell_test_pred.cpu().data.numpy()\n",
    "\n",
    "# cell_test_in_np = cell_test_batch[0].data.cpu().numpy()\n",
    "# cell_test_gold_np = cell_test_batch[1].data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:17.815759Z",
     "start_time": "2018-01-16T09:54:17.782469Z"
    }
   },
   "outputs": [],
   "source": [
    "# cell_test_cls = 0\n",
    "# cell_err_idx = numpy.where((cell_test_pred_np[:, cell_test_cls] > 0.5) ^ (cell_test_gold_np[:, cell_test_cls] > 0.5))[0]\n",
    "# cell_err_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:17.847491Z",
     "start_time": "2018-01-16T09:54:17.819472Z"
    }
   },
   "outputs": [],
   "source": [
    "# arr_to_img(mask_to_img(cell_test_in_np[9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "##### Trained Without Augmentation\n",
    "\n",
    "\n",
    "\n",
    "###### cell_fcn1_no_aug + segm_unet1_step_aug dirty\n",
    "\n",
    "*eval no aug*\n",
    "\n",
    "|          | f1        | loss      | p         | r         |\n",
    "|:---------|:----------|:----------|:----------|:----------|\n",
    "| loss     |           | 0.12Â±0.17 |           |           |\n",
    "| same_col | 0.98Â±0.07 |           | 0.97Â±0.10 | 0.99Â±0.03 |\n",
    "| same_row | 0.98Â±0.05 |           | 1.00Â±0.02 | 0.97Â±0.08 |\n",
    "\n",
    "\n",
    "*eval with aug*\n",
    "\n",
    "|          | f1        | loss      | p         | r         |\n",
    "|:---------|:----------|:----------|:----------|:----------|\n",
    "| loss     |           | 0.12Â±0.19 |           |           |\n",
    "| same_col | 0.97Â±0.07 |           | 0.96Â±0.10 | 0.99Â±0.03 |\n",
    "| same_row | 0.98Â±0.05 |           | 0.99Â±0.03 | 0.97Â±0.08 |\n",
    "\n",
    "###### cell_fcn1_no_aug + segm_unet1_step_aug clean\n",
    "\n",
    "*eval no aug*\n",
    "\n",
    "|          | f1        | loss      | p         | r         |\n",
    "|:---------|:----------|:----------|:----------|:----------|\n",
    "| loss     |           | 0.06Â±0.09 |           |           |\n",
    "| same_col | 0.99Â±0.04 |           | 0.99Â±0.06 | 1.00Â±0.02 |\n",
    "| same_row | 0.99Â±0.03 |           | 1.00Â±0.02 | 0.99Â±0.04 |\n",
    "\n",
    "\n",
    "*eval with aug*\n",
    "\n",
    "|          | f1        | loss      | p         | r         |\n",
    "|:---------|:----------|:----------|:----------|:----------|\n",
    "| loss     |           | 0.08Â±0.16 |           |           |\n",
    "| same_col | 0.99Â±0.05 |           | 0.98Â±0.06 | 1.00Â±0.02 |\n",
    "| same_row | 0.98Â±0.04 |           | 0.98Â±0.06 | 0.99Â±0.05 |\n",
    "\n",
    "\n",
    "##### Trained With Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse tables using all built models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T09:54:19.836189Z",
     "start_time": "2018-01-16T09:54:17.849463Z"
    }
   },
   "outputs": [],
   "source": [
    "def reorder_cells(c1, c2, cells, dim):\n",
    "    b1, b2 = cells[c1], cells[c2]\n",
    "    coord1, coord2 = b1[dim], b2[dim]\n",
    "    coord1o, coord2o = b1[dim+2], b2[dim+2]\n",
    "    if coord1 < coord2:\n",
    "        return c1, c2, coord2 > coord1o\n",
    "    else:\n",
    "        return c2, c1, coord1 > coord2o\n",
    "\n",
    "\n",
    "class SeqIdGen(object):\n",
    "    def __init__(self):\n",
    "        self.next_id = 0\n",
    "\n",
    "    def __call__(self):\n",
    "        res = self.next_id\n",
    "        self.next_id += 1\n",
    "        return res\n",
    "\n",
    "\n",
    "def make_equivalence_classes(neighborhood):\n",
    "    cell2cls = {}\n",
    "    gen_cls_id = SeqIdGen()\n",
    "\n",
    "    refs_by_cell = { c : 0\n",
    "                    for cur_cell, neighs in neighborhood.items()\n",
    "                    for lst in ((cur_cell,), neighs)\n",
    "                    for c in lst }\n",
    "    for cur_cell, neighs in neighborhood.items():\n",
    "        for oc in neighs:\n",
    "            refs_by_cell[oc] += 1\n",
    "    cells_with_no_refs = [c\n",
    "                          for c, refs_n in refs_by_cell.items()\n",
    "                          if refs_n == 0]\n",
    "\n",
    "    for cls_seed in cells_with_no_refs:\n",
    "        cur_queue = collections.deque([(cls_seed, { gen_cls_id() })])\n",
    "\n",
    "        while len(cur_queue) > 0:\n",
    "            cur_cell, cur_cls = cur_queue.popleft()\n",
    "            cell2cls[cur_cell] = cur_cls\n",
    "\n",
    "            cur_neighbors = neighborhood.get(cur_cell, [])\n",
    "            many_neighbors = len(cur_neighbors) > 1\n",
    "            for oc in cur_neighbors:\n",
    "                oc_cls = set(cur_cls)\n",
    "                if many_neighbors:\n",
    "                    oc_cls.add(gen_cls_id())\n",
    "                cur_queue.append((oc, oc_cls))\n",
    "\n",
    "    return cell2cls\n",
    "\n",
    "\n",
    "def reconstruct_table_from_grid(body, cells, grid, cell_idx, intracell_space_classes, prob_threshold=0.5):\n",
    "    row_neighbors = collections.defaultdict(set)\n",
    "    col_neighbors = collections.defaultdict(set)\n",
    "\n",
    "    for (c1, c2), probs in intracell_space_classes.items():\n",
    "        b1 = cells[c1]\n",
    "        b2 = cells[c2]\n",
    "        if probs[STRUCT_SAME_ROWS_I] > prob_threshold:\n",
    "            rc1, rc2, do_not_overlap = reorder_cells(c1, c2, cells, 1) # ensure rc1 is in the left of rc2\n",
    "            if do_not_overlap:\n",
    "                row_neighbors[rc1].add(rc2)\n",
    "        if probs[STRUCT_SAME_COLS_I] > prob_threshold:\n",
    "            cc1, cc2, do_not_overlap = reorder_cells(c1, c2, cells, 0) # ensure cc1 is above of cc2\n",
    "            if do_not_overlap:\n",
    "                col_neighbors[cc1].add(cc2)\n",
    "\n",
    "    cell2rows = make_equivalence_classes(row_neighbors)\n",
    "    cell2cols = make_equivalence_classes(col_neighbors)\n",
    "\n",
    "    rows = collections.defaultdict(set)\n",
    "    for cell_i, cell_rows_idx in cell2rows.items():\n",
    "        for row_i in cell_rows_idx:\n",
    "            rows[row_i].add(cell_i)\n",
    "\n",
    "    cols = collections.defaultdict(set)\n",
    "    for cell_i, cell_cols_idx in cell2cols.items():\n",
    "        for col_i in cell_cols_idx:\n",
    "            cols[col_i].add(cell_i)\n",
    "\n",
    "    row_boxes = [just_box_union([cells[i] for i in row_idx])\n",
    "                 for row_idx in rows.values()]\n",
    "    row_boxes.sort(key=lambda b: b[0])\n",
    "\n",
    "    col_boxes = [just_box_union([cells[i] for i in col_idx])\n",
    "                 for col_idx in cols.values()]\n",
    "    col_boxes.sort(key=lambda b: b[1])\n",
    "    return (body,\n",
    "            cells,\n",
    "            row_boxes,\n",
    "            col_boxes)\n",
    "\n",
    "\n",
    "def get_segm_mask_batch(images, segm_model, cuda=True):\n",
    "    batch_segm_input = npvar(numpy.expand_dims(numpy.array([numpy.array(img).astype('float32')\n",
    "                                                            for img in images]),\n",
    "                                               1) / 255.0,\n",
    "                             cuda)\n",
    "    return segm_model(batch_segm_input).data.cpu().numpy()\n",
    "\n",
    "\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# Ð¿Ð¾Ð´ÐºÐ»ÑÑÐ¸ÑÑ det_model\n",
    "# ÐºÐ¾Ð¿Ð¸ÑÐ¾Ð²Ð°ÑÑ Ð²ÑÐ´ÐµÐ»ÐµÐ½Ð½ÑÐµ ÑÑÐ°Ð³Ð¼ÐµÐ½ÑÑ Ð² Ð¾ÑÐ´ÐµÐ»ÑÐ½ÑÐµ ÐºÐ°ÑÑÐ¸Ð½ÐºÐ¸ Ð¸ Ð¸Ñ ÑÐµÐ³Ð¼ÐµÐ½ÑÐ¸ÑÐ¾Ð²Ð°ÑÑ Ñ Ð¿Ð¾Ð¼Ð¾ÑÑÑ segm_model\n",
    "\n",
    "\n",
    "def ceil_mod(x, mod):\n",
    "    if x % mod == 0:\n",
    "        return x\n",
    "    return ((x // mod) + 1) * mod\n",
    "\n",
    "\n",
    "def choose_image_size_multiple_of(min_size, multiplier=32):\n",
    "    return (ceil_mod(min_size[0], multiplier),\n",
    "            ceil_mod(min_size[1], multiplier))\n",
    "\n",
    "\n",
    "def fit_image_size(src_image, multiplier=128, mode='L', filler=255):\n",
    "    new_size = choose_image_size_multiple_of(src_image.size,\n",
    "                                             multiplier=multiplier)\n",
    "    result = Image.new(mode,\n",
    "                       new_size,\n",
    "                       filler)\n",
    "    result.paste(src_image)\n",
    "    return result\n",
    "\n",
    "\n",
    "def box_to_abs_coords(box, parent):\n",
    "    py1, px1, py2, px2 = parent\n",
    "    by1, bx1, by2, bx2 = box\n",
    "    return (by1+py1, bx1+px1, by2+py1, bx2+px1)\n",
    "\n",
    "\n",
    "def box_lst_to_abs_coords(boxes, parent):\n",
    "    return [box_to_abs_coords(box, parent) for box in boxes]\n",
    "\n",
    "\n",
    "def parse_tables_from_images(images, det_model, segm_model, cell_model, cuda=True, cell_batch_size=64, min_body_area=300, body_padding=0):\n",
    "    tables_by_image = []\n",
    "    grids_by_image = []\n",
    "\n",
    "    batch_det_output = get_segm_mask_batch(images, det_model, cuda)\n",
    "    for src_image, det_mask in zip(images, batch_det_output):\n",
    "        cur_img_tables = []\n",
    "        cur_img_grids = []\n",
    "\n",
    "#         display(arr_to_img(mask_to_img(det_mask)))\n",
    "        det_boxes_by_channel = get_boxes_by_channel(det_mask)\n",
    "    \n",
    "        \n",
    "        cur_image_captions = det_boxes_by_channel[DET_CAPTION_CHANNEL_I]\n",
    "        cur_image_bodies = det_boxes_by_channel[DET_BODY_CHANNEL_I]\n",
    "        cur_image_bodies.sort(key=box_area, reverse=True)\n",
    "        for body in cur_image_bodies:\n",
    "            if box_area(body) < min_body_area:\n",
    "                continue\n",
    "            ext_body = (max(0, body[0]-body_padding),\n",
    "                        max(0, body[1]-body_padding),\n",
    "                        min(src_image.size[1], body[2]+body_padding),\n",
    "                        min(src_image.size[0], body[3]+body_padding))\n",
    "            cropped_image = src_image.crop((ext_body[1], ext_body[0], ext_body[3], ext_body[2]))\n",
    "            src_image_for_segm = fit_image_size(cropped_image)\n",
    "            segm_output = get_segm_mask_batch([src_image_for_segm], segm_model, cuda)[0]\n",
    "\n",
    "#             display(arr_to_img(mask_to_img(segm_output)))\n",
    "\n",
    "            # here should go a loop over all found bodies\n",
    "            _, cells, grid, cell_idx, intracell_relations = table_grid_from_intracell_mask(segm_output,\n",
    "                                                                                           input_image=(numpy.array(src_image_for_segm).astype('float32') / 255.0))\n",
    "            output_cell_coords = box_lst_to_abs_coords(cells, ext_body)\n",
    "            intracell_relation_keys = list(intracell_relations.keys())\n",
    "            intracell_relation_classes = {}\n",
    "            for batch_start in range(0, len(intracell_relation_keys), cell_batch_size):\n",
    "                batch_rel_keys = intracell_relation_keys[batch_start:batch_start+cell_batch_size]\n",
    "                batch_relations = [(cells[i1], cells[i2], intracell_relations[(i1, i2)])\n",
    "                                   for (i1, i2) in batch_rel_keys]\n",
    "\n",
    "                cell_img_inp = npvar(segm_output, cuda).unsqueeze(0)\n",
    "                cell_batch_input = CellRelConvFCNClassifier.make_batch(cell_img_inp,\n",
    "                                                                       [batch_relations])\n",
    "                cell_batch_output = cell_model(cell_batch_input).data.cpu().numpy()\n",
    "                for rel_key, cur_cell_pair_out in zip(batch_rel_keys, cell_batch_output):\n",
    "                    intracell_relation_classes[rel_key] = cur_cell_pair_out\n",
    "            cur_img_grids.append((body, output_cell_coords, grid, cell_idx, intracell_relation_classes))\n",
    "            cur_img_tables.append(reconstruct_table_from_grid(body, output_cell_coords, grid, cell_idx, intracell_relation_classes))\n",
    "\n",
    "        tables_by_image.append(cur_img_tables)\n",
    "        grids_by_image.append(cur_img_grids)\n",
    "\n",
    "    return tables_by_image, grids_by_image\n",
    "\n",
    "\n",
    "def make_boxes_with_channels_from_parsed_table(table_info):\n",
    "    body, cells, rows, cols = table_info\n",
    "    boxes = [(1, body)]\n",
    "    boxes.extend((2, b) for b in cells)\n",
    "    boxes.extend((3, b) for b in rows)\n",
    "    boxes.extend((4, b) for b in cols)\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def make_demo_mask_from_parsed_table(img, table_info):\n",
    "    boxes = make_boxes_with_channels_from_parsed_table(table_info)\n",
    "    return make_demo_mask(img, boxes)\n",
    "\n",
    "\n",
    "def make_intracell_rels_symmetric(intracell_relation_classes):\n",
    "    src_keys = list(intracell_relation_classes.keys())\n",
    "    sums = collections.defaultdict(lambda: numpy.zeros(2, dtype='float32'))\n",
    "    norms = collections.defaultdict(float)\n",
    "    for (c1, c2), probs in intracell_relation_classes.items():\n",
    "        if c1 > c2:\n",
    "            c1, c2 = c2, c1\n",
    "        symmetric_key = (c1, c2)\n",
    "        sums[symmetric_key] += probs\n",
    "        norms[symmetric_key] += 1\n",
    "    result = {}\n",
    "    for key in src_keys:\n",
    "        c1, c2 = key\n",
    "        if c1 > c2:\n",
    "            c1, c2 = c2, c1\n",
    "        symmetric_key = (c1, c2)\n",
    "        result[key] = sums[symmetric_key] / norms[symmetric_key]\n",
    "    return result\n",
    "\n",
    "\n",
    "def make_demo_mask_from_grid_info(img, grid_info, min_prob=0.5, cells_of_interest=None, print_probs=False):\n",
    "    body, cells, grid, cell_idx, intracell_relation_classes = grid_info\n",
    "    rel_mask = numpy.zeros((3, img.size[1], img.size[0]), dtype='uint8')\n",
    "    for (c1, c2), probs in intracell_relation_classes.items():\n",
    "        if not cells_of_interest is None:\n",
    "            if not (c1 in cells_of_interest or c2 in cells_of_interest):\n",
    "                continue\n",
    "        b1 = cells[c1]\n",
    "        b2 = cells[c2]\n",
    "        for ch_i in range(probs.shape[0]):\n",
    "            if probs[ch_i] < min_prob:\n",
    "                continue\n",
    "            if print_probs:\n",
    "                print(c1, c2, ch_i, probs[ch_i])\n",
    "            draw_intercell_mask(rel_mask[ch_i],\n",
    "                                b1,\n",
    "                                b2,\n",
    "                                'same_row',\n",
    "                                value=int(probs[ch_i]*255))\n",
    "    rel_mask = mask_to_img(rel_mask.astype('float32') / 255.0)\n",
    "\n",
    "    rel_mask_img = arr_to_img(rel_mask)\n",
    "    cells_for_display = cells if cells_of_interest is None else [cells[i] for i in cells_of_interest]\n",
    "    base_mask = make_demo_mask(img, [(1, body)] + [(2, c)\n",
    "                                                   for c in cells_for_display])\n",
    "    return Image.blend(rel_mask_img.convert('RGB'), base_mask, 0.5)\n",
    "\n",
    "\n",
    "def get_either(m, k):\n",
    "    r = m.get(k, None)\n",
    "    if r is None:\n",
    "        r = m.get((k[1], k[0]), None)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T08:54:22.568050Z",
     "start_time": "2018-01-15T08:54:22.366700Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_img_id = val_det_image_ids[10]\n",
    "# test_img_filename = test_img_id + IN_IMG_SUFFIX\n",
    "# test_img_filename = './data/dc/docs_pages_flat/2012-3.pdf_0001.png'\n",
    "# test_img_filename = './data/dc/docs_pages_flat/2003-16.pdf_0004.png'\n",
    "# test_img_filename = './data/dc/docs_pages_flat/2002-5-mucin-gene-muc1-transfected-dendritic-cells-as-vaccine-results-of-a-phase-i-ii-clinical-trial.pdf_0001.png'\n",
    "test_img_filename = './data/dc/docs_pages_flat/2010-1.pdf_0002.png'\n",
    "test_image = fit_image_size(load_image_opaque(test_img_filename, mode='L'))\n",
    "# test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T08:26:53.181586Z",
     "start_time": "2018-01-15T08:22:10.900Z"
    }
   },
   "outputs": [],
   "source": [
    "tables_by_image, grids_by_image = parse_tables_from_images([test_image],\n",
    "                                                           det_test_net,\n",
    "                                                           cell_test_base_segm_model,\n",
    "                                                           cell_test_net,\n",
    "                                                           cuda=True,\n",
    "                                                           cell_batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T08:26:53.182214Z",
     "start_time": "2018-01-15T08:22:10.911Z"
    }
   },
   "outputs": [],
   "source": [
    "test_grid_ic_rels = grids_by_image[0][0][-1]\n",
    "print('test_grid_ic_rels', len(test_grid_ic_rels), numpy.array(list(test_grid_ic_rels.values())).mean(0))\n",
    "test_grid_ic_rels_sym = make_intracell_rels_symmetric(test_grid_ic_rels)\n",
    "print('test_grid_ic_rels_sym', len(test_grid_ic_rels_sym), numpy.array(list(test_grid_ic_rels_sym.values())).mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T08:26:53.182841Z",
     "start_time": "2018-01-15T08:22:10.922Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(get_either(test_grid_ic_rels, (5, 14)))\n",
    "make_demo_mask_from_grid_info(test_image, grids_by_image[0][0], min_prob=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T08:26:53.183471Z",
     "start_time": "2018-01-15T08:22:10.932Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_image_segm_mask = get_segm_mask_batch([test_image], cell_test_base_segm_model)\n",
    "# arr_to_img(mask_to_img(test_image_segm_mask[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T08:26:53.184193Z",
     "start_time": "2018-01-15T08:22:10.943Z"
    }
   },
   "outputs": [],
   "source": [
    "# make_demo_mask_from_parsed_table(test_image, tables_by_image[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T10:14:15.122857Z",
     "start_time": "2018-01-16T10:14:15.020294Z"
    }
   },
   "outputs": [],
   "source": [
    "def image_box_to_pdf_coords(box, cropbox):\n",
    "    return convert_coords_to_pq(numpy.array(box) * PIXELS_TO_POINTS_FACTOR, cropbox)\n",
    "\n",
    "def process_pdf(in_file, det_model, segm_model, cell_model, tmp_dir_prefix='/tmp', pages=None, cuda=True, cell_batch_size=64, min_cols=2, min_rows=2, min_cells_with_text=0.5):\n",
    "    result = []\n",
    "    pdf = PdfMinerWrapper(in_file)\n",
    "    pdf.load()\n",
    "    pdf_basename = os.path.splitext(os.path.basename(in_file))[0]\n",
    "    with tempfile.TemporaryDirectory(dir=tmp_dir_prefix) as wd:\n",
    "        page_filenames = pdf_to_pages(in_file, wd, pages=pages)\n",
    "\n",
    "        for page_fname in page_filenames:\n",
    "            page_i = int(os.path.splitext(os.path.basename(page_fname))[0])\n",
    "            cropbox = pdf.get_page(page_i)[1].cropbox\n",
    "\n",
    "            page_image = fit_image_size(load_image_opaque(page_fname, mode='L'))\n",
    "            tables_by_image, grids_by_image = parse_tables_from_images([page_image],\n",
    "                                                                       det_model,\n",
    "                                                                       segm_model,\n",
    "                                                                       cell_model,\n",
    "                                                                       cuda=cuda,\n",
    "                                                                       cell_batch_size=cell_batch_size)\n",
    "            page_result = []\n",
    "            for body, cells, rows, cols in tables_by_image[0]:\n",
    "                if len(rows) < min_rows or len(cols) < min_cols:\n",
    "                    continue\n",
    "                cell_texts = [pdf.get_text(page_i, [image_box_to_pdf_coords(cell, cropbox)])\n",
    "                              for cell in cells]\n",
    "                cells_with_text = sum(1 for ct in cell_texts if len(ct.strip()) > 0)\n",
    "                if cells_with_text / float(len(cells)) < min_cells_with_text:\n",
    "                    continue\n",
    "                page_result.append((image_box_to_pdf_coords(body, cropbox),\n",
    "                                    [image_box_to_pdf_coords(cell, cropbox) for cell in cells],\n",
    "                                    [image_box_to_pdf_coords(row, cropbox) for row in rows],\n",
    "                                    [image_box_to_pdf_coords(col, cropbox) for col in cols],\n",
    "                                    cell_texts))\n",
    "#                 page_result.append((body,\n",
    "#                                     cells,\n",
    "#                                     rows,\n",
    "#                                     cols,\n",
    "#                                     cell_texts))\n",
    "#                 print(cells[0])\n",
    "#                 display(make_demo_mask_from_parsed_table(page_image, (body, cells, rows, cols)))\n",
    "            result.append((page_i, page_result))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T11:42:26.135220Z",
     "start_time": "2018-01-15T11:40:48.598931Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "test_pdf_tables = process_pdf('./data/dc/src_docs/2010-1.pdf',\n",
    "                              det_test_net,\n",
    "                              cell_test_base_segm_model,\n",
    "                              cell_test_net,\n",
    "                              pages=[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export markup to ICDAR 2013 Table Competition format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T10:38:35.557818Z",
     "start_time": "2018-01-16T10:38:35.365236Z"
    }
   },
   "outputs": [],
   "source": [
    "ICDAR_GOOD_TXT_RE = re.compile(r'\\w+')\n",
    "def clean_text_for_icdar(t):\n",
    "    return ''.join(ICDAR_GOOD_TXT_RE.findall(t)).upper()\n",
    "\n",
    "\n",
    "def make_icdar_bb(root, bb):\n",
    "    left, bottom, right, top = bb\n",
    "    root.append(lxml.etree.Element('bounding-box',\n",
    "                                   x1=str(int(math.floor(left))),\n",
    "                                   y1=str(int(math.floor(bottom))),\n",
    "                                   x2=str(int(math.ceil(right))),\n",
    "                                   y2=str(int(math.ceil(top)))))\n",
    "\n",
    "\n",
    "def table2icdar(parent, page_no, table, table_id, for_region=True):\n",
    "    body, cells, rows, cols, cell_texts = table\n",
    "\n",
    "    table_root = lxml.etree.Element('table',\n",
    "                                    id=str(table_id))\n",
    "    parent.append(table_root)\n",
    "\n",
    "    region = lxml.etree.Element('region',\n",
    "                                **{'id': '1',\n",
    "                                   'page': str(page_no+1),\n",
    "#                                    'col-increment': '0',\n",
    "#                                    'row-increment': '0'\n",
    "                                  })\n",
    "    table_root.append(region)\n",
    "\n",
    "    if for_region:\n",
    "        make_icdar_bb(region, body)\n",
    "    else:\n",
    "#         print('!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        cell2rows = group_by_intersection(rows, cells)\n",
    "        cell2cols = group_by_intersection(cols, cells)\n",
    "#         print('structure')\n",
    "#         print(len(cells))\n",
    "#         print(cell2rows)\n",
    "#         print(cell2cols)\n",
    "        for i, (cell, txt) in enumerate(zip(cells, cell_texts)):\n",
    "            if len(cell2cols[i]) == 0 or len(cell2rows[i]) == 0:\n",
    "#                 print('unlinked cell!!')\n",
    "                continue\n",
    "            cell_node = lxml.etree.Element('cell',\n",
    "                                           **{'id': str(i),\n",
    "                                              'start-col': str(min(cell2cols[i])),\n",
    "                                              'start-row' : str(min(cell2rows[i]))})\n",
    "            make_icdar_bb(cell_node, cell)\n",
    "            content = lxml.etree.Element('content')\n",
    "            content.text = clean_text_for_icdar(txt)\n",
    "            cell_node.append(content)\n",
    "            region.append(cell_node)\n",
    "\n",
    "\n",
    "def pdf_tables2icdar(outfile, tables, for_region=True):\n",
    "    root = lxml.etree.Element('document',\n",
    "                              filename=os.path.basename(outfile))\n",
    "    table_id = 0\n",
    "    for page_no, page_tables in tables:\n",
    "        for table in page_tables:\n",
    "            table2icdar(root, page_no, table, table_id, for_region=for_region)\n",
    "            table_id += 1\n",
    "    with open(outfile, 'w') as f:\n",
    "        f.write(lxml.etree.tostring(root, pretty_print=True).decode('utf8'))\n",
    "\n",
    "\n",
    "def process_pdf_icdar(infile, outdir, det_model, segm_model, cell_model):\n",
    "    doc_tables = process_pdf(infile, det_model, segm_model, cell_model)\n",
    "    basename = os.path.splitext(os.path.basename(infile))[0]\n",
    "    pdf_tables2icdar(os.path.join(outdir, basename + '-reg-result.xml'),\n",
    "                     doc_tables,\n",
    "                     for_region=True)\n",
    "    pdf_tables2icdar(os.path.join(outdir, basename + '-str-result.xml'),\n",
    "                     doc_tables,\n",
    "                     for_region=False)\n",
    "\n",
    "\n",
    "def process_pdf_files_icdar(infiles, outdir, det_model, segm_model, cell_model):\n",
    "    for file in tqdm.tqdm(list(infiles)):\n",
    "        process_pdf_icdar(file, outdir, det_model, segm_model, cell_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T10:45:45.973624Z",
     "start_time": "2018-01-16T10:38:37.755930Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "process_pdf_icdar('./data/icdar2013-competition-dataset-with-gt/competition-dataset-us/us-001.pdf',\n",
    "                  './data/icdar2013-pred/',\n",
    "                  det_test_net,\n",
    "                  cell_test_base_segm_model,\n",
    "                  cell_test_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T10:29:23.383215Z",
     "start_time": "2018-01-16T10:29:12.484916Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/67 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-d18f78766769>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                         \u001b[0mdet_test_net\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                         \u001b[0mcell_test_base_segm_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                         cell_test_net)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-81-2f2755151d69>\u001b[0m in \u001b[0;36mprocess_pdf_files_icdar\u001b[0;34m(infiles, outdir, det_model, segm_model, cell_model)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_pdf_files_icdar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdet_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mprocess_pdf_icdar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdet_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-81-2f2755151d69>\u001b[0m in \u001b[0;36mprocess_pdf_icdar\u001b[0;34m(infile, outdir, det_model, segm_model, cell_model)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_pdf_icdar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdet_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mdoc_tables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdet_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mbasename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     pdf_tables2icdar(os.path.join(outdir, basename + '-reg-result.xml'),\n",
      "\u001b[0;32m<ipython-input-76-8c10506c1fab>\u001b[0m in \u001b[0;36mprocess_pdf\u001b[0;34m(in_file, det_model, segm_model, cell_model, tmp_dir_prefix, pages, cuda, cell_batch_size, min_cols, min_rows, min_cells_with_text)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpage_fname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpage_filenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mpage_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mcropbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcropbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mpage_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_image_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_image_opaque\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_fname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebook/latex_dataset.py\u001b[0m in \u001b[0;36mget_page\u001b[0;34m(self, page_no)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0minterpreter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPDFPageInterpreter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrsrcmgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPDFPage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_pages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpage_no\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/pdfminer/pdfinterp.py\u001b[0m in \u001b[0;36mprocess_page\u001b[0;34m(self, page)\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_contents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresources\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/pdfminer/converter.py\u001b[0m in \u001b[0;36mend_page\u001b[0;34m(self, page)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLTPage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_item\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpageno\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreceive_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/pdfminer/layout.py\u001b[0m in \u001b[0;36manalyze\u001b[0;34m(self, laparams)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0mtextboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_textlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlaparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtextlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mlaparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxes_flow\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlaparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxes_flow\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtextboxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_textboxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlaparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtextboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m             \u001b[0massigner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIndexAssigner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/pdfminer/layout.py\u001b[0m in \u001b[0;36mgroup_textboxes\u001b[0;34m(self, laparams, boxes)\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mother\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mplane\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                 \u001b[0mdists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             \u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m             \u001b[0mplane\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplane\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplane\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/pdfminer/utils.py\u001b[0m in \u001b[0;36mcsort\u001b[0;34m(objs, key)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;34m\"\"\"Order-preserving sorting function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0midxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/lib/python3.6/site-packages/pdfminer/utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;34m\"\"\"Order-preserving sorting function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0midxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "process_pdf_files_icdar(glob.glob('./data/icdar2013-competition-dataset-with-gt/*/*.pdf'),\n",
    "                        './data/icdar2013-pred/',\n",
    "                        det_test_net,\n",
    "                        cell_test_base_segm_model,\n",
    "                        cell_test_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T10:37:57.536240Z",
     "start_time": "2018-01-16T10:37:57.495524Z"
    }
   },
   "outputs": [],
   "source": [
    "class XmlValidator(object):\n",
    "    def __init__(self, dtd_file):\n",
    "        with open(dtd_file, 'r') as f:\n",
    "            tree = lxml.etree.parse(f)\n",
    "            self.schema = lxml.etree.XMLSchema(tree)\n",
    "\n",
    "    def __call__(self, xml_file):\n",
    "        with open(xml_file, 'r') as f:\n",
    "            tree = lxml.etree.parse(f)\n",
    "        is_valid = self.schema.validate(tree)\n",
    "        if is_valid:\n",
    "            errors = []\n",
    "        else:\n",
    "            errors = self.schema.error_log\n",
    "        return is_valid, errors\n",
    "\n",
    "reg_dtd = XmlValidator('./data/competition-entry-region-model.xsd')\n",
    "str_dtd = XmlValidator('./data/competition-entry-structure-model.xsd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T10:37:57.646861Z",
     "start_time": "2018-01-16T10:37:57.622375Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, [])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_dtd('./data/icdar2013-pred/us-001-reg-result.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-16T10:37:57.810201Z",
     "start_time": "2018-01-16T10:37:57.785252Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False,\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:4:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:8:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:12:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:16:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:20:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:24:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:28:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:32:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:36:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:40:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:44:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:48:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:52:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:56:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:60:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:64:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:68:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:72:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:76:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:80:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:84:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:88:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:92:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:96:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:100:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:104:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:108:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:112:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:116:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:120:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:124:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:128:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:132:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:136:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:140:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:144:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:148:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:152:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:156:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:160:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:164:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:168:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:172:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:176:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:180:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:184:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:188:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:192:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:196:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:200:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:204:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:208:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:212:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:216:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:220:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:224:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:228:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:232:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:236:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:240:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:244:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:248:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:252:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:256:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:260:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:264:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:268:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:272:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:276:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:280:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:284:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:288:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:292:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:296:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:300:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:304:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:308:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:312:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:316:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:320:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:324:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:328:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:332:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:336:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:340:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:344:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:348:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:352:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:356:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:360:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:364:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:368:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:376:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:380:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:384:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:388:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:392:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:396:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:400:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:404:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:408:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:412:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:416:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:420:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:424:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:432:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:436:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:440:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:444:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:448:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:452:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:456:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:460:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:468:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:472:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:476:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:480:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:484:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:488:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:492:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:496:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:500:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:504:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:508:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:512:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:516:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:520:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:524:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:528:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:532:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:536:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:540:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:544:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:548:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:552:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:556:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.\n",
       " /notebook/data/icdar2013-pred/us-001-str-result.xml:560:0:ERROR:SCHEMASV:SCHEMAV_CVC_COMPLEX_TYPE_4: Element 'cell': The attribute 'id' is required but missing.)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_dtd('./data/icdar2013-pred/us-001-str-result.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process images from a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-20T11:50:23.455373Z",
     "start_time": "2017-12-20T11:49:40.539Z"
    }
   },
   "outputs": [],
   "source": [
    "import svgwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-20T11:50:23.456613Z",
     "start_time": "2017-12-20T11:49:40.562Z"
    }
   },
   "outputs": [],
   "source": [
    "def color_tuple_to_html(c):\n",
    "    return '#' + '{:02x}{:02x}{:02x}'.format(*c)\n",
    "\n",
    "\n",
    "def extracted_tables_to_svg(page_img, tables, out_file):\n",
    "    img_buf = io.StringIO()\n",
    "    page_img.save(img_buf, format=\"png\")\n",
    "    img_str = base64.b64encode(img_buf.getvalue()).decode('ascii')\n",
    "    img_data_url = 'data:image/png;base64,' + img_str\n",
    "\n",
    "    dwg = svgwrite.Drawing(out_file,\n",
    "                           size=page_img.size,\n",
    "                           profile='tiny')\n",
    "    dwg.add(dwg.image(img_data_url))\n",
    "\n",
    "    for table_info in tables:\n",
    "        for cls, (y1, x1, y2, x2) in make_boxes_with_channels_from_parsed_table(table_info):\n",
    "            dwg.add(dwg.rect((x1, y1),\n",
    "                             (x2 - x1, y2 - y1),\n",
    "                             **{'fill' : 'none',\n",
    "                                'stroke' : color_tuple_to_html(CLS_TO_COLOR[cls]),\n",
    "                                'stroke-opacity' : 1}))\n",
    "\n",
    "    dwg.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T14:01:36.812780Z",
     "start_time": "2017-12-27T14:01:36.720490Z"
    }
   },
   "outputs": [],
   "source": [
    "play_files = list(glob.glob('./data/dc/docs_pages_flat/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T14:02:24.430236Z",
     "start_time": "2017-12-27T14:02:24.403045Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/dc/docs_pages_flat/2012-3.pdf_0001.png',\n",
       " './data/dc/docs_pages_flat/2003-16.pdf_0004.png',\n",
       " './data/dc/docs_pages_flat/2002-5-mucin-gene-muc1-transfected-dendritic-cells-as-vaccine-results-of-a-phase-i-ii-clinical-trial.pdf_0001.png',\n",
       " './data/dc/docs_pages_flat/2010-1.pdf_0002.png',\n",
       " './data/dc/docs_pages_flat/2003-9.pdf_0006.png',\n",
       " './data/dc/docs_pages_flat/2001-10-dendritic-cell-based-xenoantigen-vaccination-for-prostate-cancer-immunotherapy.pdf_0005.png',\n",
       " './data/dc/docs_pages_flat/2011-5.pdf_0001.png',\n",
       " './data/dc/docs_pages_flat/2003-6.pdf_0003.png',\n",
       " './data/dc/docs_pages_flat/2002-2-dendritic-cell-immunotherapy-for-patients-with-metastatic-renal-cell-carcinoma-university-of-tokyo-experience.pdf_0004.png',\n",
       " './data/dc/docs_pages_flat/2003-16.pdf_0005.png']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_files[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "notify_time": "10",
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "138px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "848px",
    "left": "0px",
    "right": "1708px",
    "top": "111px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
