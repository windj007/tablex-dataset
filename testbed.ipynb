{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Play with the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T17:25:26.014967Z",
     "start_time": "2017-07-17T17:25:25.889183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('/notebook/imgaug/')\n",
    "\n",
    "import os, numpy, glob, collections, random, h5py, shutil, pandas, \\\n",
    "    time, functools, json, traceback, itertools\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display, SVG\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import imgaug.imgaug as ia\n",
    "from imgaug.imgaug import augmenters as iaa\n",
    "from imgaug.imgaug import parameters as iap\n",
    "\n",
    "from prepare_images_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build some statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T14:51:19.925918Z",
     "start_time": "2017-07-17T14:51:19.624100Z"
    }
   },
   "outputs": [],
   "source": [
    "hist_bins = numpy.arange(0, 255.1, 10, dtype=numpy.uint8)\n",
    "half_bins = hist_bins.shape[0] // 2\n",
    "def get_image_stat(fname):\n",
    "    img = Image.open(fname)\n",
    "    pixels = numpy.asarray(img)\n",
    "    return numpy.histogram(pixels, bins = hist_bins)[0]\n",
    "\n",
    "\n",
    "def contains_white(fname):\n",
    "    img = Image.open(fname)\n",
    "    pixels = numpy.asarray(img)\n",
    "    return (pixels > 0).any()\n",
    "\n",
    "\n",
    "def get_positive_prefixes(dirname, n_jobs=20):\n",
    "    filenames = glob.glob(os.path.join(dirname, '*_out.png'))\n",
    "    white_info = Parallel(n_jobs=n_jobs)(delayed(contains_white)(fname)\n",
    "                                         for fname in filenames)\n",
    "    return [fname[:-8] for fname, has_white\n",
    "            in zip(filenames, white_info)\n",
    "            if has_white]\n",
    "\n",
    "\n",
    "def copy_only_positive(src_dir, target_dir, n_jobs=20):\n",
    "    for prefix in get_positive_prefixes(src_dir, n_jobs=n_jobs):\n",
    "        shutil.copy2(prefix + '_in.png', target_dir)\n",
    "        shutil.copy2(prefix + '_out.png', target_dir)\n",
    "\n",
    "\n",
    "def aggregate_stat_for_multiple_images(fnames):\n",
    "    marginal_hist = numpy.zeros(hist_bins.shape[0] - 1,\n",
    "                                dtype=numpy.float)\n",
    "    number_of_white_images = 0\n",
    "    img_cnt = 0.0\n",
    "    for cur_hist in Parallel(n_jobs=20)(delayed(get_image_stat)(fname)\n",
    "                                        for fname in fnames):\n",
    "        marginal_hist += cur_hist\n",
    "        img_cnt += 1\n",
    "        if cur_hist[half_bins:].sum() > 0:\n",
    "            number_of_white_images += 1\n",
    "    return marginal_hist / img_cnt, number_of_white_images\n",
    "\n",
    "\n",
    "def folder_stat(dirname):\n",
    "    fig, (in_ax, out_ax) = plt.subplots(2)\n",
    "\n",
    "    in_files = list(glob.glob(os.path.join(dirname, '*_in.png')))\n",
    "    in_files_cnt = len(in_files)\n",
    "    in_hist, in_white_cnt = aggregate_stat_for_multiple_images(in_files)\n",
    "    in_ax.bar(hist_bins[:-1], in_hist, label='In')\n",
    "    in_ax.legend()\n",
    "    in_percent = in_white_cnt / in_files_cnt * 100.0\n",
    "    print(f'In white {in_white_cnt} / {in_files_cnt}, {in_percent}%')\n",
    "\n",
    "    out_files = glob.glob(os.path.join(dirname, '*_out.png'))\n",
    "    out_files_cnt = len(out_files)\n",
    "    out_hist, out_white_cnt = aggregate_stat_for_multiple_images(out_files)\n",
    "    out_ax.bar(hist_bins[:-1], out_hist, label='Out')\n",
    "    out_ax.legend()\n",
    "    out_percent = out_white_cnt / out_files_cnt * 100.0\n",
    "    print(f'Out white {out_white_cnt} / {out_files_cnt}, {out_percent}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T14:51:20.309590Z",
     "start_time": "2017-07-17T14:51:20.236482Z"
    }
   },
   "outputs": [],
   "source": [
    "# copy_only_positive('./data/5_ready/train/', './data/5_ready/train_only_positive/')\n",
    "# copy_only_positive('./data/5_ready/val/', './data/5_ready/val_only_positive/')\n",
    "# copy_only_positive('./data/5_ready/test/', './data/5_ready/test_only_positive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T14:51:20.453963Z",
     "start_time": "2017-07-17T14:51:20.380551Z"
    }
   },
   "outputs": [],
   "source": [
    "# folder_stat('./data/5_ready/train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T14:51:20.614590Z",
     "start_time": "2017-07-17T14:51:20.539224Z"
    }
   },
   "outputs": [],
   "source": [
    "# folder_stat('./data/5_ready/train_only_positive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T14:51:20.759791Z",
     "start_time": "2017-07-17T14:51:20.683707Z"
    }
   },
   "outputs": [],
   "source": [
    "# folder_stat('./data/5_ready/test/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Train for Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-20T13:53:53.224734Z",
     "start_time": "2017-07-20T13:53:53.125494Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert_directory_to_hdf5('/notebook/data/7_full/train/', '/notebook/data/7_full/train.hdf')\n",
    "# convert_directory_to_hdf5('/notebook/data/7_full/val/', '/notebook/data/7_full/val.hdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-17T14:51:23.512704Z",
     "start_time": "2017-07-17T14:51:23.446724Z"
    }
   },
   "outputs": [],
   "source": [
    "# !rm /notebook/data/5_ready/*.hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-07-20T15:09:06.971Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# convert_directory_to_hdf5('/notebook/data/5_ready/train/', '/notebook/data/5_ready/train.hdf')\n",
    "# convert_directory_to_hdf5('/notebook/data/5_ready/val/', '/notebook/data/5_ready/val.hdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-20T14:27:03.237808Z",
     "start_time": "2017-07-20T14:27:03.184968Z"
    }
   },
   "outputs": [],
   "source": [
    "# for fold in glob.glob('/notebook/data/6_eval/*/'):\n",
    "#     convert_directory_to_hdf5(os.path.join(fold, 'train'), os.path.join(fold, 'train.hdf'))\n",
    "#     convert_directory_to_hdf5(os.path.join(fold, 'val'), os.path.join(fold, 'val.hdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-07-12T07:50:15.187Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_h5.close()\n",
    "# val_h5.close()\n",
    "# test_h5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-21T07:26:21.120226Z",
     "start_time": "2017-07-21T07:26:19.828830Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_h5 = h5py.File('/notebook/data/5_ready/train.hdf', 'r')\n",
    "# val_h5 = h5py.File('/notebook/data/5_ready/val.hdf', 'r')\n",
    "# train_h5 = h5py.File('/notebook/data/7_full/train.hdf', 'r')\n",
    "# val_h5 = h5py.File('/notebook/data/7_full/val.hdf', 'r')\n",
    "\n",
    "# train_in, train_out = train_h5['in_data'], train_h5['out_data']\n",
    "# val_in, val_out = val_h5['in_data'], val_h5['out_data']\n",
    "\n",
    "# train_in, train_out = load_dataset('/notebook/data/5_ready/train/')\n",
    "# val_in, val_out = load_dataset('/notebook/data/5_ready/val/')\n",
    "# train_in = (train_in * 255).astype('uint8')\n",
    "# train_out = (train_out * 255).astype('uint8')\n",
    "# val_in = (val_in * 255).astype('uint8')\n",
    "# val_out = (val_out * 255).astype('uint8')\n",
    "# print(train_in.shape, train_out.shape)\n",
    "# print(val_in.shape, val_out.shape)\n",
    "# # print(test_in.shape, test_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-21T07:26:23.037895Z",
     "start_time": "2017-07-21T07:26:22.852346Z"
    }
   },
   "outputs": [],
   "source": [
    "# sample_i = 25\n",
    "# display(arr_to_img(train_in[sample_i, :, :, 0]))\n",
    "# display(arr_to_img(train_out[sample_i, :, :, :3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-21T07:26:28.495851Z",
     "start_time": "2017-07-21T07:26:28.380225Z"
    }
   },
   "outputs": [],
   "source": [
    "# sample_i = 14\n",
    "# display(arr_to_img(val_in[sample_i, :, :, 0]))\n",
    "# display(arr_to_img(val_out[sample_i, :, :, :3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_getter(in_dir, batch_size=1):\n",
    "    while True:\n",
    "        in_data, out_data = load_dataset(in_dir, n_jobs=6, take_n=batch_size)\n",
    "        in_data = (in_data * 255).astype('float32')\n",
    "        out_data = (out_data * 255).astype('float32')\n",
    "        yield ia.Batch(images=in_data,\n",
    "                       heatmaps=out_data)\n",
    "\n",
    "def make_batch_getter(in_dir, batch_size=32):\n",
    "    def _f():\n",
    "        yield from batch_getter(in_dir, batch_size=batch_size)\n",
    "    return _f\n",
    "\n",
    "def augmented_batch_gen(base_gen, augmenter, heatmaps_hooks=None):\n",
    "    for batch in base_gen():\n",
    "        det = augmenter.to_deterministic() if not augmenter.deterministic else augseq\n",
    "        images_aug = numpy.asarray(det.augment_images(batch.images)).astype('float32') / 255\n",
    "        heatmaps_aug = numpy.asarray(det.augment_images(batch.heatmaps, hooks=heatmaps_hooks)).astype('float32') / 255\n",
    "        yield (images_aug, heatmaps_aug)\n",
    "\n",
    "def make_augmented_batch_gen(base_gen, augmenter, heatmaps_hooks=None):\n",
    "    def _f():\n",
    "        yield from augmented_batch_gen(base_gen, augmenter, heatmaps_hooks=heatmaps_hooks)\n",
    "    return _f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# i = iter(make_batch_getter('./data/5_ready/train/')())\n",
    "# for _ in range(20):\n",
    "#     qq = next(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(next(iter(make_augmented_batch_gen(make_batch_getter(train_in, train_out), augmenter)()))[1].shape)\n",
    "# display(arr_to_img(next(iter(make_augmented_batch_gen(make_batch_getter(train_in, train_out), augmenter)()))[1][0, :, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define U-net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Val-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "TRANSFORM_TO_WIDTH = 400\n",
    "TRANSFORM_TO_HEIGHT = 400\n",
    "emboss_aug = iaa.Emboss(alpha=0.5, strength=13.5)\n",
    "window_aug = iaa.Window((TRANSFORM_TO_HEIGHT, TRANSFORM_TO_WIDTH))\n",
    "train_aug = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5),\n",
    "    iaa.Flipud(0.5),\n",
    "#     iaa.Affine(rotate=iap.DiscreteUniform(0, 3) * 90, cval=(0, 0, 255)),\n",
    "    iaa.CropAndPad(percent=(-0.10, 0.10), pad_cval=255),\n",
    "    emboss_aug,\n",
    "    window_aug\n",
    "])\n",
    "val_aug = iaa.Sequential([\n",
    "    emboss_aug,\n",
    "    window_aug\n",
    "])\n",
    "fake_batch = next(iter(make_augmented_batch_gen(make_batch_getter('/notebook/data/5_ready/train/',\n",
    "                                                                  batch_size=BATCH_SIZE),\n",
    "                                                train_aug)()))\n",
    "# for i in range(fake_batch[0].shape[0]):\n",
    "#     display(arr_to_img(fake_batch[0][i, :, :, 0]))\n",
    "#     display(arr_to_img(fake_batch[1][i, :, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-07-21T07:41:07.560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 29/320 [=>............................] - ETA: 244s - loss: 2.0701 - dice_coef_0: 0.0446 - dice_coef_1: 0.1664 - dice_coef_01: 0.1055 - categorical_crossentropy: 0.8985"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.6.0/lib/python3.6/site-packages/PIL/Image.py:914: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  'to RGBA images')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319/320 [============================>.] - ETA: 0s - loss: 1.4222 - dice_coef_0: 0.0839 - dice_coef_1: 0.2888 - dice_coef_01: 0.1864 - categorical_crossentropy: 0.5247Epoch 00000: val_dice_coef_01 improved from -inf to 0.12713, saving model to ./tb_logs/20171013_183551/model\n",
      "320/320 [==============================] - ETA: 0s - loss: 1.4201 - dice_coef_0: 0.0841 - dice_coef_1: 0.2900 - dice_coef_01: 0.1870 - categorical_crossentropy: 0.5239 - val_loss: 1.5789 - val_dice_coef_0: 0.0355 - val_dice_coef_1: 0.2188 - val_dice_coef_01: 0.1271 - val_categorical_crossentropy: 0.4468\n",
      "Epoch 2/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 1.1966 - dice_coef_0: 0.1294 - dice_coef_1: 0.3574 - dice_coef_01: 0.2434 - categorical_crossentropy: 0.4373Epoch 00001: val_dice_coef_01 improved from 0.12713 to 0.24085, saving model to ./tb_logs/20171013_183551/model\n",
      "320/320 [==============================] - ETA: 0s - loss: 1.1984 - dice_coef_0: 0.1294 - dice_coef_1: 0.3573 - dice_coef_01: 0.2433 - categorical_crossentropy: 0.4392 - val_loss: 1.1751 - val_dice_coef_0: 0.1145 - val_dice_coef_1: 0.3672 - val_dice_coef_01: 0.2408 - val_categorical_crossentropy: 0.4048\n",
      "Epoch 3/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 1.0849 - dice_coef_0: 0.1535 - dice_coef_1: 0.3941 - dice_coef_01: 0.2738 - categorical_crossentropy: 0.4037Epoch 00002: val_dice_coef_01 improved from 0.24085 to 0.26558, saving model to ./tb_logs/20171013_183551/model\n",
      "320/320 [==============================] - ETA: 0s - loss: 1.0847 - dice_coef_0: 0.1535 - dice_coef_1: 0.3937 - dice_coef_01: 0.2736 - categorical_crossentropy: 0.4032 - val_loss: 1.1305 - val_dice_coef_0: 0.1333 - val_dice_coef_1: 0.3979 - val_dice_coef_01: 0.2656 - val_categorical_crossentropy: 0.3971\n",
      "Epoch 4/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 1.0386 - dice_coef_0: 0.1653 - dice_coef_1: 0.4185 - dice_coef_01: 0.2919 - categorical_crossentropy: 0.3912Epoch 00003: val_dice_coef_01 improved from 0.26558 to 0.29671, saving model to ./tb_logs/20171013_183551/model\n",
      "320/320 [==============================] - ETA: 0s - loss: 1.0394 - dice_coef_0: 0.1652 - dice_coef_1: 0.4182 - dice_coef_01: 0.2917 - categorical_crossentropy: 0.3917 - val_loss: 0.9709 - val_dice_coef_0: 0.1542 - val_dice_coef_1: 0.4392 - val_dice_coef_01: 0.2967 - val_categorical_crossentropy: 0.3289\n",
      "Epoch 5/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 1.0554 - dice_coef_0: 0.1734 - dice_coef_1: 0.4110 - dice_coef_01: 0.2922 - categorical_crossentropy: 0.4010Epoch 00004: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 1.0574 - dice_coef_0: 0.1732 - dice_coef_1: 0.4100 - dice_coef_01: 0.2916 - categorical_crossentropy: 0.4013 - val_loss: 1.1298 - val_dice_coef_0: 0.1394 - val_dice_coef_1: 0.3574 - val_dice_coef_01: 0.2484 - val_categorical_crossentropy: 0.4054\n",
      "Epoch 6/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 1.0010 - dice_coef_0: 0.1909 - dice_coef_1: 0.4253 - dice_coef_01: 0.3081 - categorical_crossentropy: 0.3782Epoch 00005: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 1.0008 - dice_coef_0: 0.1909 - dice_coef_1: 0.4255 - dice_coef_01: 0.3082 - categorical_crossentropy: 0.3783 - val_loss: 1.0483 - val_dice_coef_0: 0.1597 - val_dice_coef_1: 0.3674 - val_dice_coef_01: 0.2635 - val_categorical_crossentropy: 0.3282\n",
      "Epoch 7/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.9820 - dice_coef_0: 0.1921 - dice_coef_1: 0.4406 - dice_coef_01: 0.3163 - categorical_crossentropy: 0.3733Epoch 00006: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.9820 - dice_coef_0: 0.1921 - dice_coef_1: 0.4404 - dice_coef_01: 0.3163 - categorical_crossentropy: 0.3733 - val_loss: 1.8917 - val_dice_coef_0: 0.1113 - val_dice_coef_1: 0.1650 - val_dice_coef_01: 0.1382 - val_categorical_crossentropy: 0.8070\n",
      "Epoch 8/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.9572 - dice_coef_0: 0.1970 - dice_coef_1: 0.4456 - dice_coef_01: 0.3213 - categorical_crossentropy: 0.3555Epoch 00007: val_dice_coef_01 improved from 0.29671 to 0.35662, saving model to ./tb_logs/20171013_183551/model\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.9558 - dice_coef_0: 0.1969 - dice_coef_1: 0.4465 - dice_coef_01: 0.3217 - categorical_crossentropy: 0.3549 - val_loss: 0.8558 - val_dice_coef_0: 0.1789 - val_dice_coef_1: 0.5344 - val_dice_coef_01: 0.3566 - val_categorical_crossentropy: 0.3130\n",
      "Epoch 9/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.9587 - dice_coef_0: 0.2036 - dice_coef_1: 0.4552 - dice_coef_01: 0.3294 - categorical_crossentropy: 0.3756Epoch 00008: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.9598 - dice_coef_0: 0.2039 - dice_coef_1: 0.4541 - dice_coef_01: 0.3290 - categorical_crossentropy: 0.3760 - val_loss: 1.6100 - val_dice_coef_0: 0.1391 - val_dice_coef_1: 0.2430 - val_dice_coef_01: 0.1910 - val_categorical_crossentropy: 0.7031\n",
      "Epoch 10/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.9206 - dice_coef_0: 0.2159 - dice_coef_1: 0.4658 - dice_coef_01: 0.3409 - categorical_crossentropy: 0.3566Epoch 00009: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.9209 - dice_coef_0: 0.2156 - dice_coef_1: 0.4659 - dice_coef_01: 0.3407 - categorical_crossentropy: 0.3567 - val_loss: 0.8978 - val_dice_coef_0: 0.1538 - val_dice_coef_1: 0.5160 - val_dice_coef_01: 0.3349 - val_categorical_crossentropy: 0.3093\n",
      "Epoch 11/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.9362 - dice_coef_0: 0.2204 - dice_coef_1: 0.4673 - dice_coef_01: 0.3439 - categorical_crossentropy: 0.3764Epoch 00010: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.9376 - dice_coef_0: 0.2206 - dice_coef_1: 0.4667 - dice_coef_01: 0.3436 - categorical_crossentropy: 0.3776 - val_loss: 0.9660 - val_dice_coef_0: 0.1360 - val_dice_coef_1: 0.4852 - val_dice_coef_01: 0.3106 - val_categorical_crossentropy: 0.3451\n",
      "Epoch 12/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.9112 - dice_coef_0: 0.2220 - dice_coef_1: 0.4628 - dice_coef_01: 0.3424 - categorical_crossentropy: 0.3441Epoch 00011: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.9123 - dice_coef_0: 0.2216 - dice_coef_1: 0.4623 - dice_coef_01: 0.3420 - categorical_crossentropy: 0.3446 - val_loss: 0.9373 - val_dice_coef_0: 0.1581 - val_dice_coef_1: 0.4956 - val_dice_coef_01: 0.3268 - val_categorical_crossentropy: 0.3378\n",
      "Epoch 13/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.9101 - dice_coef_0: 0.2161 - dice_coef_1: 0.4776 - dice_coef_01: 0.3468 - categorical_crossentropy: 0.3597Epoch 00012: val_dice_coef_01 improved from 0.35662 to 0.36967, saving model to ./tb_logs/20171013_183551/model\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.9095 - dice_coef_0: 0.2162 - dice_coef_1: 0.4776 - dice_coef_01: 0.3469 - categorical_crossentropy: 0.3592 - val_loss: 0.8559 - val_dice_coef_0: 0.2003 - val_dice_coef_1: 0.5391 - val_dice_coef_01: 0.3697 - val_categorical_crossentropy: 0.3012\n",
      "Epoch 14/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8852 - dice_coef_0: 0.2297 - dice_coef_1: 0.4883 - dice_coef_01: 0.3590 - categorical_crossentropy: 0.3474Epoch 00013: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8850 - dice_coef_0: 0.2297 - dice_coef_1: 0.4888 - dice_coef_01: 0.3592 - categorical_crossentropy: 0.3476 - val_loss: 0.8736 - val_dice_coef_0: 0.1681 - val_dice_coef_1: 0.5116 - val_dice_coef_01: 0.3399 - val_categorical_crossentropy: 0.3017\n",
      "Epoch 15/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.9564 - dice_coef_0: 0.2250 - dice_coef_1: 0.4771 - dice_coef_01: 0.3510 - categorical_crossentropy: 0.3505Epoch 00014: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.9563 - dice_coef_0: 0.2247 - dice_coef_1: 0.4769 - dice_coef_01: 0.3508 - categorical_crossentropy: 0.3502 - val_loss: 1.0890 - val_dice_coef_0: 0.2226 - val_dice_coef_1: 0.4829 - val_dice_coef_01: 0.3528 - val_categorical_crossentropy: 0.3028\n",
      "Epoch 16/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8957 - dice_coef_0: 0.2394 - dice_coef_1: 0.4779 - dice_coef_01: 0.3587 - categorical_crossentropy: 0.3575Epoch 00015: val_dice_coef_01 improved from 0.36967 to 0.37774, saving model to ./tb_logs/20171013_183551/model\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8949 - dice_coef_0: 0.2396 - dice_coef_1: 0.4783 - dice_coef_01: 0.3589 - categorical_crossentropy: 0.3571 - val_loss: 0.7802 - val_dice_coef_0: 0.2118 - val_dice_coef_1: 0.5437 - val_dice_coef_01: 0.3777 - val_categorical_crossentropy: 0.2662\n",
      "Epoch 17/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8666 - dice_coef_0: 0.2348 - dice_coef_1: 0.4955 - dice_coef_01: 0.3652 - categorical_crossentropy: 0.3377Epoch 00016: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8703 - dice_coef_0: 0.2347 - dice_coef_1: 0.4945 - dice_coef_01: 0.3646 - categorical_crossentropy: 0.3405 - val_loss: 0.9790 - val_dice_coef_0: 0.1616 - val_dice_coef_1: 0.4571 - val_dice_coef_01: 0.3094 - val_categorical_crossentropy: 0.3378\n",
      "Epoch 18/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8644 - dice_coef_0: 0.2421 - dice_coef_1: 0.4962 - dice_coef_01: 0.3692 - categorical_crossentropy: 0.3422Epoch 00017: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8647 - dice_coef_0: 0.2419 - dice_coef_1: 0.4961 - dice_coef_01: 0.3690 - categorical_crossentropy: 0.3424 - val_loss: 0.7966 - val_dice_coef_0: 0.2018 - val_dice_coef_1: 0.5341 - val_dice_coef_01: 0.3679 - val_categorical_crossentropy: 0.2642\n",
      "Epoch 19/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.9566 - dice_coef_0: 0.2335 - dice_coef_1: 0.4859 - dice_coef_01: 0.3597 - categorical_crossentropy: 0.3577Epoch 00018: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.9564 - dice_coef_0: 0.2333 - dice_coef_1: 0.4860 - dice_coef_01: 0.3596 - categorical_crossentropy: 0.3576 - val_loss: 0.8270 - val_dice_coef_0: 0.2107 - val_dice_coef_1: 0.5424 - val_dice_coef_01: 0.3766 - val_categorical_crossentropy: 0.3112\n",
      "Epoch 20/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.9149 - dice_coef_0: 0.2271 - dice_coef_1: 0.4674 - dice_coef_01: 0.3473 - categorical_crossentropy: 0.3561Epoch 00019: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.9143 - dice_coef_0: 0.2271 - dice_coef_1: 0.4678 - dice_coef_01: 0.3474 - categorical_crossentropy: 0.3558 - val_loss: 1.2404 - val_dice_coef_0: 0.1669 - val_dice_coef_1: 0.3090 - val_dice_coef_01: 0.2379 - val_categorical_crossentropy: 0.4685\n",
      "Epoch 21/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8758 - dice_coef_0: 0.2505 - dice_coef_1: 0.4750 - dice_coef_01: 0.3628 - categorical_crossentropy: 0.3452Epoch 00020: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8749 - dice_coef_0: 0.2503 - dice_coef_1: 0.4755 - dice_coef_01: 0.3629 - categorical_crossentropy: 0.3446 - val_loss: 0.7978 - val_dice_coef_0: 0.1942 - val_dice_coef_1: 0.5276 - val_dice_coef_01: 0.3609 - val_categorical_crossentropy: 0.2630\n",
      "Epoch 22/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8745 - dice_coef_0: 0.2392 - dice_coef_1: 0.4968 - dice_coef_01: 0.3680 - categorical_crossentropy: 0.3482Epoch 00021: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8737 - dice_coef_0: 0.2393 - dice_coef_1: 0.4969 - dice_coef_01: 0.3681 - categorical_crossentropy: 0.3477 - val_loss: 0.8083 - val_dice_coef_0: 0.2257 - val_dice_coef_1: 0.4742 - val_dice_coef_01: 0.3500 - val_categorical_crossentropy: 0.2552\n",
      "Epoch 23/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8353 - dice_coef_0: 0.2621 - dice_coef_1: 0.5004 - dice_coef_01: 0.3813 - categorical_crossentropy: 0.3268Epoch 00022: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8350 - dice_coef_0: 0.2622 - dice_coef_1: 0.5008 - dice_coef_01: 0.3815 - categorical_crossentropy: 0.3269 - val_loss: 0.8612 - val_dice_coef_0: 0.2035 - val_dice_coef_1: 0.5095 - val_dice_coef_01: 0.3565 - val_categorical_crossentropy: 0.2964\n",
      "Epoch 24/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8924 - dice_coef_0: 0.2473 - dice_coef_1: 0.4709 - dice_coef_01: 0.3591 - categorical_crossentropy: 0.3521Epoch 00023: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8921 - dice_coef_0: 0.2474 - dice_coef_1: 0.4707 - dice_coef_01: 0.3590 - categorical_crossentropy: 0.3518 - val_loss: 0.8146 - val_dice_coef_0: 0.1865 - val_dice_coef_1: 0.5328 - val_dice_coef_01: 0.3596 - val_categorical_crossentropy: 0.2566\n",
      "Epoch 25/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.9059 - dice_coef_0: 0.2390 - dice_coef_1: 0.4663 - dice_coef_01: 0.3527 - categorical_crossentropy: 0.3514Epoch 00024: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.9063 - dice_coef_0: 0.2387 - dice_coef_1: 0.4665 - dice_coef_01: 0.3526 - categorical_crossentropy: 0.3518 - val_loss: 0.8213 - val_dice_coef_0: 0.1941 - val_dice_coef_1: 0.5470 - val_dice_coef_01: 0.3705 - val_categorical_crossentropy: 0.2895\n",
      "Epoch 26/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8931 - dice_coef_0: 0.2355 - dice_coef_1: 0.4886 - dice_coef_01: 0.3621 - categorical_crossentropy: 0.3450Epoch 00025: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8927 - dice_coef_0: 0.2358 - dice_coef_1: 0.4888 - dice_coef_01: 0.3623 - categorical_crossentropy: 0.3450 - val_loss: 0.8397 - val_dice_coef_0: 0.1898 - val_dice_coef_1: 0.5310 - val_dice_coef_01: 0.3604 - val_categorical_crossentropy: 0.2983\n",
      "Epoch 27/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8848 - dice_coef_0: 0.2412 - dice_coef_1: 0.4858 - dice_coef_01: 0.3635 - categorical_crossentropy: 0.3466Epoch 00026: val_dice_coef_01 improved from 0.37774 to 0.38403, saving model to ./tb_logs/20171013_183551/model\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8865 - dice_coef_0: 0.2409 - dice_coef_1: 0.4857 - dice_coef_01: 0.3633 - categorical_crossentropy: 0.3480 - val_loss: 0.7578 - val_dice_coef_0: 0.2322 - val_dice_coef_1: 0.5358 - val_dice_coef_01: 0.3840 - val_categorical_crossentropy: 0.2604\n",
      "Epoch 28/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8409 - dice_coef_0: 0.2630 - dice_coef_1: 0.4985 - dice_coef_01: 0.3808 - categorical_crossentropy: 0.3284Epoch 00027: val_dice_coef_01 improved from 0.38403 to 0.38616, saving model to ./tb_logs/20171013_183551/model\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8407 - dice_coef_0: 0.2625 - dice_coef_1: 0.4986 - dice_coef_01: 0.3805 - categorical_crossentropy: 0.3280 - val_loss: 0.7933 - val_dice_coef_0: 0.2316 - val_dice_coef_1: 0.5407 - val_dice_coef_01: 0.3862 - val_categorical_crossentropy: 0.2806\n",
      "Epoch 29/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.9048 - dice_coef_0: 0.2503 - dice_coef_1: 0.5007 - dice_coef_01: 0.3755 - categorical_crossentropy: 0.3263Epoch 00028: val_dice_coef_01 improved from 0.38616 to 0.39637, saving model to ./tb_logs/20171013_183551/model\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.9041 - dice_coef_0: 0.2507 - dice_coef_1: 0.5007 - dice_coef_01: 0.3757 - categorical_crossentropy: 0.3261 - val_loss: 0.7784 - val_dice_coef_0: 0.2360 - val_dice_coef_1: 0.5568 - val_dice_coef_01: 0.3964 - val_categorical_crossentropy: 0.2845\n",
      "Epoch 30/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8758 - dice_coef_0: 0.2438 - dice_coef_1: 0.4915 - dice_coef_01: 0.3676 - categorical_crossentropy: 0.3488Epoch 00029: val_dice_coef_01 did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - ETA: 0s - loss: 0.8772 - dice_coef_0: 0.2440 - dice_coef_1: 0.4909 - dice_coef_01: 0.3674 - categorical_crossentropy: 0.3500 - val_loss: 0.8457 - val_dice_coef_0: 0.2141 - val_dice_coef_1: 0.4941 - val_dice_coef_01: 0.3541 - val_categorical_crossentropy: 0.2741\n",
      "Epoch 31/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8776 - dice_coef_0: 0.2436 - dice_coef_1: 0.4938 - dice_coef_01: 0.3687 - categorical_crossentropy: 0.3489Epoch 00030: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8780 - dice_coef_0: 0.2439 - dice_coef_1: 0.4926 - dice_coef_01: 0.3683 - categorical_crossentropy: 0.3487 - val_loss: 1.0989 - val_dice_coef_0: 0.1692 - val_dice_coef_1: 0.3497 - val_dice_coef_01: 0.2595 - val_categorical_crossentropy: 0.3466\n",
      "Epoch 32/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8353 - dice_coef_0: 0.2534 - dice_coef_1: 0.5089 - dice_coef_01: 0.3811 - categorical_crossentropy: 0.3270Epoch 00031: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8346 - dice_coef_0: 0.2537 - dice_coef_1: 0.5093 - dice_coef_01: 0.3815 - categorical_crossentropy: 0.3268 - val_loss: 0.7462 - val_dice_coef_0: 0.2077 - val_dice_coef_1: 0.5746 - val_dice_coef_01: 0.3912 - val_categorical_crossentropy: 0.2490\n",
      "Epoch 33/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8414 - dice_coef_0: 0.2452 - dice_coef_1: 0.5149 - dice_coef_01: 0.3801 - categorical_crossentropy: 0.3296Epoch 00032: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8416 - dice_coef_0: 0.2450 - dice_coef_1: 0.5148 - dice_coef_01: 0.3799 - categorical_crossentropy: 0.3297 - val_loss: 0.7684 - val_dice_coef_0: 0.2200 - val_dice_coef_1: 0.5587 - val_dice_coef_01: 0.3894 - val_categorical_crossentropy: 0.2661\n",
      "Epoch 34/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8592 - dice_coef_0: 0.2622 - dice_coef_1: 0.4894 - dice_coef_01: 0.3758 - categorical_crossentropy: 0.3443Epoch 00033: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8594 - dice_coef_0: 0.2620 - dice_coef_1: 0.4894 - dice_coef_01: 0.3757 - categorical_crossentropy: 0.3444 - val_loss: 0.7916 - val_dice_coef_0: 0.2161 - val_dice_coef_1: 0.5532 - val_dice_coef_01: 0.3846 - val_categorical_crossentropy: 0.2784\n",
      "Epoch 35/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8194 - dice_coef_0: 0.2379 - dice_coef_1: 0.5409 - dice_coef_01: 0.3894 - categorical_crossentropy: 0.3222Epoch 00034: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8184 - dice_coef_0: 0.2378 - dice_coef_1: 0.5415 - dice_coef_01: 0.3896 - categorical_crossentropy: 0.3217 - val_loss: 0.9067 - val_dice_coef_0: 0.1882 - val_dice_coef_1: 0.4944 - val_dice_coef_01: 0.3413 - val_categorical_crossentropy: 0.3079\n",
      "Epoch 36/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8379 - dice_coef_0: 0.2508 - dice_coef_1: 0.5102 - dice_coef_01: 0.3805 - categorical_crossentropy: 0.3303Epoch 00035: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8370 - dice_coef_0: 0.2513 - dice_coef_1: 0.5103 - dice_coef_01: 0.3808 - categorical_crossentropy: 0.3298 - val_loss: 1.4464 - val_dice_coef_0: 0.1623 - val_dice_coef_1: 0.2960 - val_dice_coef_01: 0.2291 - val_categorical_crossentropy: 0.4415\n",
      "Epoch 37/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8094 - dice_coef_0: 0.2714 - dice_coef_1: 0.5234 - dice_coef_01: 0.3974 - categorical_crossentropy: 0.3223Epoch 00036: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8104 - dice_coef_0: 0.2718 - dice_coef_1: 0.5225 - dice_coef_01: 0.3972 - categorical_crossentropy: 0.3231 - val_loss: 1.1018 - val_dice_coef_0: 0.1936 - val_dice_coef_1: 0.4945 - val_dice_coef_01: 0.3441 - val_categorical_crossentropy: 0.2760\n",
      "Epoch 38/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8117 - dice_coef_0: 0.2693 - dice_coef_1: 0.5199 - dice_coef_01: 0.3946 - categorical_crossentropy: 0.3161Epoch 00037: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8111 - dice_coef_0: 0.2693 - dice_coef_1: 0.5204 - dice_coef_01: 0.3948 - categorical_crossentropy: 0.3159 - val_loss: 1.1943 - val_dice_coef_0: 0.2285 - val_dice_coef_1: 0.2820 - val_dice_coef_01: 0.2553 - val_categorical_crossentropy: 0.4741\n",
      "Epoch 39/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8331 - dice_coef_0: 0.2622 - dice_coef_1: 0.5232 - dice_coef_01: 0.3927 - categorical_crossentropy: 0.3406Epoch 00038: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8343 - dice_coef_0: 0.2617 - dice_coef_1: 0.5227 - dice_coef_01: 0.3922 - categorical_crossentropy: 0.3411 - val_loss: 0.8198 - val_dice_coef_0: 0.2161 - val_dice_coef_1: 0.5003 - val_dice_coef_01: 0.3582 - val_categorical_crossentropy: 0.2438\n",
      "Epoch 40/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8749 - dice_coef_0: 0.2582 - dice_coef_1: 0.4816 - dice_coef_01: 0.3699 - categorical_crossentropy: 0.3488Epoch 00039: val_dice_coef_01 improved from 0.39637 to 0.40239, saving model to ./tb_logs/20171013_183551/model\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8744 - dice_coef_0: 0.2581 - dice_coef_1: 0.4815 - dice_coef_01: 0.3698 - categorical_crossentropy: 0.3482 - val_loss: 0.7137 - val_dice_coef_0: 0.2160 - val_dice_coef_1: 0.5888 - val_dice_coef_01: 0.4024 - val_categorical_crossentropy: 0.2301\n",
      "Epoch 41/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8260 - dice_coef_0: 0.2592 - dice_coef_1: 0.5128 - dice_coef_01: 0.3860 - categorical_crossentropy: 0.3264Epoch 00040: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8259 - dice_coef_0: 0.2597 - dice_coef_1: 0.5126 - dice_coef_01: 0.3862 - categorical_crossentropy: 0.3265 - val_loss: 0.8097 - val_dice_coef_0: 0.2095 - val_dice_coef_1: 0.5305 - val_dice_coef_01: 0.3700 - val_categorical_crossentropy: 0.2836\n",
      "Epoch 42/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8473 - dice_coef_0: 0.2622 - dice_coef_1: 0.4986 - dice_coef_01: 0.3804 - categorical_crossentropy: 0.3358Epoch 00041: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8474 - dice_coef_0: 0.2620 - dice_coef_1: 0.4988 - dice_coef_01: 0.3804 - categorical_crossentropy: 0.3360 - val_loss: 0.7402 - val_dice_coef_0: 0.2359 - val_dice_coef_1: 0.5641 - val_dice_coef_01: 0.4000 - val_categorical_crossentropy: 0.2498\n",
      "Epoch 43/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8093 - dice_coef_0: 0.2612 - dice_coef_1: 0.5258 - dice_coef_01: 0.3935 - categorical_crossentropy: 0.3168Epoch 00042: val_dice_coef_01 improved from 0.40239 to 0.41088, saving model to ./tb_logs/20171013_183551/model\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8092 - dice_coef_0: 0.2610 - dice_coef_1: 0.5260 - dice_coef_01: 0.3935 - categorical_crossentropy: 0.3168 - val_loss: 0.7292 - val_dice_coef_0: 0.2359 - val_dice_coef_1: 0.5859 - val_dice_coef_01: 0.4109 - val_categorical_crossentropy: 0.2504\n",
      "Epoch 44/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8195 - dice_coef_0: 0.2763 - dice_coef_1: 0.5162 - dice_coef_01: 0.3963 - categorical_crossentropy: 0.3321Epoch 00043: val_dice_coef_01 improved from 0.41088 to 0.41790, saving model to ./tb_logs/20171013_183551/model\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8221 - dice_coef_0: 0.2763 - dice_coef_1: 0.5151 - dice_coef_01: 0.3957 - categorical_crossentropy: 0.3338 - val_loss: 0.7028 - val_dice_coef_0: 0.2619 - val_dice_coef_1: 0.5739 - val_dice_coef_01: 0.4179 - val_categorical_crossentropy: 0.2408\n",
      "Epoch 45/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8211 - dice_coef_0: 0.2610 - dice_coef_1: 0.5205 - dice_coef_01: 0.3908 - categorical_crossentropy: 0.3266Epoch 00044: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8199 - dice_coef_0: 0.2610 - dice_coef_1: 0.5212 - dice_coef_01: 0.3911 - categorical_crossentropy: 0.3259 - val_loss: 0.8968 - val_dice_coef_0: 0.1878 - val_dice_coef_1: 0.5041 - val_dice_coef_01: 0.3460 - val_categorical_crossentropy: 0.3282\n",
      "Epoch 46/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8449 - dice_coef_0: 0.2626 - dice_coef_1: 0.5018 - dice_coef_01: 0.3822 - categorical_crossentropy: 0.3340Epoch 00045: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8443 - dice_coef_0: 0.2630 - dice_coef_1: 0.5014 - dice_coef_01: 0.3822 - categorical_crossentropy: 0.3337 - val_loss: 0.7130 - val_dice_coef_0: 0.2334 - val_dice_coef_1: 0.5808 - val_dice_coef_01: 0.4071 - val_categorical_crossentropy: 0.2324\n",
      "Epoch 47/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8157 - dice_coef_0: 0.2692 - dice_coef_1: 0.5062 - dice_coef_01: 0.3877 - categorical_crossentropy: 0.3182Epoch 00046: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8154 - dice_coef_0: 0.2687 - dice_coef_1: 0.5064 - dice_coef_01: 0.3876 - categorical_crossentropy: 0.3177 - val_loss: 0.8762 - val_dice_coef_0: 0.2032 - val_dice_coef_1: 0.4841 - val_dice_coef_01: 0.3436 - val_categorical_crossentropy: 0.2851\n",
      "Epoch 48/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8135 - dice_coef_0: 0.2645 - dice_coef_1: 0.5240 - dice_coef_01: 0.3943 - categorical_crossentropy: 0.3259Epoch 00047: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8126 - dice_coef_0: 0.2644 - dice_coef_1: 0.5245 - dice_coef_01: 0.3944 - categorical_crossentropy: 0.3252 - val_loss: 0.7821 - val_dice_coef_0: 0.2232 - val_dice_coef_1: 0.5622 - val_dice_coef_01: 0.3927 - val_categorical_crossentropy: 0.2643\n",
      "Epoch 49/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.7994 - dice_coef_0: 0.2727 - dice_coef_1: 0.5278 - dice_coef_01: 0.4003 - categorical_crossentropy: 0.3141Epoch 00048: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.7985 - dice_coef_0: 0.2729 - dice_coef_1: 0.5278 - dice_coef_01: 0.4004 - categorical_crossentropy: 0.3135 - val_loss: 0.7838 - val_dice_coef_0: 0.2266 - val_dice_coef_1: 0.5428 - val_dice_coef_01: 0.3847 - val_categorical_crossentropy: 0.2689\n",
      "Epoch 50/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8192 - dice_coef_0: 0.2797 - dice_coef_1: 0.5055 - dice_coef_01: 0.3926 - categorical_crossentropy: 0.3288Epoch 00049: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8200 - dice_coef_0: 0.2798 - dice_coef_1: 0.5054 - dice_coef_01: 0.3926 - categorical_crossentropy: 0.3297 - val_loss: 0.8655 - val_dice_coef_0: 0.1695 - val_dice_coef_1: 0.5058 - val_dice_coef_01: 0.3376 - val_categorical_crossentropy: 0.2792\n",
      "Epoch 51/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8382 - dice_coef_0: 0.2617 - dice_coef_1: 0.5028 - dice_coef_01: 0.3822 - categorical_crossentropy: 0.3352Epoch 00050: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8385 - dice_coef_0: 0.2619 - dice_coef_1: 0.5027 - dice_coef_01: 0.3823 - categorical_crossentropy: 0.3356 - val_loss: 0.7498 - val_dice_coef_0: 0.2049 - val_dice_coef_1: 0.5439 - val_dice_coef_01: 0.3744 - val_categorical_crossentropy: 0.2249\n",
      "Epoch 52/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.7934 - dice_coef_0: 0.2777 - dice_coef_1: 0.5210 - dice_coef_01: 0.3993 - categorical_crossentropy: 0.3094Epoch 00051: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.7935 - dice_coef_0: 0.2776 - dice_coef_1: 0.5204 - dice_coef_01: 0.3990 - categorical_crossentropy: 0.3092 - val_loss: 0.7812 - val_dice_coef_0: 0.2313 - val_dice_coef_1: 0.5843 - val_dice_coef_01: 0.4078 - val_categorical_crossentropy: 0.2723\n",
      "Epoch 53/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8005 - dice_coef_0: 0.2825 - dice_coef_1: 0.5224 - dice_coef_01: 0.4024 - categorical_crossentropy: 0.3237Epoch 00052: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8016 - dice_coef_0: 0.2823 - dice_coef_1: 0.5218 - dice_coef_01: 0.4021 - categorical_crossentropy: 0.3244 - val_loss: 0.7745 - val_dice_coef_0: 0.2100 - val_dice_coef_1: 0.5329 - val_dice_coef_01: 0.3715 - val_categorical_crossentropy: 0.2452\n",
      "Epoch 54/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.7903 - dice_coef_0: 0.2761 - dice_coef_1: 0.5300 - dice_coef_01: 0.4031 - categorical_crossentropy: 0.3126Epoch 00053: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.7952 - dice_coef_0: 0.2760 - dice_coef_1: 0.5287 - dice_coef_01: 0.4023 - categorical_crossentropy: 0.3162 - val_loss: 0.8254 - val_dice_coef_0: 0.1960 - val_dice_coef_1: 0.5341 - val_dice_coef_01: 0.3650 - val_categorical_crossentropy: 0.2706\n",
      "Epoch 55/200\n",
      "319/320 [============================>.] - ETA: 0s - loss: 0.8767 - dice_coef_0: 0.2689 - dice_coef_1: 0.5095 - dice_coef_01: 0.3892 - categorical_crossentropy: 0.3189Epoch 00054: val_dice_coef_01 did not improve\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.8769 - dice_coef_0: 0.2688 - dice_coef_1: 0.5094 - dice_coef_01: 0.3891 - categorical_crossentropy: 0.3192 - val_loss: 0.7990 - val_dice_coef_0: 0.1925 - val_dice_coef_1: 0.5684 - val_dice_coef_01: 0.3805 - val_categorical_crossentropy: 0.2686\n",
      "Epoch 00054: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = get_unet_row_col_info(fake_batch[0].shape[1:], fake_batch[1][0].shape[-1])\n",
    "# model.summary()\n",
    "# display(SVG(model_to_dot(model).create(prog='dot', format='svg')))\n",
    "\n",
    "log_dir = os.path.join('.',\n",
    "                       'tb_logs',\n",
    "                       datetime.datetime.now().strftime('%Y%m%d_%H%M%S'))\n",
    "\n",
    "model_file = os.path.join(log_dir, 'model')\n",
    "# model_file = './full_model'\n",
    "\n",
    "if os.path.exists(model_file):\n",
    "    os.remove(model_file)\n",
    "try:\n",
    "    history = History()\n",
    "    model.fit_generator(augmented_batch_gen(make_batch_getter('./data/5_ready/train/',\n",
    "                                                              batch_size=BATCH_SIZE),\n",
    "                                            train_aug),\n",
    "                        BATCH_SIZE * 80,\n",
    "                        epochs=200,\n",
    "                        callbacks=[\n",
    "                                   EarlyStopping(verbose=1, patience=10, monitor='val_dice_coef_01', mode='max'),\n",
    "                                   ModelCheckpoint(filepath=model_file, verbose=1, monitor='val_dice_coef_01', mode='max', save_best_only=True),\n",
    "                                   history,\n",
    "                                   TensorBoard(log_dir=log_dir,\n",
    "#                                                histogram_freq=1,\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               write_graph=True,\n",
    "                                               write_grads=True,\n",
    "                                               write_images=True),\n",
    "                                   ReduceLROnPlateau(factor=0.5,\n",
    "                                                     patience=40,\n",
    "                                                     epsilon=1e-3,\n",
    "                                                     verbose=1,\n",
    "                                                     cooldown=10,\n",
    "                                                     min_lr=1e-6)\n",
    "                        ],\n",
    "                        validation_data=augmented_batch_gen(make_batch_getter('./data/5_ready/val/',\n",
    "                                                                              batch_size=BATCH_SIZE),\n",
    "                                                            val_aug),\n",
    "                        validation_steps=BATCH_SIZE * 20,\n",
    "                        verbose=1)\n",
    "except KeyboardInterrupt:\n",
    "    print(traceback.format_exc())\n",
    "    pass\n",
    "# model = load_model(model_file, custom_objects=dict(dice_coef_loss=dice_coef_loss,\n",
    "#                                                    dice_coef=dice_coef,\n",
    "#                                                    dice_ce_loss=dice_ce_loss,\n",
    "#                                                    dice_coef_0=dice_coef_0,\n",
    "#                                                    dice_coef_1=dice_coef_1,\n",
    "#                                                    dice_coef_01=dice_coef_01,\n",
    "#                                                    dice_ce_01_loss=dice_ce_01_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-07-18T07:54:50.772Z"
    }
   },
   "outputs": [],
   "source": [
    "# for fold in glob.glob('/notebook/data/6_eval/*/'):\n",
    "#     fold_train_h5 = h5py.File(os.path.join(fold, 'train.hdf'), 'r')\n",
    "#     fold_val_h5 = h5py.File(os.path.join(fold, 'val.hdf'), 'r')\n",
    "\n",
    "#     fold_train_in = fold_train_h5['in_data']\n",
    "#     fold_train_out = fold_train_h5['out_data']\n",
    "\n",
    "#     fold_val_in = fold_val_h5['in_data']\n",
    "#     fold_val_out = fold_val_h5['out_data']\n",
    "\n",
    "#     fold_model_fname = os.path.join(fold, 'model')\n",
    "#     if os.path.exists(fold_model_fname):\n",
    "#         os.remove(fold_model_fname)\n",
    "\n",
    "#     history = History()\n",
    "#     model = get_unet(fold_train_in.shape[1:], fold_val_out.shape[-1])\n",
    "#     model.fit(fold_train_in,\n",
    "#               fold_train_out,\n",
    "#               batch_size=8,\n",
    "#               epochs=20,\n",
    "#               callbacks=[\n",
    "#                          EarlyStopping(verbose=1, patience=10, monitor='val_dice_coef_01', mode='max'),\n",
    "#                          ModelCheckpoint(filepath=fold_model_fname, verbose=1, monitor='val_dice_coef_01', mode='max', save_best_only=True),\n",
    "#                          history\n",
    "# #                          ReduceLROnPlateau(factor=0.3, patience=10, epsilon=1e-3, verbose=1, cooldown=5, min_lr=1e-6)\n",
    "# #                          LearningRateScheduler(lambda epoch: 1e-1 * (0.93 ** epoch))\n",
    "#                          ],\n",
    "#               validation_data=[fold_val_in, fold_val_out],\n",
    "#               shuffle='batch',\n",
    "#               verbose=1)\n",
    "#     with open(os.path.join(fold, 'train_history.js'), 'w') as f:\n",
    "#         json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-18T07:53:51.482911Z",
     "start_time": "2017-07-18T07:53:51.137633Z"
    }
   },
   "outputs": [],
   "source": [
    "# cv_hist = pandas.concat([pandas.DataFrame(json.load(open(os.path.join(fold, 'train_history.js'), 'r')))\n",
    "#                          for fold in glob.glob('/notebook/data/6_eval/*/')],\n",
    "#                         keys=[os.path.basename(fold) for fold in glob.glob('/notebook/data/6_eval/*')],\n",
    "#                         names=['fold'],\n",
    "#                         axis=1)\n",
    "# cv_hist.xs('val_dice_coef_01', level=1, axis=1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-07-21T21:32:05.810Z"
    }
   },
   "outputs": [],
   "source": [
    "# ax = pandas.DataFrame(history.history)[[k for k in history.history.keys()]].plot(figsize=(16, 10))\n",
    "# ax.set_ylim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-10T08:05:59.073577Z",
     "start_time": "2017-07-10T08:04:00.285901Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_layer_vis(model, layer_i):\n",
    "    output_getter = K.function([model.layers[0].input, K.learning_phase()],\n",
    "                               [model.layers[layer_i].output])\n",
    "    def _impl(img):\n",
    "        inp = numpy.expand_dims(numpy.expand_dims(numpy.array(img), -1), 0)\n",
    "        outp = output_getter([inp, False])[0]\n",
    "        flat = numpy.rollaxis(outp, -1, 2).reshape((outp.shape[1], outp.shape[2]*outp.shape[-1]))\n",
    "        display((flat.min(), flat.max(), flat.mean()))\n",
    "        flat -= flat.min()\n",
    "        flat /= (flat.max() + 1e-4)\n",
    "#         flat = outp[0, :, :, 0] #.reshape((outp.shape[1], outp.shape[2]*outp.shape[-1]))\n",
    "        return Image.fromarray((flat*255).astype('uint8'), mode='L')\n",
    "    return _impl\n",
    "\n",
    "def vis_layer(img, model):\n",
    "    visualizers = [(model.layers[i], make_layer_vis(model, i))\n",
    "                   for i in (i for i in range(len(model.layers))\n",
    "                             if not isinstance(model.layers[i],\n",
    "                                               (Dropout,\n",
    "                                                BatchNormalization,\n",
    "                                                )))]\n",
    "    for layer, v in visualizers:\n",
    "        display(layer.name)\n",
    "        display(v(img))\n",
    "        time.sleep(1.0)\n",
    "\n",
    "# vis_img = read_images_to_tensor(['./data/5_ready/test_tiny/12147373-0005_2_in.png'])[0]\n",
    "vis_img = fake_batch[0][2, :, :, 0]\n",
    "vis_layer(vis_img, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "notify_time": "5",
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "799px",
    "left": "0px",
    "right": "1708px",
    "top": "106px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
